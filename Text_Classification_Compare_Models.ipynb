{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Text Classification</center></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "0it [00:00, ?it/s]\n",
      "/home/chris/.local/lib/python3.8/site-packages/tqdm/std.py:668: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import time\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os\n",
    "import random\n",
    "import stanza\n",
    "import re\n",
    "#from preprocess import * \n",
    "#from custom_preprocessing import CustomPreProcessing\n",
    "#from custom_preprocessing import PreProcessing\n",
    "#from class_metric import Metrics\n",
    "from googletrans import Translator\n",
    "import sklearn\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn import decomposition, ensemble\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import balanced_accuracy_score, recall_score, f1_score\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "\n",
    "\n",
    "import itertools\n",
    "#from textblob import TextBlob \n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "sns.set(style=\"darkgrid\")\n",
    "\n",
    "\n",
    "import string\n",
    "import fasttext\n",
    "import fasttext.util\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ---- Call tqdm to see progress bar with pandas\n",
    "tqdm().pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23.1\n",
      "2.2.0\n"
     ]
    }
   ],
   "source": [
    "print(sklearn.__version__)\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tn(y_true, y_pred): return confusion_matrix(y_true, y_pred)[0, 0]\n",
    "def fp(y_true, y_pred): return confusion_matrix(y_true, y_pred)[0, 1]\n",
    "def fn(y_true, y_pred): return confusion_matrix(y_true, y_pred)[1, 0]\n",
    "def tp(y_true, y_pred): return confusion_matrix(y_true, y_pred)[1, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Content</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Parameters](#part_1)\n",
    "- [List of Models](#part_2)\n",
    "- [List of Metrics for the Model Selection](#part_3)\n",
    "- [Sand box to load Data](#part_4)\n",
    "- [Start Pipeline](#part_5)\n",
    "    - [Prepare data to ML classic](#part_5_1)\n",
    "- [Machine Learning](#part_6)\n",
    "    - [Class Weights](#part_6_1)\n",
    "    - [Save Unique Labels](#part_6_2)\n",
    "    - [DataFrame for the Results](#part_6_3)\n",
    "    - [One-Hot encoding](#part_6_4)\n",
    "    - [TF-IDF](#part_6_5)\n",
    "    - [Load Pre-trained Model FastText](#part_6_6)\n",
    "    - [Word Embeddings](#part_6_7)\n",
    "    - [Multinomial Naive Bayes](#part_6_8)\n",
    "    - [Logistic Regression](#part_6_9)\n",
    "    - [SVM](#part_6_10)\n",
    "    - [k-NN](#part_6_11)\n",
    "    - [RandomForest](#part_6_12)\n",
    "    - [Stochastic Gradient Descent](#part_6_13)\n",
    "    - [Gradient Boosting](#part_6_14)\n",
    "    - [XGBoost Classifier](#part_6_15)\n",
    "- [Deep Learning](#part_7)\n",
    "    - [Shallow Neural Networks](#part_7_1)\n",
    "    - [Deep Neural Networks](#part_7_2)\n",
    "    - [Recurrent Neural Networks (RNN)](#part_7_3)\n",
    "    - [Convolutional Neural Networks (CNN)](#part_7_4)\n",
    "    - [Long Short Terme Memory (LSTM)](#part_7_5)\n",
    "    - [CNN-LSTM](#part_7_6)\n",
    "    - [CNN-GRU](#part_7_7)\n",
    "    - [Gated Recurrent Unit (GRU)](#part_7_8)\n",
    "    - [Biderectional RNN](#part_7_9)\n",
    "    - [Biderectional LSTM](#part_7_10)\n",
    "    - [Bidirectional GRU](#part_7_11)\n",
    "    - [Recurent Convulotional Neural Nerworks (RCNN)](#part_7_12)\n",
    "    - [Transformers](#part_7_13)\n",
    "- [Results](#part_8)\n",
    "- [Visualization](#part_9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h2><a id=\"part_1\">Parameters</a></h2></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part allows you to determine the text column to classify as well as the label column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = \"text\"\n",
    "LABEL = \"label\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h2><a id=\"part_2\">List of Models</a></h2></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "CV_splits              = 5        # Number of splits for cross-validation and k-folds\n",
    "save_results           = True\n",
    "lang                   = False\n",
    "sample                 = True\n",
    "multinomial_naive_bayes= True\n",
    "logistic_regression    = True\n",
    "svm_model              = False\n",
    "k_nn_model             = True\n",
    "sgd                    = True\n",
    "random_forest          = True\n",
    "gradient_boosting      = True\n",
    "xgboost_classifier     = True\n",
    "shallow_network        = True\n",
    "deep_nn                = True\n",
    "rnn                    = True\n",
    "lstm                   = True\n",
    "cnn                    = True\n",
    "gru                    = True\n",
    "cnn_lstm               = True\n",
    "cnn_gru                = True\n",
    "bidirectional_rnn      = True\n",
    "bidirectional_lstm     = True\n",
    "bidirectional_gru      = True\n",
    "rcnn                   = True\n",
    "transformers           = True\n",
    "pre_trained            = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h2><a id=\"part_3\">List of Metrics for the Model Selection</a></h2></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_metrics = {'acc': accuracy_score,\n",
    "               'balanced_accuracy': balanced_accuracy_score,\n",
    "               'prec': precision_score,\n",
    "               'recall': recall_score,\n",
    "               'f1-score': f1_score,\n",
    "               'tp': tp, 'tn': tn,\n",
    "               'fp': fp, 'fn': fn,\n",
    "               'cohens_kappa':cohen_kappa_score,\n",
    "               'matthews_corrcoef':matthews_corrcoef,\n",
    "               \"roc_auc\":roc_auc_score}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h2><a id=\"part_4\">Sand Box to Load Data</a></h2></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sandbox is the working area of your data if it has not been processed before using the pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for preprocessing\n",
    "def remove_upper_case( text):\n",
    "    '''\n",
    "    Function to transform upper string in title words\n",
    "    @param text: (str) text \n",
    "    @return: (str) text without upper words \n",
    "    '''\n",
    "    sentences = text.split(\"\\n\")\n",
    "    new_sentences = []\n",
    "    for i in sentences:\n",
    "        words = text.split()\n",
    "        stripped = [w.title() if w.isupper() else w for w in words]\n",
    "        new_sentences.append(\" \".join(stripped))\n",
    "    return \"\\n\".join(new_sentences)\n",
    "  \n",
    "def remove_URL( text):\n",
    "    '''\n",
    "    Function to remove url from text.\n",
    "    @param text: (str) sentence\n",
    "    @return: (str) clean text\n",
    "\n",
    "    '''\n",
    "    url = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return url.sub(r'',text)\n",
    "    \n",
    "    \n",
    "def remove_html( text):\n",
    "    '''\n",
    "    Function regex to clean text from html balises.\n",
    "    @param text: (str) sentence \n",
    "    @return: (str) clean text \n",
    "    '''\n",
    "    html=re.compile(r'<.*?>')\n",
    "    return html.sub(r'',text)\n",
    "    \n",
    "    \n",
    "\n",
    "def remove_emoji( text):\n",
    "    '''\n",
    "    Function to remove emojis, symbols and pictograms etc from text\n",
    "    @param text: (str) sentences \n",
    "    @return: (str) clean text \n",
    "    '''\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "df = pd.read_csv(\"mails_clean_new.csv\", sep=\";\")\n",
    "df[LABEL][df[LABEL]!=\"annulation\"] = \"other\"\n",
    "print(df[LABEL].value_counts())\n",
    "print(df[TEXT].isnull().sum())\n",
    "#df[TEXT][df[TEXT].isnull()] = \"empty\"\n",
    "df.dropna(subset=[TEXT])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will not apply HSTS. The HSTS database must be a regular and non-world-writable file.\n",
      "ERROR: could not open HSTS store at '/home/chris/.wget-hsts'. HSTS will be disabled.\n",
      "--2020-06-08 23:02:31--  http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
      "Resolving ai.stanford.edu (ai.stanford.edu)... 171.64.68.10\n",
      "Connecting to ai.stanford.edu (ai.stanford.edu)|171.64.68.10|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 84125825 (80M) [application/x-gzip]\n",
      "Saving to: ‘aclImdb_v1.tar.gz’\n",
      "\n",
      "aclImdb_v1.tar.gz   100%[===================>]  80.23M  7.52MB/s    in 15s     \n",
      "\n",
      "2020-06-08 23:02:46 (5.50 MB/s) - ‘aclImdb_v1.tar.gz’ saved [84125825/84125825]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
    "!tar -xzf aclImdb_v1.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_imdb_sentiment_analysis_dataset(data_path, seed=123):\n",
    "    \"\"\"Loads the IMDb movie reviews sentiment analysis dataset.\n",
    "\n",
    "    # Arguments\n",
    "        data_path: string, path to the data directory.\n",
    "        seed: int, seed for randomizer.\n",
    "\n",
    "    # Returns\n",
    "        A tuple of training and validation data.\n",
    "        Number of training samples: 25000\n",
    "        Number of test samples: 25000\n",
    "        Number of categories: 2 (0 - negative, 1 - positive)\n",
    "\n",
    "    # References\n",
    "        Mass et al., http://www.aclweb.org/anthology/P11-1015\n",
    "\n",
    "        Download and uncompress archive from:\n",
    "        http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
    "    \"\"\"\n",
    "    imdb_data_path = os.path.join(data_path, 'aclImdb')\n",
    "\n",
    "    # Load the training data\n",
    "    train_texts = []\n",
    "    train_labels = []\n",
    "    for category in ['pos', 'neg']:\n",
    "        train_path = os.path.join(imdb_data_path, 'train', category)\n",
    "        for fname in tqdm(sorted(os.listdir(train_path))):\n",
    "            if fname.endswith('.txt'):\n",
    "                with open(os.path.join(train_path, fname)) as f:\n",
    "                    train_texts.append(f.read())\n",
    "                train_labels.append(0 if category == 'neg' else 1)\n",
    "    print(\"\\nTrain done\\n\")\n",
    "    # Load the validation data.\n",
    "    test_texts = []\n",
    "    test_labels = []\n",
    "    for category in ['pos', 'neg']:\n",
    "        test_path = os.path.join(imdb_data_path, 'test', category)\n",
    "        for fname in tqdm(sorted(os.listdir(test_path))):\n",
    "            if fname.endswith('.txt'):\n",
    "                with open(os.path.join(test_path, fname)) as f:\n",
    "                    test_texts.append(f.read())\n",
    "                test_labels.append(0 if category == 'neg' else 1)\n",
    "    print(\"\\nTest done\\n\")\n",
    "    # Shuffle the training data and labels.\n",
    "    random.seed(seed)\n",
    "    random.shuffle(train_texts)\n",
    "    random.seed(seed)\n",
    "    random.shuffle(train_labels)\n",
    "\n",
    "    return ((train_texts, np.array(train_labels)),\n",
    "            (test_texts, np.array(test_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12500/12500 [04:03<00:00, 51.40it/s]\n",
      "100%|██████████| 12500/12500 [03:46<00:00, 55.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train done\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12500/12500 [04:14<00:00, 49.20it/s]\n",
      "100%|██████████| 12500/12500 [03:57<00:00, 52.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test done\n",
      "\n",
      "                                                text label\n",
      "0  Possible SPOILERSThe Spy Who Shagged Me is a m...     0\n",
      "1  The long list of \"big\" names in this flick (in...     0\n",
      "2  Bette Midler showcases her talents and beauty ...     1\n",
      "3  Great movie when I saw it. Have to say one of ...     1\n",
      "4  Although it's most certainly politically incor...     1\n",
      "CPU times: user 51.1 s, sys: 54.7 s, total: 1min 45s\n",
      "Wall time: 16min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#%%script false --no-raise-error\n",
    "(x_train, y_train), (x_test, y_test) = load_imdb_sentiment_analysis_dataset(\"../Datasets/\")\n",
    "\n",
    "df = pd.DataFrame(data=[x_train, y_train], index=[\"text\", \"label\"]).T\n",
    "df = df.append(pd.DataFrame(data=[x_test, y_test], index=[\"text\", \"label\"]).T)\n",
    "\n",
    "df[TEXT] = df[TEXT].apply(remove_upper_case)\n",
    "df[TEXT] = df[TEXT].apply(remove_URL)\n",
    "df[TEXT] = df[TEXT].apply(remove_html)\n",
    "df[TEXT] = df[TEXT].apply(remove_emoji)\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h2><a id=\"part_5\">Sart Pipeline</a></h2></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_lang_google( x):\n",
    "        '''\n",
    "        Function to detect the language of the string\n",
    "        @param x: (str) sentences of text to detect language\n",
    "        @return: (str or nan) language of the sentence\n",
    "        '''\n",
    "        translate = Translator()\n",
    "        try:\n",
    "            return translate.detect(x).lang\n",
    "        except:\n",
    "            return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if lang:\n",
    "    # ---- Language detection of the text\n",
    "    df.loc[:,\"language\"] = df[TEXT].progress_apply(detect_lang_google)\n",
    "    # ---- Extract most frequent language \n",
    "    language = df.language.value_counts().index.tolist()[0]\n",
    "    print(f\"The language most present in the dataset is {language}\")\n",
    "else:\n",
    "    language=\"en\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h3><a id=\"part_5_1\">Prepare data for ML Classic</a></h3></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if sample:\n",
    "    df_save = df.copy()\n",
    "    df = df.sample(5000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Load stopwords \n",
    "if language==\"fr\":\n",
    "    stop_word = np.loadtxt(\"../stopwords/stopwords-fr.txt\", dtype=str)\n",
    "if language==\"en\":\n",
    "    stop_word = np.loadtxt(\"../stopwords/stopwords_en.txt\", dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words( x, stop_word):\n",
    "        '''\n",
    "        Function to remove a list of words\n",
    "        @param x : (str) text \n",
    "        @param stop_word: (list) list of stopwords to delete \n",
    "        @return: (str) new string without stopwords \n",
    "        '''\n",
    "        x_new = text_to_word_sequence(x)    # tokenize text \n",
    "        x_ = []\n",
    "        for i in x_new:\n",
    "            if i not in stop_word:\n",
    "                x_.append(i)\n",
    "        return \" \".join(x_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:31<00:00, 161.00it/s]\n"
     ]
    }
   ],
   "source": [
    "df.loc[:,TEXT+\"_sw\"] = df.loc[:,TEXT].progress_apply(lambda x : remove_stop_words(x, stop_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if df[TEXT+\"_sw\"].isnull().sum()>0:\n",
    "    print(\"Empty text\")\n",
    "    df.dropna(subset=[TEXT+\"_w\"])\n",
    "    #df[TEXT+\"_sw\"][df[TEXT+\"_sw\"].isnull()] = \"empty_text\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><a id=\"part_6\"><h1>Machine Learning</h1></a></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset into training and validation datasets \n",
    "# ML classic \n",
    "train_x_sw, valid_x_sw, y_train_sw, y_valid_sw = model_selection.train_test_split(df[TEXT+\"_sw\"], df[LABEL], random_state=42, stratify=df[LABEL], test_size=0.2)\n",
    "\n",
    "# For Embeddings\n",
    "train_x, valid_x, y_train, y_valid = model_selection.train_test_split(df[TEXT], df[LABEL], random_state=42, stratify=df[LABEL], test_size=0.2)\n",
    "\n",
    "# label encode the target variable \n",
    "encoder = preprocessing.LabelEncoder()\n",
    "train_y_sw = encoder.fit_transform(y_train_sw)\n",
    "valid_y_sw = encoder.fit_transform(y_valid_sw)\n",
    "train_y = encoder.fit_transform(y_train)\n",
    "valid_y = encoder.fit_transform(y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><a id=\"part_6_1\"><h3>Class Weights</h3></a></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chris/.local/lib/python3.8/site-packages/sklearn/utils/validation.py:68: FutureWarning: Pass classes=[0 1], y=8784     1\n",
      "18183    0\n",
      "536      1\n",
      "5872     1\n",
      "5142     1\n",
      "        ..\n",
      "12214    1\n",
      "11163    1\n",
      "5107     1\n",
      "12958    0\n",
      "23463    0\n",
      "Name: label, Length: 4000, dtype: object as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n"
     ]
    }
   ],
   "source": [
    "# Compute the class weight with sklearn \n",
    "class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                 np.unique(y_train),\n",
    "                                                 y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weight: 1.0194\tclass: 0\n",
      "Class weight: 0.9814\tclass: 1\n"
     ]
    }
   ],
   "source": [
    "print(*[f'Class weight: {round(i[0],4)}\\tclass: {i[1]}' for i in zip(class_weights, np.unique(y_train))], sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The dataset is balanced (ratio=0.962)\n"
     ]
    }
   ],
   "source": [
    "# Determined if the dataset is balanced or imbalanced \n",
    "ratio = np.min(df.label.value_counts()) / np.max(df.label.value_counts())\n",
    "if ratio > 0.1:      # Ratio 1:10 -> limite blanced / imbalanced \n",
    "    balanced = True\n",
    "    print(f\"\\nThe dataset is balanced (ratio={round(ratio, 3)})\")\n",
    "else:\n",
    "    balanced = False\n",
    "    print(f\"\\nThe dataset is imbalanced (ratio={round(ratio, 3)})\")\n",
    "    #from imblearn.over_sampling import ADASYN\n",
    "    # put class for debalanced data \n",
    "    # in progress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><a id=\"part_6_2\"><h3>Save Unique Labels</h3></a></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep the unique label corresponding to their encoding correspondance\n",
    "labels = df[LABEL].unique()\n",
    "test=pd.DataFrame(data=np.transpose([labels,encoder.fit_transform(labels)]), columns=[\"labels\", \"encoding\"]).sort_values(by=[\"encoding\"])\n",
    "labels=test.labels.tolist()\n",
    "if any([0,1]) in labels and len(labels)==2:\n",
    "    labels[labels.index(0)] = \"negative\"\n",
    "    labels[labels.index(1)] = \"positive\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><a id=\"part_6_3\"><h3>DataFrame for the results</h3></a></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><a id=\"part_6_4\"><h3>One-Hot encoding (CountVectorizing)</h3></a></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.61 s, sys: 0 ns, total: 1.61 s\n",
      "Wall time: 1.62 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# create a count vectorizer object \n",
    "count_vect = CountVectorizer(analyzer='word', token_pattern=r'\\w{1,}')\n",
    "count_vect.fit(df[TEXT]+\"_sw\")\n",
    "\n",
    "# transform the training and validation data using count vectorizer object\n",
    "xtrain_count =  count_vect.transform(train_x_sw)\n",
    "xvalid_count =  count_vect.transform(valid_x_sw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xtrain_tfidf.toarray()[0][xtrain_tfidf.toarray()[0]  >0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><a id=\"part_6_5\"><h3>TF-IDF</h3></a></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word level tf-idf done\n",
      "ngram level tf-idf done\n",
      "characters level tf-idf done\n",
      "CPU times: user 18.3 s, sys: 1.27 s, total: 19.6 s\n",
      "Wall time: 19.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# word level tf-idf\n",
    "tfidf_vect = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', max_features=10000)\n",
    "tfidf_vect.fit(df[TEXT])\n",
    "xtrain_tfidf =  tfidf_vect.transform(train_x_sw)\n",
    "xvalid_tfidf =  tfidf_vect.transform(valid_x_sw)\n",
    "print(\"word level tf-idf done\")\n",
    "# ngram level tf-idf \n",
    "tfidf_vect_ngram = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', ngram_range=(2,3), max_features=10000)\n",
    "tfidf_vect_ngram.fit(df[TEXT])\n",
    "xtrain_tfidf_ngram =  tfidf_vect_ngram.transform(train_x_sw)\n",
    "xvalid_tfidf_ngram =  tfidf_vect_ngram.transform(valid_x_sw)\n",
    "print(\"ngram level tf-idf done\")\n",
    "# characters level tf-idf\n",
    "tfidf_vect_ngram_chars = TfidfVectorizer(analyzer='char',  ngram_range=(2,3), max_features=10000) #token_pattern=r'\\w{1,}',\n",
    "tfidf_vect_ngram_chars.fit(df[TEXT])\n",
    "xtrain_tfidf_ngram_chars =  tfidf_vect_ngram_chars.transform(train_x_sw) \n",
    "xvalid_tfidf_ngram_chars =  tfidf_vect_ngram_chars.transform(valid_x_sw) \n",
    "print(\"characters level tf-idf done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><a id=\"part_6_6\"><h3>Load Pre-Trained model fastText</h3></a></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.1 s, sys: 29.2 s, total: 40.3 s\n",
      "Wall time: 1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if language==\"fr\":\n",
    "    #!wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.fr.300.bin.gz\n",
    "    #!gunzip cc.fr.300.bin.gz\n",
    "    pretrained = fasttext.FastText.load_model('../Pretrained-models/cc.fr.300.bin')\n",
    "if language==\"en\":\n",
    "    #!wget https://dl.fbaipublicfiles.com/fasttext/vectors-english/crawl-300d-2M-subword.zip\n",
    "    #!unzip crawl-300d-2M-subword.zip\n",
    "    pretrained = fasttext.FastText.load_model('../Pretrained-models/crawl-300d-2M-subword.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><a id=\"part_6_7\"><h3>Word Embeddings</h3></a></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43321/43321 [00:02<00:00, 16293.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.19 s, sys: 594 ms, total: 7.78 s\n",
      "Wall time: 9.79 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "# create a tokenizer \n",
    "token = Tokenizer()\n",
    "token.fit_on_texts(df[TEXT])\n",
    "word_index = token.word_index\n",
    "\n",
    "# convert text to sequence of tokens and pad them to ensure equal length vectors \n",
    "train_seq_x = sequence.pad_sequences(token.texts_to_sequences(train_x), maxlen=300)\n",
    "valid_seq_x = sequence.pad_sequences(token.texts_to_sequences(valid_x), maxlen=300)\n",
    "\n",
    "# create token-embedding mapping\n",
    "embedding_matrix = np.zeros((len(word_index) + 1, 300))\n",
    "words = []\n",
    "for word, i in tqdm(word_index.items()):\n",
    "    embedding_vector = pretrained.get_word_vector(word) #embeddings_index.get(word)\n",
    "    words.append(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#words[1], embedding_matrix[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report(clf, x, y, name='classifier', cv=5, dict_scoring=None, fit_params=None):\n",
    "    '''\n",
    "    Function create a metric report automatically with cross_validate function.\n",
    "    @param clf: (model) classifier\n",
    "    @param x: (list or matrix or tensor) training x data\n",
    "    @param y: (list) label data \n",
    "    @param name: (string) name of the model (default classifier)\n",
    "    @param cv: (int) number of fold for cross-validation (default 5)\n",
    "    @param dict_scoring: (dict) dictionary of metrics and names\n",
    "    @param fit_aparams: (dict) add parameters for model fitting \n",
    "    @return: (pandas.dataframe) dataframe containing all the results of the metrics \n",
    "    for each fold and the mean and std for each of them\n",
    "    '''\n",
    "    if dict_scoring!=None:\n",
    "        score = dict_scoring.copy() # save the original dictionary\n",
    "        for i in score.keys():\n",
    "            score[i] = make_scorer(score[i]) # make each function scorer\n",
    "    \n",
    "    scores = cross_validate(clf, x, y, scoring=score,\n",
    "                         cv=cv, return_train_score=False, n_jobs=-1,  fit_params=fit_params)\n",
    "    # initialisation \n",
    "    index = []\n",
    "    value = []\n",
    "    index.append(\"Model\")\n",
    "    value.append(name)\n",
    "    for i in scores:  # loop on each metric generate text and values\n",
    "        if i == \"estimator\":\n",
    "            continue\n",
    "        for j in enumerate(scores[i]):\n",
    "            index.append(i+\"_cv\"+str(j[0]+1))\n",
    "            value.append(j[1])\n",
    "        \n",
    "        \n",
    "        index.append(i+\"_mean\")\n",
    "        value.append(np.mean(scores[i]))\n",
    "        index.append(i+\"_std\")\n",
    "        value.append(np.std(scores[i]))\n",
    "        \n",
    "    return pd.DataFrame(data=value, index=index).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><a id=\"part_6_8\"><h3>Multinomial Naive Bayes</h3></a></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if multinomial_naive_bayes:\n",
    "    df_results = df_results.append(report(naive_bayes.MultinomialNB(), xtrain_count,train_y_sw, name='NB_Count_Vectors', cv=CV_splits, dict_scoring=score_metrics))\n",
    "    df_results = df_results.append(report(naive_bayes.MultinomialNB(), xtrain_tfidf,train_y, name='NB_WordLevel_TF-IDF', cv=CV_splits, dict_scoring=score_metrics))\n",
    "    df_results = df_results.append(report(naive_bayes.MultinomialNB(), xtrain_tfidf_ngram,train_y, name='NB_N-Gram_TF-IDF', cv=CV_splits, dict_scoring=score_metrics))\n",
    "    df_results = df_results.append(report(naive_bayes.MultinomialNB(), xtrain_tfidf_ngram_chars,train_y, name='NB_CharLevel_TF-IDF', cv=CV_splits, dict_scoring=score_metrics))\n",
    "    df_results = df_results.append(report(naive_bayes.MultinomialNB(), train_seq_x,train_y, name='NB_Words', cv=CV_splits, dict_scoring=score_metrics))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><a id=\"part_6_9\"><h3>Logistic Regression</h3></a></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if logistic_regression:\n",
    "    df_results = df_results.append(report(linear_model.LogisticRegression(max_iter=1000), xtrain_count,train_y_sw, name='LR_Count_Vectors', cv=CV_splits, dict_scoring=score_metrics))\n",
    "    df_results = df_results.append(report(linear_model.LogisticRegression(max_iter=1000), xtrain_tfidf,train_y, name='LR_WordLevel_TF-IDF', cv=CV_splits, dict_scoring=score_metrics))\n",
    "    df_results = df_results.append(report(linear_model.LogisticRegression(max_iter=1000), xtrain_tfidf_ngram,train_y, name='LR_N-Gram_TF-IDF', cv=CV_splits, dict_scoring=score_metrics))\n",
    "    df_results = df_results.append(report(linear_model.LogisticRegression(max_iter=1000), xtrain_tfidf_ngram_chars,train_y, name='LR_CharLevel_TF-IDF', cv=CV_splits, dict_scoring=score_metrics))\n",
    "    df_results = df_results.append(report(linear_model.LogisticRegression(max_iter=1000), train_seq_x,train_y, name='LR_Words', cv=CV_splits, dict_scoring=score_metrics))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><a id=\"part_6_10\"><h3>SVM</h3></a></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if svm_model:\n",
    "    df_results = df_results.append(report(svm.SVC(), xtrain_count,train_y_sw, name='SVM_Count_Vectors', cv=CV_splits, dict_scoring=score_metrics))\n",
    "    df_results = df_results.append(report(svm.SVC(), xtrain_tfidf,train_y, name='SVM_WordLevel_TF-IDF', cv=CV_splits, dict_scoring=score_metrics))\n",
    "    df_results = df_results.append(report(svm.SVC(), xtrain_tfidf_ngram,train_y, name='SVM_N-Gram_TF-IDF', cv=CV_splits, dict_scoring=score_metrics))\n",
    "    df_results = df_results.append(report(svm.SVC(), xtrain_tfidf_ngram_chars,train_y, name='SVM_CharLevel_TF-IDF', cv=CV_splits, dict_scoring=score_metrics))\n",
    "    df_results = df_results.append(report(svm.SVC(), train_seq_x,train_y, name='SVM_Words', cv=CV_splits, dict_scoring=score_metrics))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><a id=\"part_6_11\"><h3>k-NN</h3></a></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if k_nn_model:\n",
    "    df_results = df_results.append(report(KNeighborsClassifier(n_neighbors=20, weights='distance', n_jobs=-1), xtrain_count,train_y_sw, name='kNN_Count_Vectors', cv=CV_splits, dict_scoring=score_metrics))\n",
    "    df_results = df_results.append(report(KNeighborsClassifier(n_neighbors=20, weights='distance', n_jobs=-1), xtrain_tfidf,train_y, name='kNN_WordLevel_TF-IDF', cv=CV_splits, dict_scoring=score_metrics))\n",
    "    df_results = df_results.append(report(KNeighborsClassifier(n_neighbors=20, weights='distance', n_jobs=-1), xtrain_tfidf_ngram,train_y, name='kNN_N-Gram_TF-IDF', cv=CV_splits, dict_scoring=score_metrics))\n",
    "    df_results = df_results.append(report(KNeighborsClassifier(n_neighbors=20, weights='distance', n_jobs=-1), xtrain_tfidf_ngram_chars,train_y, name='kNN_CharLevel_TF-IDF', cv=CV_splits, dict_scoring=score_metrics))\n",
    "    df_results = df_results.append(report(KNeighborsClassifier(n_neighbors=20, weights='distance', n_jobs=-1), train_seq_x,train_y, name='kNN_Words', cv=CV_splits, dict_scoring=score_metrics))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><a id=\"part_6_12\"><h3>RandomForest</h3></a></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if random_forest:\n",
    "    df_results = df_results.append(report(ensemble.RandomForestClassifier(bootstrap=True,min_impurity_decrease=1e-7,n_jobs=-1, random_state=42), xtrain_count,train_y_sw, name='RF_Count_Vectors', cv=CV_splits, dict_scoring=score_metrics))\n",
    "    df_results = df_results.append(report(ensemble.RandomForestClassifier(bootstrap=True,min_impurity_decrease=1e-7,n_jobs=-1, random_state=42), xtrain_tfidf,train_y, name='RF_WordLevel_TF-IDF', cv=CV_splits, dict_scoring=score_metrics))\n",
    "    df_results = df_results.append(report(ensemble.RandomForestClassifier(bootstrap=True,min_impurity_decrease=1e-7,n_jobs=-1, random_state=42), xtrain_tfidf_ngram,train_y, name='RF_N-Gram_TF-IDF', cv=CV_splits, dict_scoring=score_metrics))\n",
    "    df_results = df_results.append(report(ensemble.RandomForestClassifier(bootstrap=True,min_impurity_decrease=1e-7,n_jobs=-1, random_state=42), xtrain_tfidf_ngram_chars,train_y, name='RF_CharLevel_TF-IDF', cv=CV_splits, dict_scoring=score_metrics))\n",
    "    df_results = df_results.append(report(ensemble.RandomForestClassifier(bootstrap=True,min_impurity_decrease=1e-7,n_jobs=-1, random_state=42), train_seq_x,train_y, name='RF_Words', cv=CV_splits, dict_scoring=score_metrics))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><a id=\"part_6_13\"><h3>Stochastic Gradient Descent</h3></a></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if sgd:\n",
    "    df_results = df_results.append(report(SGDClassifier(loss='modified_huber', max_iter=1000, tol=1e-3,   n_iter_no_change=10, early_stopping=True, n_jobs=-1 ), xtrain_count,train_y_sw, name='SGD_Count_Vectors', cv=CV_splits, dict_scoring=score_metrics))\n",
    "    df_results = df_results.append(report(SGDClassifier(loss='modified_huber', max_iter=1000, tol=1e-3,   n_iter_no_change=10, early_stopping=True, n_jobs=-1 ), xtrain_tfidf,train_y, name='SGD_WordLevel_TF-IDF', cv=CV_splits, dict_scoring=score_metrics))\n",
    "    df_results = df_results.append(report(SGDClassifier(loss='modified_huber', max_iter=1000, tol=1e-3,   n_iter_no_change=10, early_stopping=True, n_jobs=-1 ), xtrain_tfidf_ngram,train_y, name='SGD_N-Gram_Vectors', cv=CV_splits, dict_scoring=score_metrics))\n",
    "    df_results = df_results.append(report(SGDClassifier(loss='modified_huber', max_iter=1000, tol=1e-3,   n_iter_no_change=10, early_stopping=True, n_jobs=-1 ), xtrain_tfidf_ngram_chars,train_y, name='SGD_CharLevel_Vectors', cv=CV_splits, dict_scoring=score_metrics))\n",
    "    df_results = df_results.append(report(SGDClassifier(loss='modified_huber', max_iter=1000, tol=1e-3,   n_iter_no_change=10, early_stopping=True, n_jobs=-1 ), train_seq_x,train_y, name='SGD_Words', cv=CV_splits, dict_scoring=score_metrics))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><a id=\"part_6_14\"><h3>Gradient Boosting</h3></a></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if gradient_boosting:\n",
    "    df_results = df_results.append(report(ensemble.GradientBoostingClassifier(n_estimators=1000,\n",
    "                                               validation_fraction=0.2,\n",
    "                                               n_iter_no_change=10, tol=0.01,\n",
    "                                               random_state=0, verbose=0 ), xtrain_count,train_y_sw, name='GB_Count_Vectors', cv=CV_splits, dict_scoring=score_metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if gradient_boosting:\n",
    "    df_results = df_results.append(report(ensemble.GradientBoostingClassifier(n_estimators=1000,\n",
    "                                               validation_fraction=0.2,\n",
    "                                               n_iter_no_change=10, tol=0.01,\n",
    "                                               random_state=0, verbose=0 ), xtrain_tfidf,train_y, name='GB_WordLevel_TF-IDF', cv=CV_splits, dict_scoring=score_metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if gradient_boosting:\n",
    "    df_results = df_results.append(report(ensemble.GradientBoostingClassifier(n_estimators=1000,\n",
    "                                               validation_fraction=0.2,\n",
    "                                               n_iter_no_change=10, tol=0.01,\n",
    "                                               random_state=0, verbose=0 ), xtrain_tfidf_ngram,train_y, name='GB_N-Gram_TF-IDF', cv=CV_splits, dict_scoring=score_metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if gradient_boosting:\n",
    "    df_results = df_results.append(report(ensemble.GradientBoostingClassifier(n_estimators=1000,\n",
    "                                               validation_fraction=0.2,\n",
    "                                               n_iter_no_change=10, tol=0.01,\n",
    "                                               random_state=0, verbose=0 ), xtrain_tfidf_ngram_chars,train_y, name='GB_CharLevel_TF-IDF', cv=CV_splits, dict_scoring=score_metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if gradient_boosting:\n",
    "    df_results = df_results.append(report(ensemble.GradientBoostingClassifier(n_estimators=1000,\n",
    "                                               validation_fraction=0.2,\n",
    "                                               n_iter_no_change=10, tol=0.01,\n",
    "                                               random_state=0, verbose=0 ), train_seq_x,train_y, name='GB_Words', cv=CV_splits, dict_scoring=score_metrics))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><a id=\"part_6_15\"><h3>XGBoost Classifier</h3></a></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the XGBoost have early stopping implemented with 10 rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if xgboost_classifier:\n",
    "    fit_params={'early_stopping_rounds':10,\\\n",
    "                         'eval_set':[(xvalid_count, valid_y_sw)]}\n",
    "    df_results = df_results.append(report(XGBClassifier(n_estimators=1000, subsample=0.8), xtrain_count,train_y_sw, name='XGB_Count_Vectors', cv=CV_splits, fit_params=fit_params, dict_scoring=score_metrics))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if xgboost_classifier:\n",
    "    fit_params={'early_stopping_rounds':10,\\\n",
    "                         'eval_set':[(xvalid_tfidf, valid_y_sw)]}\n",
    "    df_results = df_results.append(report(XGBClassifier(n_estimators=1000, subsample=0.8), xtrain_tfidf,train_y, name='XGB_WordLevel_TF-IDF', cv=CV_splits, fit_params=fit_params, dict_scoring=score_metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if xgboost_classifier:\n",
    "    fit_params={'early_stopping_rounds':10,\\\n",
    "                         'eval_set':[(xvalid_tfidf_ngram, valid_y_sw)]}\n",
    "    df_results = df_results.append(report(XGBClassifier(n_estimators=1000, subsample=0.8), xtrain_tfidf_ngram,train_y, name='XGB_N-Gram_TF-IDF', cv=CV_splits, fit_params=fit_params, dict_scoring=score_metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if xgboost_classifier:\n",
    "    fit_params={'early_stopping_rounds':10,\\\n",
    "                         'eval_set':[(xvalid_tfidf_ngram_chars, valid_y_sw)]}\n",
    "    df_results = df_results.append(report(XGBClassifier(n_estimators=1000, subsample=0.8), xtrain_tfidf_ngram_chars,train_y, name='XGB_CharLevel_TF-IDF', cv=CV_splits, fit_params=fit_params, dict_scoring=score_metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if xgboost_classifier:\n",
    "    fit_params={'early_stopping_rounds':10,\\\n",
    "                         'eval_set':[(valid_seq_x,valid_y)]}\n",
    "    df_results = df_results.append(report(XGBClassifier(n_estimators=1000, subsample=0.8), train_seq_x,train_y, name='XGB_Words', cv=CV_splits, fit_params=fit_params, dict_scoring=score_metrics))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><a id=\"part_7\"><h2>Deep Learning</h2></a></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Cohen’s kappa</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function [cohen_kappa_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.cohen_kappa_score.html#sklearn.metrics.cohen_kappa_score) computes [Cohen’s kappa](https://en.wikipedia.org/wiki/Cohen%27s_kappa) statistic. This measure is intended to compare labelings by different human annotators, not a classifier versus a ground truth.\n",
    "\n",
    "The kappa score (see docstring) is a number between -1 and 1. Scores above .8 are generally considered good agreement; zero or lower means no agreement (practically random labels).\n",
    "\n",
    "Kappa scores can be computed for binary or multiclass problems, but not for multilabel problems (except by manually computing a per-label score) and not for more than two annotators."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Balanced Accuracy</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the balanced accuracy\n",
    "\n",
    "The balanced accuracy in binary and multiclass classification problems to deal with imbalanced datasets. It is defined as the average of recall obtained on each class.\n",
    "\n",
    "The best value is 1 and the worst value is 0 when adjusted=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Early Stopping, Model saving, Class weight configuration</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = tf.keras.callbacks.EarlyStopping(monitor='loss', mode='auto', patience=3)\n",
    "check_p = tf.keras.callbacks.ModelCheckpoint(\"save_models/model.h5\", save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_w = {}\n",
    "for i in zip(range(len(class_weights)), class_weights):\n",
    "    class_w[i[0]] = i[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate_NN(model, X, y, X_test, y_test, callbacks,name=\"NN\", fit_params=None, scoring=None, n_splits=5):\n",
    "    '''\n",
    "    Function create a metric report automatically with cross_validate function.\n",
    "    @param model: (model) neural network model\n",
    "    @param X: (list or matrix or tensor) training X data\n",
    "    @param y: (list) label data \n",
    "    @param X_test: (list or matrix or tensor) testing X data\n",
    "    @param y_test: (list) label test data \n",
    "    @param callbacks: (function) callback function\n",
    "    @param name: (string) name of the model (default classifier)\n",
    "    @param fit_aparams: (dict) add parameters for model fitting \n",
    "    @param scoring: (dict) dictionary of metrics and names\n",
    "    @param n_splits: (int) number of fold for cross-validation (default 5)\n",
    "    @return: (pandas.dataframe) dataframe containing all the results of the metrics \n",
    "    for each fold and the mean and std for each of them\n",
    "    '''\n",
    "    # ---- Parameters initialisation\n",
    "    seed = 42\n",
    "    k = 1\n",
    "    np.random.seed(seed)\n",
    "    kfold = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
    "    \n",
    "    # Creation of list for each metric\n",
    "    if scoring==None:        # create a dictionary if none is passed\n",
    "        dic_scoring = {}\n",
    "    if scoring!=None:        # save the dict \n",
    "        dic_score = scoring.copy()\n",
    "        \n",
    "    dic_score[\"fit_time\"] = None   # initialisation for time fitting and scoring\n",
    "    dic_score[\"score_time\"] = None\n",
    "    scorer = {}\n",
    "    for i in dic_score.keys(): \n",
    "        scorer[i] = []\n",
    "        \n",
    "    \n",
    "    index = [\"Model\"]\n",
    "    results = [name]\n",
    "    # ---- Loop on k-fold for cross-valisation\n",
    "    for train, test in kfold.split(X, y):   # training NN on each fold \n",
    "        # create model\n",
    "        print(f\"k-fold : {k}\")\n",
    "        fit_start = time.time()\n",
    "        _model = model\n",
    "        _model.fit(X[train], y[train],\n",
    "                        epochs=1000, callbacks=[callbacks],\n",
    "                        validation_split=0.2, verbose=False)\n",
    "        \n",
    "        fit_end = time.time() - fit_start\n",
    "\n",
    "        _acc = _model.evaluate(X[test], y[test], verbose=0)\n",
    "\n",
    "        score_start = time.time()\n",
    "        y_pred = (model.predict(X_test)>0.5).astype(int)\n",
    "        score_end = time.time() - score_start\n",
    "\n",
    "        # ---- save each metric\n",
    "        for i in dic_score.keys():    # compute metrics \n",
    "            if i == \"fit_time\":\n",
    "                scorer[i].append(fit_end)\n",
    "                index.append(i+'_cv'+str(k))\n",
    "                results.append(fit_end)\n",
    "                continue\n",
    "            if i == \"score_time\":\n",
    "                scorer[i].append(score_end)\n",
    "                index.append(i+'_cv'+str(k))\n",
    "                results.append(score_end)\n",
    "                continue\n",
    "                \n",
    "            scorer[i].append(dic_score[i](y_test, y_pred))\n",
    "            index.append(\"test_\"+i+'_cv'+str(k))\n",
    "            results.append(scorer[i][-1])\n",
    "        \n",
    "        k+=1\n",
    "    \n",
    "    # Train test on the overall data\n",
    "    fit_start = time.time()\n",
    "    _model = model\n",
    "    _model.fit(X, y,epochs=1000, callbacks=[callbacks],\n",
    "                        validation_split=0.2, verbose=False)\n",
    "        \n",
    "    fit_end = time.time() - fit_start\n",
    "\n",
    "    _acc = _model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "    score_start = time.time()\n",
    "    y_pred = (model.predict(X_test)>0.5).astype(int)\n",
    "    score_end = time.time() - score_start\n",
    "    \n",
    "    # Compute mean and std for each metric\n",
    "    for i in scorer: \n",
    "        \n",
    "        results.append(np.mean(scorer[i]))\n",
    "        results.append(np.std(scorer[i]))\n",
    "        if i == \"fit_time\":\n",
    "            index.append(i+\"_mean\")\n",
    "            index.append(i+\"_std\")\n",
    "            continue\n",
    "        if i == \"score_time\":\n",
    "            index.append(i+\"_mean\")\n",
    "            index.append(i+\"_std\")\n",
    "            continue\n",
    "        \n",
    "        index.append(\"test_\"+i+\"_mean\")\n",
    "        index.append(\"test_\"+i+\"_std\")\n",
    "    # add metrics averall dataset on the dictionary \n",
    "    for i in dic_score.keys():    # compute metrics \n",
    "        if i == \"fit_time\":\n",
    "            scorer[i].append(fit_end)\n",
    "            index.append(i+'_overall')\n",
    "            results.append(fit_end)\n",
    "            continue\n",
    "        if i == \"score_time\":\n",
    "            scorer[i].append(score_end)\n",
    "            index.append(i+'_overall')\n",
    "            results.append(score_end)\n",
    "            continue\n",
    "                \n",
    "        scorer[i].append(dic_score[i](y_test, y_pred))\n",
    "        index.append(\"test_\"+i+'_overall')\n",
    "        results.append(scorer[i][-1])\n",
    "            \n",
    "            \n",
    "            \n",
    "    return pd.DataFrame(results, index=index).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><a id=\"part_7_1\"><h3>Shallow Neural Networks</h3></a></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shallow_neural_networks(word_index, label=labels, embedding_matrix=embedding_matrix, pre_trained=False):\n",
    "    '''\n",
    "    Function to generate a shallow neural network for binary or multiclass classification.\n",
    "    @param word_index: (matrix) unique token in corpus\n",
    "    @param label: (list) list of labels to determine if it,s a binary or multiclass\n",
    "    @param embedding_matrix: (matrix) matrix of integer for each word in the \n",
    "    @param pre_trained: (bool) determine if the model will use pretrained model\n",
    "    @return: (model) shallow neural network \n",
    "    '''\n",
    "    if pre_trained==False:\n",
    "        embedded = keras.layers.Embedding(len(word_index) + 1, 16)\n",
    "    else:\n",
    "        embedded = keras.layers.Embedding(len(word_index) + 1, 300, weights=[embedding_matrix], trainable=False)\n",
    "    \n",
    "    model = keras.Sequential([\n",
    "      embedded,\n",
    "      keras.layers.GlobalAveragePooling1D(),\n",
    "      \n",
    "      keras.layers.Dense(1 if len(label)<=2 else len(label), activation='sigmoid' if len(label)<=2 else \"softmax\")])\n",
    "\n",
    "    if len(label)==2: # binary\n",
    "        model.compile(optimizer='adam',\n",
    "              loss=tf.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "    else:  # multiclass \n",
    "        model.compile(optimizer='adam',\n",
    "              loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k-fold : 1\n",
      "k-fold : 2\n",
      "k-fold : 3\n",
      "k-fold : 4\n",
      "k-fold : 5\n",
      "CPU times: user 14min 19s, sys: 57.7 s, total: 15min 16s\n",
      "Wall time: 12min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if shallow_network:\n",
    "    df_results = df_results.append(cross_validate_NN(shallow_neural_networks(word_index, pre_trained=pre_trained), train_seq_x, train_y, valid_seq_x, valid_y, es, name=\"Shallow_NN_WE\", scoring=score_metrics, n_splits=CV_splits))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><a id=\"part_7_2\"><h3>Deep Neural Networks</h3></a></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deep_neural_networks(word_index, label=labels, embedding_matrix=embedding_matrix, pre_trained=False):\n",
    "    '''\n",
    "    Function to generate a deep neural network for binary or multiclass classification.\n",
    "    @param word_index: (matrix) unique token in corpus\n",
    "    @param label: (list) list of labels to determine if it,s a binary or multiclass\n",
    "    @param embedding_matrix: (matrix) matrix of integer for each word in the \n",
    "    @param pre_trained: (bool) determine if the model will use pretrained model\n",
    "    @return: (model) deep neural network \n",
    "    '''\n",
    "    if pre_trained==False:\n",
    "        embedded = keras.layers.Embedding(len(word_index) + 1, 50)\n",
    "    else:\n",
    "        embedded = keras.layers.Embedding(len(word_index) + 1, 300, weights=[embedding_matrix], trainable=False)\n",
    "    \n",
    "    model = keras.Sequential([\n",
    "      embedded,\n",
    "      keras.layers.GlobalAveragePooling1D(),\n",
    "      keras.layers.Dense(16, activation=\"relu\"),#tf.nn.swish),\n",
    "      keras.layers.Dense(1 if len(label)<=2 else len(label), activation='sigmoid' if len(label)<=2 else \"softmax\")])\n",
    "\n",
    "    if len(label)==2:\n",
    "        model.compile(optimizer='adam',\n",
    "              loss=tf.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "    else: \n",
    "        model.compile(optimizer=tf.optimizers.RMSprop(lr=1e-4),\n",
    "              loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "    #print(model.summary())\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k-fold : 1\n",
      "k-fold : 2\n",
      "k-fold : 3\n",
      "k-fold : 4\n",
      "k-fold : 5\n",
      "CPU times: user 18min 27s, sys: 1min 28s, total: 19min 55s\n",
      "Wall time: 6min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if deep_nn:\n",
    "    df_results = df_results.append(cross_validate_NN(deep_neural_networks(word_index, pre_trained=pre_trained), train_seq_x, train_y, valid_seq_x, valid_y, es, name=\"Deep_NN_WE\",scoring=score_metrics, n_splits=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Deep Neural Networks variation 1</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deep_neural_networks_var1(word_index, label=labels, embedding_matrix=embedding_matrix, pre_trained=False):\n",
    "    '''\n",
    "    Function to generate a deep neural network for binary or multiclass classification.\n",
    "    @param word_index: (matrix) unique token in corpus\n",
    "    @param label: (list) list of labels to determine if it,s a binary or multiclass\n",
    "    @param embedding_matrix: (matrix) matrix of integer for each word in the \n",
    "    @param pre_trained: (bool) determine if the model will use pretrained model\n",
    "    @return: (model) deep neural network \n",
    "    '''\n",
    "    if pre_trained==False:\n",
    "        embedded = keras.layers.Embedding(len(word_index) + 1, 100)\n",
    "    else:\n",
    "        embedded = keras.layers.Embedding(len(word_index) + 1, 300, weights=[embedding_matrix], trainable=False)\n",
    "    \n",
    "    model = keras.Sequential([\n",
    "      embedded,\n",
    "      keras.layers.GlobalAveragePooling1D(),\n",
    "      keras.layers.Dense(16, activation=\"relu\"),#tf.nn.swish),\n",
    "      keras.layers.Dense(16, activation=\"relu\"),#tf.nn.swish),\n",
    "      keras.layers.Dense(1  if len(label)<=2 else len(label), activation='sigmoid' if len(label)<=2 else \"softmax\")])\n",
    "\n",
    "    if len(label)==2:\n",
    "        model.compile(optimizer='adam',\n",
    "              loss=tf.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "    else: \n",
    "        model.compile(optimizer=tf.optimizers.RMSprop(lr=1e-4),\n",
    "              loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "    #print(model.summary())\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k-fold : 1\n",
      "k-fold : 2\n",
      "k-fold : 3\n",
      "k-fold : 4\n",
      "k-fold : 5\n",
      "CPU times: user 18min 21s, sys: 8min 50s, total: 27min 12s\n",
      "Wall time: 8min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if deep_nn:\n",
    "    df_results = df_results.append(cross_validate_NN(deep_neural_networks_var1(word_index, pre_trained=pre_trained), \n",
    "                                                     train_seq_x, train_y, valid_seq_x, valid_y, es, name=\"Deep_NN_var1_WE\",scoring=score_metrics, n_splits=CV_splits))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Deep Neural Networks variation 2</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deep_neural_networks_var2(word_index, label=labels, embedding_matrix=embedding_matrix, pre_trained=False):\n",
    "    '''\n",
    "    Function to generate a deep neural network for binary or multiclass classification.\n",
    "    @param word_index: (matrix) unique token in corpus\n",
    "    @param label: (list) list of labels to determine if it,s a binary or multiclass\n",
    "    @param embedding_matrix: (matrix) matrix of integer for each word in the \n",
    "    @param pre_trained: (bool) determine if the model will use pretrained model\n",
    "    @return: (model) deep neural network \n",
    "    '''\n",
    "    if pre_trained==False:\n",
    "        embedded = keras.layers.Embedding(len(word_index) + 1, 100)\n",
    "    else:\n",
    "        embedded = keras.layers.Embedding(len(word_index) + 1, 300, weights=[embedding_matrix], trainable=False)\n",
    "    \n",
    "    model = keras.Sequential([\n",
    "      embedded,\n",
    "      keras.layers.GlobalAveragePooling1D(),\n",
    "      keras.layers.Dense(32, activation='relu'),\n",
    "      keras.layers.Dense(16, activation='relu'),\n",
    "      keras.layers.Dense(1  if len(label)<=2 else len(label), activation='sigmoid' if len(label)<=2 else \"softmax\")])\n",
    "\n",
    "    if len(label)==2:\n",
    "        model.compile(optimizer='adam',\n",
    "              loss=tf.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "    else: \n",
    "        model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=1e-4),\n",
    "              loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "    #print(model.summary())\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if deep_nn:\n",
    "    df_results = df_results.append(cross_validate_NN(deep_neural_networks_var2(word_index, pre_trained=pre_trained), \n",
    "                                                     train_seq_x, train_y, valid_seq_x, valid_y, es, name=\"Deep_NN_var2_WE\",scoring=score_metrics, n_splits=CV_splits))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><a id=\"part_7_3\"><h3>Recurent Neural Network (RNN)</h3></a></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_rnn_model(word_index, label=labels, embedding_matrix=embedding_matrix, pre_trained=False):\n",
    "    '''\n",
    "    Function to generate a recurrent neural network for binary or multiclass classification.\n",
    "    @param word_index: (matrix) unique token in corpus\n",
    "    @param label: (list) list of labels to determine if it,s a binary or multiclass\n",
    "    @param embedding_matrix: (matrix) matrix of integer for each word in the \n",
    "    @param pre_trained: (bool) determine if the model will use pretrained model\n",
    "    @return: (model) recurrent neural network \n",
    "    '''\n",
    "    if pre_trained==False:\n",
    "        embedded = keras.layers.Embedding(len(word_index) + 1, 100)\n",
    "    else:\n",
    "        embedded = keras.layers.Embedding(len(word_index) + 1, 300, weights=[embedding_matrix], trainable=False)\n",
    "    \n",
    "    model = keras.Sequential([\n",
    "    embedded,\n",
    "    keras.layers.SimpleRNN(40, return_sequences=True, activation='tanh'),\n",
    "    keras.layers.SimpleRNN(40, return_sequences=True, activation='tanh'),\n",
    "    keras.layers.SimpleRNN(40, return_sequences=True, activation='tanh'),\n",
    "    keras.layers.SimpleRNN(40, activation=\"tanh\"),\n",
    "    keras.layers.Dense(1 if len(label)<=2 else len(label), activation='sigmoid' if len(label)<=2 else \"softmax\")])\n",
    "\n",
    "    if len(label)==2:\n",
    "        model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=1e-4),\n",
    "              loss=tf.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "    else: \n",
    "        model.compile(optimizer='adam',\n",
    "              loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "    #print(model.summary())\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if rnn:\n",
    "    df_results = df_results.append(cross_validate_NN(create_rnn_model(word_index, pre_trained=pre_trained), \n",
    "                                                     train_seq_x, train_y, valid_seq_x, valid_y, es, name=\"RNN_WE\",scoring=score_metrics, n_splits=CV_splits))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><a id=\"part_7_4\"><h3>Convolutional Neural Network (CNN)</h3></a></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_conv_model(word_index, label=labels, embedding_matrix=embedding_matrix, pre_trained=False):\n",
    "    '''\n",
    "    Function to generate a convulational neural network for binary or multiclass classification.\n",
    "    @param word_index: (matrix) unique token in corpus\n",
    "    @param label: (list) list of labels to determine if it,s a binary or multiclass\n",
    "    @param embedding_matrix: (matrix) matrix of integer for each word in the \n",
    "    @param pre_trained: (bool) determine if the model will use pretrained model\n",
    "    @return: (model) convulational neural network \n",
    "    '''\n",
    "    if pre_trained==False:\n",
    "        embedded = keras.layers.Embedding(len(word_index) +1, 100)\n",
    "    else:\n",
    "        embedded = keras.layers.Embedding(len(word_index) + 1, 300, weights=[embedding_matrix], trainable=False)\n",
    "    \n",
    "    model = keras.Sequential([\n",
    "    embedded,\n",
    "    keras.layers.Conv1D(100, 5, activation=\"relu\"),#tf.nn.swish), # padding='same'\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.MaxPooling1D(pool_size=4),\n",
    "    keras.layers.Conv1D(64, 5, activation=\"relu\"),#tf.nn.swish),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.MaxPooling1D(pool_size=4),\n",
    "    keras.layers.Conv1D(32, 5, activation=\"relu\"),#tf.nn.swish),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.GlobalMaxPooling1D(),\n",
    "\n",
    "    keras.layers.Dense(1 if len(label)<=2 else len(label), activation='sigmoid' if len(label)<=2 else \"softmax\")])\n",
    "\n",
    "    if len(label)==2:\n",
    "        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "              loss=tf.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "    else: \n",
    "        model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=1e-4),\n",
    "              loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "    #print(model.summary())\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k-fold : 1\n",
      "k-fold : 2\n",
      "k-fold : 3\n",
      "k-fold : 4\n",
      "k-fold : 5\n",
      "CPU times: user 52min 38s, sys: 7min 48s, total: 1h 26s\n",
      "Wall time: 17min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if cnn:\n",
    "    df_results = df_results.append(cross_validate_NN(create_conv_model(word_index, pre_trained=pre_trained), \n",
    "                                                     train_seq_x, train_y, valid_seq_x, valid_y, es, name=\"CNN_WE\",scoring=score_metrics, n_splits=CV_splits))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><a id=\"part_7_4\"><h3>Long Short Term Memory (LSTM)</h3></a></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lstm_model(word_index, label=labels, embedding_matrix=embedding_matrix, pre_trained=False):\n",
    "    '''\n",
    "    Function to generate a lstm for binary or multiclass classification.\n",
    "    @param word_index: (matrix) unique token in corpus\n",
    "    @param label: (list) list of labels to determine if it,s a binary or multiclass\n",
    "    @param embedding_matrix: (matrix) matrix of integer for each word in the \n",
    "    @param pre_trained: (bool) determine if the model will use pretrained model\n",
    "    @return: (model)lstm \n",
    "    '''\n",
    "    if pre_trained==False:\n",
    "        embedded = keras.layers.Embedding(len(word_index) +1, 100)\n",
    "    else:\n",
    "        embedded = keras.layers.Embedding(len(word_index)+1, 300, weights=[embedding_matrix], trainable=False)\n",
    "    \n",
    "    model = keras.Sequential([\n",
    "    embedded,\n",
    "    keras.layers.LSTM(32, activation='tanh'),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(1 if len(label)<=2 else len(label), activation='sigmoid' if len(label)<=2 else \"softmax\")])\n",
    "\n",
    "    if len(label)==2:\n",
    "        model.compile(optimizer='adam',\n",
    "              loss=tf.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "    else: \n",
    "        model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=1e-4),\n",
    "              loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "    #print(model.summary())\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if lstm:\n",
    "    df_results = df_results.append(cross_validate_NN(create_lstm_model(word_index, pre_trained=pre_trained), \n",
    "                                                     train_seq_x, train_y, valid_seq_x, valid_y, es, name=\"LSTM_WE\",scoring=score_metrics, n_splits=CV_splits))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><a id=\"part_7_6\"><h3>CNN – LSTM</h3></a></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn_lstm_model(word_index, label=labels, embedding_matrix=embedding_matrix, pre_trained=False):\n",
    "    '''\n",
    "    Function to generate a convulational neural network lstm for binary or multiclass classification.\n",
    "    @param word_index: (matrix) unique token in corpus\n",
    "    @param label: (list) list of labels to determine if it,s a binary or multiclass\n",
    "    @param embedding_matrix: (matrix) matrix of integer for each word in the \n",
    "    @param pre_trained: (bool) determine if the model will use pretrained model\n",
    "    @return: (model) convulational neural network lstm\n",
    "    '''\n",
    "    if pre_trained==False:\n",
    "        embedded = keras.layers.Embedding(len(word_index) + 1, 100)\n",
    "    else:\n",
    "        embedded = keras.layers.Embedding(len(word_index) + 1, 300, weights=[embedding_matrix], trainable=False)\n",
    "    \n",
    "    model = keras.Sequential([\n",
    "    embedded,\n",
    "    keras.layers.Conv1D(128, 5, activation='relu'),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.MaxPooling1D(pool_size=4),\n",
    "    keras.layers.LSTM(32, activation='tanh'),\n",
    "    keras.layers.Dense(1 if len(label)<=2 else len(label), activation='sigmoid' if len(label)<=2 else \"softmax\")])\n",
    "\n",
    "    if len(label)==2:\n",
    "        model.compile(optimizer='adam',\n",
    "              loss=tf.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "    else: \n",
    "        model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=1e-4),\n",
    "              loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "    #print(model.summary())\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if cnn_lstm:\n",
    "    df_results = df_results.append(cross_validate_NN(create_cnn_lstm_model(word_index, pre_trained=pre_trained), \n",
    "                                                     train_seq_x, train_y, valid_seq_x, valid_y, es,name=\"CNN_LSTM_WE\", scoring=score_metrics, n_splits=CV_splits))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><a id=\"part_7_7\"><h3>CNN – GRU</h3></a></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn_gru_model(word_index, label=labels, embedding_matrix=embedding_matrix, pre_trained=False):\n",
    "    '''\n",
    "    Function to generate a convulational neural network GRU for binary or multiclass classification.\n",
    "    @param word_index: (matrix) unique token in corpus\n",
    "    @param label: (list) list of labels to determine if it,s a binary or multiclass\n",
    "    @param embedding_matrix: (matrix) matrix of integer for each word in the \n",
    "    @param pre_trained: (bool) determine if the model will use pretrained model\n",
    "    @return: (model) convulational neural network GRU\n",
    "    '''\n",
    "    if pre_trained==False:\n",
    "        embedded = keras.layers.Embedding(len(word_index) + 1, 100)\n",
    "    else:\n",
    "        embedded = keras.layers.Embedding(len(word_index) + 1, 300, weights=[embedding_matrix], trainable=False)\n",
    "    \n",
    "    model = keras.Sequential([\n",
    "    embedded,\n",
    "    keras.layers.Conv1D(128, 5, activation='relu'),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.MaxPooling1D(pool_size=4),\n",
    "    keras.layers.GRU(32, activation='tanh'),\n",
    "    keras.layers.Dense(1 if len(label)<=2 else len(label), activation='sigmoid' if len(label)<=2 else \"softmax\")])\n",
    "\n",
    "    if len(label)==2:\n",
    "        model.compile(optimizer='adam',\n",
    "              loss=tf.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "    else: \n",
    "        model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=1e-4),\n",
    "              loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "    #print(model.summary())\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if cnn_gru:\n",
    "    df_results = df_results.append(cross_validate_NN(create_cnn_gru_model(word_index, pre_trained=pre_trained), \n",
    "                                                     train_seq_x, train_y, valid_seq_x, valid_y, es, name=\"CNN_GRU_WE\", scoring=score_metrics, n_splits=CV_splits))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><a id=\"part_7_8\"><h3>Gated Recurrent Units – GRU</h3></a></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.keras.layers.GRU(\n",
    "    units, activation='tanh', recurrent_activation='sigmoid', use_bias=True,\n",
    "    kernel_initializer='glorot_uniform', recurrent_initializer='orthogonal',\n",
    "    bias_initializer='zeros', kernel_regularizer=None, recurrent_regularizer=None,\n",
    "    bias_regularizer=None, activity_regularizer=None, kernel_constraint=None,\n",
    "    recurrent_constraint=None, bias_constraint=None, dropout=0.0,\n",
    "    recurrent_dropout=0.0, implementation=2, return_sequences=False,\n",
    "    return_state=False, go_backwards=False, stateful=False, unroll=False,\n",
    "    time_major=False, reset_after=True, **kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gru_model(word_index, label=labels, embedding_matrix=embedding_matrix, pre_trained=False):\n",
    "    '''\n",
    "    Function to generate a GRU for binary or multiclass classification.\n",
    "    @param word_index: (matrix) unique token in corpus\n",
    "    @param label: (list) list of labels to determine if it,s a binary or multiclass\n",
    "    @param embedding_matrix: (matrix) matrix of integer for each word in the \n",
    "    @param pre_trained: (bool) determine if the model will use pretrained model\n",
    "    @return: (model) GRU\n",
    "    '''\n",
    "    if pre_trained==False:\n",
    "        embedded = keras.layers.Embedding(len(word_index) + 1, 100)\n",
    "    else:\n",
    "        embedded = keras.layers.Embedding(len(word_index) + 1, 300, weights=[embedding_matrix], trainable=False)\n",
    "    \n",
    "    model = keras.Sequential([\n",
    "    embedded,\n",
    "    keras.layers.GRU(32, activation='tanh'),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(1 if len(label)<=2 else len(label), activation='sigmoid' if len(label)<=2 else \"softmax\")])\n",
    "\n",
    "    if len(label)==2:\n",
    "        model.compile(optimizer='adam',\n",
    "              loss=tf.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "    else: \n",
    "        model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=1e-4),\n",
    "              loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "    #print(model.summary())\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if gru:\n",
    "    df_results = df_results.append(cross_validate_NN(create_gru_model(word_index, pre_trained=pre_trained), \n",
    "                                                     train_seq_x, train_y, valid_seq_x, valid_y, es, name=\"GRU_WE\", scoring=score_metrics, n_splits=CV_splits))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><a id=\"part_7_9\"><h3>Bidirectional RNN</h3></a></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bidirec_rnn_model(word_index, label=labels, embedding_matrix=embedding_matrix, pre_trained=False):\n",
    "    '''\n",
    "    Function to generate a bidirectionnal rnn for binary or multiclass classification.\n",
    "    @param word_index: (matrix) unique token in corpus\n",
    "    @param label: (list) list of labels to determine if it,s a binary or multiclass\n",
    "    @param embedding_matrix: (matrix) matrix of integer for each word in the \n",
    "    @param pre_trained: (bool) determine if the model will use pretrained model\n",
    "    @return: (model) bidirectionnal rnn\n",
    "    '''\n",
    "    if pre_trained==False:\n",
    "        embedded = keras.layers.Embedding(len(word_index) + 1, 100)\n",
    "    else:\n",
    "        embedded = keras.layers.Embedding(len(word_index) + 1, 300, weights=[embedding_matrix], trainable=False)\n",
    "    \n",
    "    model = keras.Sequential([\n",
    "    embedded,\n",
    "    keras.layers.Bidirectional(keras.layers.SimpleRNN(32, return_sequences=True, activation=\"tanh\")),\n",
    "    keras.layers.Bidirectional(keras.layers.SimpleRNN(32, return_sequences=True, activation=\"tanh\")),\n",
    "    keras.layers.Bidirectional(keras.layers.SimpleRNN(32, return_sequences=True, activation=\"tanh\")),\n",
    "    keras.layers.Bidirectional(keras.layers.SimpleRNN(32, activation=\"tanh\")),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(1 if len(label)<=2 else len(label), activation='sigmoid' if len(label)<=2 else \"softmax\")])\n",
    "\n",
    "    if len(label)==2:\n",
    "        model.compile(optimizer='adam',\n",
    "              loss=tf.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "    else: \n",
    "        model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=1e-4),\n",
    "              loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "    #print(model.summary())\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if bidirectional_rnn:\n",
    "    df_results = df_results.append(cross_validate_NN(create_bidirec_rnn_model(word_index, pre_trained=pre_trained), \n",
    "                                                     train_seq_x, train_y, valid_seq_x, valid_y, es, name=\"BiRNN_WE\",scoring=score_metrics, n_splits=CV_splits))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><a id=\"part_7_10\"><h3>Bidirectional LSTM</h3></a></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bidirec_lstm_model(word_index, label=labels, embedding_matrix=embedding_matrix, pre_trained=False):\n",
    "    '''\n",
    "    Function to generate a bidirectionnal lstm for binary or multiclass classification.\n",
    "    @param word_index: (matrix) unique token in corpus\n",
    "    @param label: (list) list of labels to determine if it,s a binary or multiclass\n",
    "    @param embedding_matrix: (matrix) matrix of integer for each word in the \n",
    "    @param pre_trained: (bool) determine if the model will use pretrained model\n",
    "    @return: (model) bidirectionnal lstm\n",
    "    '''\n",
    "    if pre_trained==False:\n",
    "        embedded = keras.layers.Embedding(len(word_index) + 1, 100)\n",
    "    else:\n",
    "        embedded = keras.layers.Embedding(len(word_index) + 1, 300, weights=[embedding_matrix], trainable=False)\n",
    "    \n",
    "    model = keras.Sequential([\n",
    "    embedded,\n",
    "    keras.layers.Bidirectional(keras.layers.LSTM(32, activation=\"tanh\")),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(1 if len(label)<=2 else len(label), activation='sigmoid' if len(label)<=2 else \"softmax\")])\n",
    "\n",
    "    if len(label)==2:\n",
    "        model.compile(optimizer='adam',\n",
    "              loss=tf.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "    else: \n",
    "        model.compile(optimizer=tf.keras.optimizers.RMSprop(1e-4),\n",
    "              loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "    #print(model.summary())\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if bidirectional_lstm:\n",
    "    df_results = df_results.append(cross_validate_NN(create_bidirec_lstm_model(word_index, pre_trained=pre_trained), \n",
    "                                                     train_seq_x, train_y, valid_seq_x, valid_y, es, name=\"BiLSTM_WE\",scoring=score_metrics, n_splits=CV_splits))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><a id=\"part_7_11\"><h3>Bidirectional GRU</h3></a></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bidirec_gru_model(word_index, label=labels, embedding_matrix=embedding_matrix, pre_trained=False):\n",
    "    '''\n",
    "    Function to generate a bidirectionnal gru for binary or multiclass classification.\n",
    "    @param word_index: (matrix) unique token in corpus\n",
    "    @param label: (list) list of labels to determine if it,s a binary or multiclass\n",
    "    @param embedding_matrix: (matrix) matrix of integer for each word in the \n",
    "    @param pre_trained: (bool) determine if the model will use pretrained model\n",
    "    @return: (model) bidirectionnal gru\n",
    "    '''\n",
    "    if pre_trained==False:\n",
    "        embedded = keras.layers.Embedding(len(word_index) + 1, 100)\n",
    "    else:\n",
    "        embedded = keras.layers.Embedding(len(word_index) + 1, 300, weights=[embedding_matrix], trainable=False)\n",
    "    \n",
    "    model = keras.Sequential([\n",
    "    embedded,\n",
    "    keras.layers.Bidirectional(keras.layers.GRU(32, activation=\"tanh\")),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(1 if len(label)<=2 else len(label), activation='sigmoid' if len(label)<=2 else \"softmax\")])\n",
    "\n",
    "    if len(label)==2:\n",
    "        model.compile(optimizer='adam',\n",
    "              loss=tf.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "    else: \n",
    "        model.compile(optimizer=tf.keras.optimizers.RMSprop(1e-4),\n",
    "              loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "    #print(model.summary())\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if bidirectional_gru:\n",
    "    df_results = df_results.append(cross_validate_NN(create_bidirec_gru_model(word_index, pre_trained=pre_trained), \n",
    "                                                     train_seq_x, train_y, valid_seq_x, valid_y, es, name=\"BiGRU_WE\",scoring=score_metrics, n_splits=CV_splits))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><a id=\"part_7_12\"><h3>Recurrent Convolutional Neural Network (RCNN)</h3></a></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_rcnn(X, word_index, label=labels, embedding_matrix=embedding_matrix, pre_trained=False):\n",
    "    '''\n",
    "    Function to generate a rcnn for binary or multiclass classification.\n",
    "    @param word_index: (matrix) unique token in corpus\n",
    "    @param label: (list) list of labels to determine if it,s a binary or multiclass\n",
    "    @param embedding_matrix: (matrix) matrix of integer for each word in the \n",
    "    @param pre_trained: (bool) determine if the model will use pretrained model\n",
    "    @return: (model)  rcnn\n",
    "    '''\n",
    "    if pre_trained==False:\n",
    "        embedded = keras.layers.Embedding(len(word_index) + 1, 100)\n",
    "    else:\n",
    "        embedded = keras.layers.Embedding(len(word_index) + 1, 300,input_length=X.shape[1], weights=[embedding_matrix], trainable=False)\n",
    "    \n",
    "    model = keras.Sequential([\n",
    "    embedded,\n",
    "    keras.layers.SpatialDropout1D(0.3),\n",
    "    keras.layers.Bidirectional(keras.layers.GRU(32,return_sequences=True, activation=\"tanh\")),\n",
    "    keras.layers.Convolution1D(32, 3, activation=\"tanh\"),\n",
    "    keras.layers.GlobalMaxPool1D(),\n",
    "    keras.layers.Dense(25, activation=\"relu\"),\n",
    "    keras.layers.Dropout(0.25),\n",
    "    keras.layers.Dense(1 if len(label)<=2 else len(label), activation='sigmoid' if len(label)<=2 else \"softmax\")])\n",
    "\n",
    "    if len(label)==2:\n",
    "        model.compile(optimizer='adam',\n",
    "              loss=tf.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "    else: \n",
    "        model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=1e-4),\n",
    "              loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "    #print(model.summary())\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if rcnn:\n",
    "    df_results = df_results.append(cross_validate_NN(create_rcnn(train_seq_x, word_index, pre_trained=pre_trained), \n",
    "                                                     train_seq_x, train_y, valid_seq_x, valid_y, es, name=\"RCNN_WE\",scoring=score_metrics, n_splits=CV_splits))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Recurrent Convolutional Neural Network variation 1</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_rcnn_var1(word_index, label=labels, embedding_matrix=embedding_matrix, pre_trained=False):\n",
    "    '''\n",
    "    Function to generate a rcnn for binary or multiclass classification.\n",
    "    @param word_index: (matrix) unique token in corpus\n",
    "    @param label: (list) list of labels to determine if it,s a binary or multiclass\n",
    "    @param embedding_matrix: (matrix) matrix of integer for each word in the \n",
    "    @param pre_trained: (bool) determine if the model will use pretrained model\n",
    "    @return: (model)  rcnn\n",
    "    '''\n",
    "    if pre_trained==False:\n",
    "        embedded = keras.layers.Embedding(len(word_index) + 1, 100)\n",
    "    else:\n",
    "        embedded = keras.layers.Embedding(len(word_index) + 1, 300, weights=[embedding_matrix], trainable=False)\n",
    "    \n",
    "    model = keras.Sequential([\n",
    "    embedded,\n",
    "    keras.layers.SpatialDropout1D(0.3),\n",
    "    keras.layers.Bidirectional(keras.layers.LSTM(32,return_sequences=True, activation=\"tanh\")),\n",
    "    keras.layers.Convolution1D(32, 3, activation=\"relu\"),\n",
    "    keras.layers.GlobalMaxPool1D(),\n",
    "    keras.layers.Dense(25, activation=\"relu\"),\n",
    "    keras.layers.Dropout(0.25),\n",
    "    keras.layers.Dense(1 if len(label)<=2 else len(label), activation='sigmoid' if len(label)<=2 else \"softmax\")])\n",
    "\n",
    "    if len(label)==2:\n",
    "        model.compile(optimizer='adam',\n",
    "              loss=tf.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "    else: \n",
    "        model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=1e-4),\n",
    "              loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "    #print(model.summary())\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if rcnn:\n",
    "    df_results = df_results.append(cross_validate_NN(create_rcnn_var1(word_index, pre_trained=pre_trained), \n",
    "                                                     train_seq_x, train_y, valid_seq_x, valid_y, es, name=\"RCNN_var1_WE\",scoring=score_metrics, n_splits=CV_splits))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Recurrent Convulational Neural Network variation 2</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_rcnn_var2(word_index, label=labels, embedding_matrix=embedding_matrix, pre_trained=False):\n",
    "    '''\n",
    "    Function to generate a rcnn for binary or multiclass classification.\n",
    "    @param word_index: (matrix) unique token in corpus\n",
    "    @param label: (list) list of labels to determine if it,s a binary or multiclass\n",
    "    @param embedding_matrix: (matrix) matrix of integer for each word in the \n",
    "    @param pre_trained: (bool) determine if the model will use pretrained model\n",
    "    @return: (model)  rcnn\n",
    "    '''\n",
    "    if pre_trained==False:\n",
    "        embedded = keras.layers.Embedding(len(word_index) + 1, 100)\n",
    "    else:\n",
    "        embedded = keras.layers.Embedding(len(word_index) + 1, 300, weights=[embedding_matrix], trainable=False)\n",
    "    \n",
    "    model = keras.Sequential([\n",
    "    embedded,\n",
    "    keras.layers.SpatialDropout1D(0.3),\n",
    "    keras.layers.Bidirectional(keras.layers.GRU(32,return_sequences=True, activation=\"tanh\")),\n",
    "    keras.layers.Bidirectional(keras.layers.GRU(32,return_sequences=True, activation=\"tanh\")),\n",
    "    keras.layers.Convolution1D(32, 3, activation=\"relu\"),\n",
    "    keras.layers.GlobalMaxPool1D(),\n",
    "    keras.layers.Dense(25, activation=\"relu\"),\n",
    "    keras.layers.Dropout(0.25),\n",
    "    keras.layers.Dense(1 if len(label)<=2 else len(label), activation='sigmoid' if len(label)<=2 else \"softmax\")])\n",
    "\n",
    "    if len(label)==2:\n",
    "        model.compile(optimizer='adam',\n",
    "              loss=tf.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "    else: \n",
    "        model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=1e-4),\n",
    "              loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "    #print(model.summary())\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if rcnn:\n",
    "    df_results = df_results.append(cross_validate_NN(create_rcnn_var2(word_index, pre_trained=pre_trained), \n",
    "                                                     train_seq_x, train_y, valid_seq_x, valid_y, es, name=\"RCNN_var2_WE\",scoring=score_metrics, n_splits=CV_splits))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Recurrent Convulational Neural Network variation 3</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_rcnn_var3(word_index, label=labels, embedding_matrix=embedding_matrix, pre_trained=False):\n",
    "    if pre_trained==False:\n",
    "        embedded = keras.layers.Embedding(len(word_index) + 1, 100)\n",
    "    else:\n",
    "        embedded = keras.layers.Embedding(len(word_index) + 1, 300, weights=[embedding_matrix], trainable=False)\n",
    "    \n",
    "    model = keras.Sequential([\n",
    "    embedded,\n",
    "    keras.layers.SpatialDropout1D(0.3),\n",
    "    keras.layers.Bidirectional(keras.layers.GRU(32,return_sequences=True, activation=\"tanh\")),\n",
    "    keras.layers.Bidirectional(keras.layers.LSTM(32,return_sequences=True, activation=\"tanh\")),\n",
    "    keras.layers.Convolution1D(32, 3, activation=\"relu\"),\n",
    "    keras.layers.GlobalMaxPool1D(),\n",
    "    keras.layers.Dense(25, activation=\"relu\"),\n",
    "    keras.layers.Dropout(0.25),\n",
    "    keras.layers.Dense(1 if len(label)<=2 else len(label), activation='sigmoid' if len(label)<=2 else \"softmax\")])\n",
    "\n",
    "    if len(label)==2:\n",
    "        model.compile(optimizer='adam',\n",
    "              loss=tf.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "    else: \n",
    "        model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=1e-4),\n",
    "              loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "    #print(model.summary())\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if rcnn:\n",
    "    df_results = df_results.append(cross_validate_NN(create_rcnn_var3(word_index, pre_trained=pre_trained), \n",
    "                                                     train_seq_x, train_y, valid_seq_x, valid_y, es, name=\"RCNN_var3_WE\",scoring=score_metrics, n_splits=CV_splits))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><a id=\"part_7_13\"><h3>Transformers</h3></a></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tutorial available on Keras documentation, code example written by Apoorv Nandan (<a href=\"https://keras.io/examples/nlp/text_classification_with_transformer/\">source: kears.io</a>)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadSelfAttention(layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads=8):\n",
    "        super(MultiHeadSelfAttention, self).__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        if embed_dim % num_heads != 0:\n",
    "            raise ValueError(\n",
    "                f\"embedding dimension = {embed_dim} should be divisible by number of heads = {num_heads}\"\n",
    "            )\n",
    "        self.projection_dim = embed_dim // num_heads\n",
    "        self.query_dense = layers.Dense(embed_dim)\n",
    "        self.key_dense = layers.Dense(embed_dim)\n",
    "        self.value_dense = layers.Dense(embed_dim)\n",
    "        self.combine_heads = layers.Dense(embed_dim)\n",
    "\n",
    "    def attention(self, query, key, value):\n",
    "        score = tf.matmul(query, key, transpose_b=True)\n",
    "        dim_key = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "        scaled_score = score / tf.math.sqrt(dim_key)\n",
    "        weights = tf.nn.softmax(scaled_score, axis=-1)\n",
    "        output = tf.matmul(weights, value)\n",
    "        return output, weights\n",
    "\n",
    "    def separate_heads(self, x, batch_size):\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.projection_dim))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # x.shape = [batch_size, seq_len, embedding_dim]\n",
    "        batch_size = tf.shape(inputs)[0]\n",
    "        query = self.query_dense(inputs)  # (batch_size, seq_len, embed_dim)\n",
    "        key = self.key_dense(inputs)  # (batch_size, seq_len, embed_dim)\n",
    "        value = self.value_dense(inputs)  # (batch_size, seq_len, embed_dim)\n",
    "        query = self.separate_heads(\n",
    "            query, batch_size\n",
    "        )  # (batch_size, num_heads, seq_len, projection_dim)\n",
    "        key = self.separate_heads(\n",
    "            key, batch_size\n",
    "        )  # (batch_size, num_heads, seq_len, projection_dim)\n",
    "        value = self.separate_heads(\n",
    "            value, batch_size\n",
    "        )  # (batch_size, num_heads, seq_len, projection_dim)\n",
    "        attention, weights = self.attention(query, key, value)\n",
    "        attention = tf.transpose(\n",
    "            attention, perm=[0, 2, 1, 3]\n",
    "        )  # (batch_size, seq_len, num_heads, projection_dim)\n",
    "        concat_attention = tf.reshape(\n",
    "            attention, (batch_size, -1, self.embed_dim)\n",
    "        )  # (batch_size, seq_len, embed_dim)\n",
    "        output = self.combine_heads(\n",
    "            concat_attention\n",
    "        )  # (batch_size, seq_len, embed_dim)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.att = MultiHeadSelfAttention(embed_dim, num_heads)\n",
    "        self.ffn = keras.Sequential(\n",
    "            [layers.Dense(ff_dim, activation=tf.nn.swish), layers.Dense(embed_dim),]\n",
    "        )\n",
    "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = layers.Dropout(rate)\n",
    "        self.dropout2 = layers.Dropout(rate)\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        attn_output = self.att(inputs)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenAndPositionEmbedding(layers.Layer):\n",
    "    def __init__(self, maxlen, vocab_size, emded_dim):\n",
    "        super(TokenAndPositionEmbedding, self).__init__()\n",
    "        self.token_emb = layers.Embedding(input_dim=vocab_size, output_dim=emded_dim)\n",
    "        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=emded_dim)\n",
    "\n",
    "    def call(self, x):\n",
    "        maxlen = tf.shape(x)[-1]\n",
    "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
    "        positions = self.pos_emb(positions)\n",
    "        x = self.token_emb(x)\n",
    "        return x + positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformers_classifier(word_index, label=labels):\n",
    "    '''\n",
    "    Function to generate a rcnn for binary or multiclass classification.\n",
    "    @param word_index: (matrix) unique token in corpus\n",
    "    @param label: (list) list of labels to determine if it,s a binary or multiclass\n",
    "    @param embedding_matrix: (matrix) matrix of integer for each word in the \n",
    "    @param pre_trained: (bool) determine if the model will use pretrained model\n",
    "    @return: (model)  rcnn\n",
    "    '''\n",
    "    embed_dim = 32  # Embedding size for each token\n",
    "    num_heads = 2  # Number of attention heads\n",
    "    ff_dim = 32  # Hidden layer size in feed forward network inside transformer\n",
    "    vocab_size = len(word_index)+1\n",
    "    maxlen = 300\n",
    "    inputs = layers.Input(shape=(maxlen,))\n",
    "    embedding_layer = TokenAndPositionEmbedding(maxlen, vocab_size, embed_dim)\n",
    "    x = embedding_layer(inputs)\n",
    "    transformer_block = TransformerBlock(embed_dim, num_heads, ff_dim)\n",
    "    x = transformer_block(x)\n",
    "    x = layers.GlobalAveragePooling1D()(x)\n",
    "    x = layers.Dropout(0.1)(x)\n",
    "    x = layers.Dense(20, activation=\"relu\")(x) #tf.nn.swish\n",
    "    x = layers.Dropout(0.1)(x)\n",
    "    #outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "    \n",
    "    outputs = keras.layers.Dense(1 if len(label)<=2 else len(label), activation='sigmoid' if len(label)<=2 else \"softmax\")(x)\n",
    "\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    if len(label)==2:\n",
    "        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "              loss=tf.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "    else: \n",
    "        model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=1e-4),\n",
    "              loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "    print(model.summary())\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 300)]             0         \n",
      "_________________________________________________________________\n",
      "token_and_position_embedding (None, 300, 32)           1395904   \n",
      "_________________________________________________________________\n",
      "transformer_block_2 (Transfo (None, 300, 32)           6464      \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_6 ( (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 20)                660       \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 1,403,049\n",
      "Trainable params: 1,403,049\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "k-fold : 1\n",
      "k-fold : 2\n",
      "k-fold : 3\n",
      "k-fold : 4\n",
      "k-fold : 5\n"
     ]
    }
   ],
   "source": [
    "if transformers:\n",
    "    \n",
    "    df_results = df_results.append(cross_validate_NN(transformers_classifier(word_index, label=labels), \n",
    "                                                     train_seq_x, train_y, valid_seq_x, valid_y, es, name=\"transformers\",scoring=score_metrics, n_splits=CV_splits))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><a id=\"part_8\"><h2>Results</h2></a></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>test_acc_mean</th>\n",
       "      <th>test_acc_std</th>\n",
       "      <th>test_prec_mean</th>\n",
       "      <th>test_prec_std</th>\n",
       "      <th>test_recall_mean</th>\n",
       "      <th>test_recall_std</th>\n",
       "      <th>test_f1-score_mean</th>\n",
       "      <th>test_f1-score_std</th>\n",
       "      <th>test_cohens_kappa_mean</th>\n",
       "      <th>test_cohens_kappa_std</th>\n",
       "      <th>test_matthews_corrcoef_mean</th>\n",
       "      <th>test_matthews_corrcoef_std</th>\n",
       "      <th>test_roc_auc_mean</th>\n",
       "      <th>test_roc_auc_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SGD_WordLevel_TF-IDF</td>\n",
       "      <td>0.904533</td>\n",
       "      <td>0.003558</td>\n",
       "      <td>0.903289</td>\n",
       "      <td>0.005953</td>\n",
       "      <td>0.925551</td>\n",
       "      <td>0.006072</td>\n",
       "      <td>0.914256</td>\n",
       "      <td>0.003150</td>\n",
       "      <td>0.806615</td>\n",
       "      <td>0.007254</td>\n",
       "      <td>0.806987</td>\n",
       "      <td>0.007162</td>\n",
       "      <td>0.902204</td>\n",
       "      <td>0.003758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>LR_Count_Vectors</td>\n",
       "      <td>0.902220</td>\n",
       "      <td>0.006502</td>\n",
       "      <td>0.896764</td>\n",
       "      <td>0.008218</td>\n",
       "      <td>0.929219</td>\n",
       "      <td>0.003529</td>\n",
       "      <td>0.912692</td>\n",
       "      <td>0.005567</td>\n",
       "      <td>0.801666</td>\n",
       "      <td>0.013313</td>\n",
       "      <td>0.802346</td>\n",
       "      <td>0.013113</td>\n",
       "      <td>0.899227</td>\n",
       "      <td>0.006905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>XGB_Count_Vectors</td>\n",
       "      <td>0.900677</td>\n",
       "      <td>0.002894</td>\n",
       "      <td>0.888951</td>\n",
       "      <td>0.006372</td>\n",
       "      <td>0.936449</td>\n",
       "      <td>0.005731</td>\n",
       "      <td>0.912047</td>\n",
       "      <td>0.002351</td>\n",
       "      <td>0.798154</td>\n",
       "      <td>0.006024</td>\n",
       "      <td>0.799669</td>\n",
       "      <td>0.005712</td>\n",
       "      <td>0.896712</td>\n",
       "      <td>0.003317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LR_WordLevel_TF-IDF</td>\n",
       "      <td>0.899905</td>\n",
       "      <td>0.004583</td>\n",
       "      <td>0.892538</td>\n",
       "      <td>0.005471</td>\n",
       "      <td>0.929974</td>\n",
       "      <td>0.004104</td>\n",
       "      <td>0.910863</td>\n",
       "      <td>0.003990</td>\n",
       "      <td>0.796849</td>\n",
       "      <td>0.009354</td>\n",
       "      <td>0.797744</td>\n",
       "      <td>0.009264</td>\n",
       "      <td>0.896572</td>\n",
       "      <td>0.004780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>XGB_WordLevel_TF-IDF</td>\n",
       "      <td>0.898303</td>\n",
       "      <td>0.003968</td>\n",
       "      <td>0.888787</td>\n",
       "      <td>0.006056</td>\n",
       "      <td>0.931701</td>\n",
       "      <td>0.004254</td>\n",
       "      <td>0.909720</td>\n",
       "      <td>0.003336</td>\n",
       "      <td>0.793450</td>\n",
       "      <td>0.008166</td>\n",
       "      <td>0.794652</td>\n",
       "      <td>0.007949</td>\n",
       "      <td>0.894601</td>\n",
       "      <td>0.004291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>SGD_CharLevel_Vectors</td>\n",
       "      <td>0.897829</td>\n",
       "      <td>0.006208</td>\n",
       "      <td>0.898523</td>\n",
       "      <td>0.007719</td>\n",
       "      <td>0.917998</td>\n",
       "      <td>0.012709</td>\n",
       "      <td>0.908076</td>\n",
       "      <td>0.005908</td>\n",
       "      <td>0.793110</td>\n",
       "      <td>0.012440</td>\n",
       "      <td>0.793533</td>\n",
       "      <td>0.012696</td>\n",
       "      <td>0.895592</td>\n",
       "      <td>0.005998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>RF_WordLevel_TF-IDF</td>\n",
       "      <td>0.896642</td>\n",
       "      <td>0.003888</td>\n",
       "      <td>0.887120</td>\n",
       "      <td>0.006699</td>\n",
       "      <td>0.930514</td>\n",
       "      <td>0.003212</td>\n",
       "      <td>0.908278</td>\n",
       "      <td>0.003124</td>\n",
       "      <td>0.790057</td>\n",
       "      <td>0.008074</td>\n",
       "      <td>0.791291</td>\n",
       "      <td>0.007713</td>\n",
       "      <td>0.892888</td>\n",
       "      <td>0.004368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Deep_NN_var2_WE</td>\n",
       "      <td>0.896630</td>\n",
       "      <td>0.001046</td>\n",
       "      <td>0.904108</td>\n",
       "      <td>0.007284</td>\n",
       "      <td>0.908502</td>\n",
       "      <td>0.009483</td>\n",
       "      <td>0.906223</td>\n",
       "      <td>0.001457</td>\n",
       "      <td>0.791071</td>\n",
       "      <td>0.002027</td>\n",
       "      <td>0.791247</td>\n",
       "      <td>0.002145</td>\n",
       "      <td>0.895316</td>\n",
       "      <td>0.001221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>RF_Count_Vectors</td>\n",
       "      <td>0.895159</td>\n",
       "      <td>0.004666</td>\n",
       "      <td>0.884417</td>\n",
       "      <td>0.005064</td>\n",
       "      <td>0.931055</td>\n",
       "      <td>0.006297</td>\n",
       "      <td>0.907120</td>\n",
       "      <td>0.004163</td>\n",
       "      <td>0.786963</td>\n",
       "      <td>0.009477</td>\n",
       "      <td>0.788375</td>\n",
       "      <td>0.009524</td>\n",
       "      <td>0.891180</td>\n",
       "      <td>0.004716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>transformers</td>\n",
       "      <td>0.894637</td>\n",
       "      <td>0.005935</td>\n",
       "      <td>0.898383</td>\n",
       "      <td>0.023930</td>\n",
       "      <td>0.912991</td>\n",
       "      <td>0.021280</td>\n",
       "      <td>0.905071</td>\n",
       "      <td>0.003611</td>\n",
       "      <td>0.786681</td>\n",
       "      <td>0.013065</td>\n",
       "      <td>0.788096</td>\n",
       "      <td>0.011700</td>\n",
       "      <td>0.892605</td>\n",
       "      <td>0.008458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Deep_NN_WE</td>\n",
       "      <td>0.894020</td>\n",
       "      <td>0.001535</td>\n",
       "      <td>0.899003</td>\n",
       "      <td>0.006631</td>\n",
       "      <td>0.909538</td>\n",
       "      <td>0.006678</td>\n",
       "      <td>0.904192</td>\n",
       "      <td>0.001147</td>\n",
       "      <td>0.785629</td>\n",
       "      <td>0.003316</td>\n",
       "      <td>0.785802</td>\n",
       "      <td>0.003190</td>\n",
       "      <td>0.892302</td>\n",
       "      <td>0.002114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RCNN_var1_WE</td>\n",
       "      <td>0.893213</td>\n",
       "      <td>0.003740</td>\n",
       "      <td>0.913308</td>\n",
       "      <td>0.006664</td>\n",
       "      <td>0.890462</td>\n",
       "      <td>0.014029</td>\n",
       "      <td>0.901625</td>\n",
       "      <td>0.004413</td>\n",
       "      <td>0.784889</td>\n",
       "      <td>0.007097</td>\n",
       "      <td>0.785418</td>\n",
       "      <td>0.006687</td>\n",
       "      <td>0.893518</td>\n",
       "      <td>0.002842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>XGB_CharLevel_TF-IDF</td>\n",
       "      <td>0.893557</td>\n",
       "      <td>0.006169</td>\n",
       "      <td>0.883646</td>\n",
       "      <td>0.007464</td>\n",
       "      <td>0.928788</td>\n",
       "      <td>0.005401</td>\n",
       "      <td>0.905638</td>\n",
       "      <td>0.005309</td>\n",
       "      <td>0.783740</td>\n",
       "      <td>0.012626</td>\n",
       "      <td>0.785061</td>\n",
       "      <td>0.012452</td>\n",
       "      <td>0.889652</td>\n",
       "      <td>0.006470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Deep_NN_var1_WE</td>\n",
       "      <td>0.890888</td>\n",
       "      <td>0.003898</td>\n",
       "      <td>0.900944</td>\n",
       "      <td>0.023493</td>\n",
       "      <td>0.902201</td>\n",
       "      <td>0.025852</td>\n",
       "      <td>0.900902</td>\n",
       "      <td>0.002781</td>\n",
       "      <td>0.779476</td>\n",
       "      <td>0.008873</td>\n",
       "      <td>0.780991</td>\n",
       "      <td>0.007160</td>\n",
       "      <td>0.889635</td>\n",
       "      <td>0.006359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RCNN_WE</td>\n",
       "      <td>0.889464</td>\n",
       "      <td>0.011414</td>\n",
       "      <td>0.911528</td>\n",
       "      <td>0.015915</td>\n",
       "      <td>0.885973</td>\n",
       "      <td>0.039535</td>\n",
       "      <td>0.897699</td>\n",
       "      <td>0.014024</td>\n",
       "      <td>0.777507</td>\n",
       "      <td>0.021422</td>\n",
       "      <td>0.779410</td>\n",
       "      <td>0.018161</td>\n",
       "      <td>0.889850</td>\n",
       "      <td>0.008470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Shallow_NN_WE</td>\n",
       "      <td>0.888799</td>\n",
       "      <td>0.002446</td>\n",
       "      <td>0.898272</td>\n",
       "      <td>0.005160</td>\n",
       "      <td>0.899698</td>\n",
       "      <td>0.004811</td>\n",
       "      <td>0.898962</td>\n",
       "      <td>0.002119</td>\n",
       "      <td>0.775324</td>\n",
       "      <td>0.005025</td>\n",
       "      <td>0.775374</td>\n",
       "      <td>0.005025</td>\n",
       "      <td>0.887593</td>\n",
       "      <td>0.002703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>RF_CharLevel_TF-IDF</td>\n",
       "      <td>0.887564</td>\n",
       "      <td>0.006365</td>\n",
       "      <td>0.864633</td>\n",
       "      <td>0.006391</td>\n",
       "      <td>0.943247</td>\n",
       "      <td>0.007233</td>\n",
       "      <td>0.902214</td>\n",
       "      <td>0.005538</td>\n",
       "      <td>0.770551</td>\n",
       "      <td>0.012998</td>\n",
       "      <td>0.774644</td>\n",
       "      <td>0.013018</td>\n",
       "      <td>0.881392</td>\n",
       "      <td>0.006483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RCNN_var2_WE</td>\n",
       "      <td>0.886664</td>\n",
       "      <td>0.010916</td>\n",
       "      <td>0.915037</td>\n",
       "      <td>0.008614</td>\n",
       "      <td>0.875529</td>\n",
       "      <td>0.030220</td>\n",
       "      <td>0.894426</td>\n",
       "      <td>0.012414</td>\n",
       "      <td>0.772224</td>\n",
       "      <td>0.020918</td>\n",
       "      <td>0.773824</td>\n",
       "      <td>0.019025</td>\n",
       "      <td>0.887896</td>\n",
       "      <td>0.008848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>LR_CharLevel_TF-IDF</td>\n",
       "      <td>0.887920</td>\n",
       "      <td>0.005539</td>\n",
       "      <td>0.887730</td>\n",
       "      <td>0.007639</td>\n",
       "      <td>0.911524</td>\n",
       "      <td>0.002371</td>\n",
       "      <td>0.899457</td>\n",
       "      <td>0.004639</td>\n",
       "      <td>0.772900</td>\n",
       "      <td>0.011392</td>\n",
       "      <td>0.773273</td>\n",
       "      <td>0.011237</td>\n",
       "      <td>0.885304</td>\n",
       "      <td>0.005978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CNN_LSTM_WE</td>\n",
       "      <td>0.886948</td>\n",
       "      <td>0.003256</td>\n",
       "      <td>0.905462</td>\n",
       "      <td>0.005168</td>\n",
       "      <td>0.887095</td>\n",
       "      <td>0.010584</td>\n",
       "      <td>0.896120</td>\n",
       "      <td>0.003665</td>\n",
       "      <td>0.772145</td>\n",
       "      <td>0.006272</td>\n",
       "      <td>0.772465</td>\n",
       "      <td>0.006050</td>\n",
       "      <td>0.886932</td>\n",
       "      <td>0.002699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>GB_CharLevel_TF-IDF</td>\n",
       "      <td>0.883826</td>\n",
       "      <td>0.005883</td>\n",
       "      <td>0.868733</td>\n",
       "      <td>0.007777</td>\n",
       "      <td>0.929220</td>\n",
       "      <td>0.003910</td>\n",
       "      <td>0.897941</td>\n",
       "      <td>0.004850</td>\n",
       "      <td>0.763478</td>\n",
       "      <td>0.012154</td>\n",
       "      <td>0.765854</td>\n",
       "      <td>0.011744</td>\n",
       "      <td>0.878795</td>\n",
       "      <td>0.006334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>GB_WordLevel_TF-IDF</td>\n",
       "      <td>0.882165</td>\n",
       "      <td>0.002954</td>\n",
       "      <td>0.861412</td>\n",
       "      <td>0.005821</td>\n",
       "      <td>0.936447</td>\n",
       "      <td>0.004023</td>\n",
       "      <td>0.897340</td>\n",
       "      <td>0.002201</td>\n",
       "      <td>0.759629</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>0.763347</td>\n",
       "      <td>0.005598</td>\n",
       "      <td>0.876146</td>\n",
       "      <td>0.003473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>RF_N-Gram_TF-IDF</td>\n",
       "      <td>0.881987</td>\n",
       "      <td>0.003995</td>\n",
       "      <td>0.870738</td>\n",
       "      <td>0.003381</td>\n",
       "      <td>0.922314</td>\n",
       "      <td>0.004834</td>\n",
       "      <td>0.895780</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>0.760024</td>\n",
       "      <td>0.008092</td>\n",
       "      <td>0.761709</td>\n",
       "      <td>0.008177</td>\n",
       "      <td>0.877517</td>\n",
       "      <td>0.003974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RCNN_var3_WE</td>\n",
       "      <td>0.879829</td>\n",
       "      <td>0.010114</td>\n",
       "      <td>0.913264</td>\n",
       "      <td>0.008981</td>\n",
       "      <td>0.863876</td>\n",
       "      <td>0.029520</td>\n",
       "      <td>0.887462</td>\n",
       "      <td>0.011882</td>\n",
       "      <td>0.758765</td>\n",
       "      <td>0.019218</td>\n",
       "      <td>0.760822</td>\n",
       "      <td>0.017069</td>\n",
       "      <td>0.881595</td>\n",
       "      <td>0.008048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>SGD_Count_Vectors</td>\n",
       "      <td>0.881156</td>\n",
       "      <td>0.004425</td>\n",
       "      <td>0.885379</td>\n",
       "      <td>0.013898</td>\n",
       "      <td>0.900947</td>\n",
       "      <td>0.011302</td>\n",
       "      <td>0.892926</td>\n",
       "      <td>0.003041</td>\n",
       "      <td>0.759417</td>\n",
       "      <td>0.009522</td>\n",
       "      <td>0.759939</td>\n",
       "      <td>0.009311</td>\n",
       "      <td>0.878960</td>\n",
       "      <td>0.005728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>LR_N-Gram_TF-IDF</td>\n",
       "      <td>0.881037</td>\n",
       "      <td>0.002585</td>\n",
       "      <td>0.869804</td>\n",
       "      <td>0.003801</td>\n",
       "      <td>0.921667</td>\n",
       "      <td>0.006931</td>\n",
       "      <td>0.894958</td>\n",
       "      <td>0.002538</td>\n",
       "      <td>0.758083</td>\n",
       "      <td>0.005166</td>\n",
       "      <td>0.759842</td>\n",
       "      <td>0.005377</td>\n",
       "      <td>0.876534</td>\n",
       "      <td>0.002464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>XGB_N-Gram_TF-IDF</td>\n",
       "      <td>0.880148</td>\n",
       "      <td>0.007969</td>\n",
       "      <td>0.860863</td>\n",
       "      <td>0.010614</td>\n",
       "      <td>0.932996</td>\n",
       "      <td>0.003914</td>\n",
       "      <td>0.895447</td>\n",
       "      <td>0.006418</td>\n",
       "      <td>0.755589</td>\n",
       "      <td>0.016551</td>\n",
       "      <td>0.759027</td>\n",
       "      <td>0.015712</td>\n",
       "      <td>0.874289</td>\n",
       "      <td>0.008676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>SGD_N-Gram_Vectors</td>\n",
       "      <td>0.880800</td>\n",
       "      <td>0.003215</td>\n",
       "      <td>0.875960</td>\n",
       "      <td>0.005267</td>\n",
       "      <td>0.912495</td>\n",
       "      <td>0.003901</td>\n",
       "      <td>0.893838</td>\n",
       "      <td>0.002652</td>\n",
       "      <td>0.758078</td>\n",
       "      <td>0.006652</td>\n",
       "      <td>0.758940</td>\n",
       "      <td>0.006486</td>\n",
       "      <td>0.877287</td>\n",
       "      <td>0.003529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>GB_Count_Vectors</td>\n",
       "      <td>0.878783</td>\n",
       "      <td>0.003545</td>\n",
       "      <td>0.855772</td>\n",
       "      <td>0.004820</td>\n",
       "      <td>0.937635</td>\n",
       "      <td>0.005356</td>\n",
       "      <td>0.894816</td>\n",
       "      <td>0.003018</td>\n",
       "      <td>0.752499</td>\n",
       "      <td>0.007298</td>\n",
       "      <td>0.756931</td>\n",
       "      <td>0.007161</td>\n",
       "      <td>0.872258</td>\n",
       "      <td>0.003736</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model  test_acc_mean  test_acc_std  test_prec_mean  \\\n",
       "9    SGD_WordLevel_TF-IDF       0.904533      0.003558        0.903289   \n",
       "14       LR_Count_Vectors       0.902220      0.006502        0.896764   \n",
       "17      XGB_Count_Vectors       0.900677      0.002894        0.888951   \n",
       "15    LR_WordLevel_TF-IDF       0.899905      0.004583        0.892538   \n",
       "18   XGB_WordLevel_TF-IDF       0.898303      0.003968        0.888787   \n",
       "12  SGD_CharLevel_Vectors       0.897829      0.006208        0.898523   \n",
       "21    RF_WordLevel_TF-IDF       0.896642      0.003888        0.887120   \n",
       "8         Deep_NN_var2_WE       0.896630      0.001046        0.904108   \n",
       "23       RF_Count_Vectors       0.895159      0.004666        0.884417   \n",
       "52           transformers       0.894637      0.005935        0.898383   \n",
       "11             Deep_NN_WE       0.894020      0.001535        0.899003   \n",
       "2            RCNN_var1_WE       0.893213      0.003740        0.913308   \n",
       "24   XGB_CharLevel_TF-IDF       0.893557      0.006169        0.883646   \n",
       "10        Deep_NN_var1_WE       0.890888      0.003898        0.900944   \n",
       "4                 RCNN_WE       0.889464      0.011414        0.911528   \n",
       "13          Shallow_NN_WE       0.888799      0.002446        0.898272   \n",
       "29    RF_CharLevel_TF-IDF       0.887564      0.006365        0.864633   \n",
       "1            RCNN_var2_WE       0.886664      0.010916        0.915037   \n",
       "19    LR_CharLevel_TF-IDF       0.887920      0.005539        0.887730   \n",
       "6             CNN_LSTM_WE       0.886948      0.003256        0.905462   \n",
       "28    GB_CharLevel_TF-IDF       0.883826      0.005883        0.868733   \n",
       "31    GB_WordLevel_TF-IDF       0.882165      0.002954        0.861412   \n",
       "26       RF_N-Gram_TF-IDF       0.881987      0.003995        0.870738   \n",
       "3            RCNN_var3_WE       0.879829      0.010114        0.913264   \n",
       "22      SGD_Count_Vectors       0.881156      0.004425        0.885379   \n",
       "27       LR_N-Gram_TF-IDF       0.881037      0.002585        0.869804   \n",
       "32      XGB_N-Gram_TF-IDF       0.880148      0.007969        0.860863   \n",
       "25     SGD_N-Gram_Vectors       0.880800      0.003215        0.875960   \n",
       "33       GB_Count_Vectors       0.878783      0.003545        0.855772   \n",
       "\n",
       "    test_prec_std  test_recall_mean  test_recall_std  test_f1-score_mean  \\\n",
       "9        0.005953          0.925551         0.006072            0.914256   \n",
       "14       0.008218          0.929219         0.003529            0.912692   \n",
       "17       0.006372          0.936449         0.005731            0.912047   \n",
       "15       0.005471          0.929974         0.004104            0.910863   \n",
       "18       0.006056          0.931701         0.004254            0.909720   \n",
       "12       0.007719          0.917998         0.012709            0.908076   \n",
       "21       0.006699          0.930514         0.003212            0.908278   \n",
       "8        0.007284          0.908502         0.009483            0.906223   \n",
       "23       0.005064          0.931055         0.006297            0.907120   \n",
       "52       0.023930          0.912991         0.021280            0.905071   \n",
       "11       0.006631          0.909538         0.006678            0.904192   \n",
       "2        0.006664          0.890462         0.014029            0.901625   \n",
       "24       0.007464          0.928788         0.005401            0.905638   \n",
       "10       0.023493          0.902201         0.025852            0.900902   \n",
       "4        0.015915          0.885973         0.039535            0.897699   \n",
       "13       0.005160          0.899698         0.004811            0.898962   \n",
       "29       0.006391          0.943247         0.007233            0.902214   \n",
       "1        0.008614          0.875529         0.030220            0.894426   \n",
       "19       0.007639          0.911524         0.002371            0.899457   \n",
       "6        0.005168          0.887095         0.010584            0.896120   \n",
       "28       0.007777          0.929220         0.003910            0.897941   \n",
       "31       0.005821          0.936447         0.004023            0.897340   \n",
       "26       0.003381          0.922314         0.004834            0.895780   \n",
       "3        0.008981          0.863876         0.029520            0.887462   \n",
       "22       0.013898          0.900947         0.011302            0.892926   \n",
       "27       0.003801          0.921667         0.006931            0.894958   \n",
       "32       0.010614          0.932996         0.003914            0.895447   \n",
       "25       0.005267          0.912495         0.003901            0.893838   \n",
       "33       0.004820          0.937635         0.005356            0.894816   \n",
       "\n",
       "    test_f1-score_std  test_cohens_kappa_mean  test_cohens_kappa_std  \\\n",
       "9            0.003150                0.806615               0.007254   \n",
       "14           0.005567                0.801666               0.013313   \n",
       "17           0.002351                0.798154               0.006024   \n",
       "15           0.003990                0.796849               0.009354   \n",
       "18           0.003336                0.793450               0.008166   \n",
       "12           0.005908                0.793110               0.012440   \n",
       "21           0.003124                0.790057               0.008074   \n",
       "8            0.001457                0.791071               0.002027   \n",
       "23           0.004163                0.786963               0.009477   \n",
       "52           0.003611                0.786681               0.013065   \n",
       "11           0.001147                0.785629               0.003316   \n",
       "2            0.004413                0.784889               0.007097   \n",
       "24           0.005309                0.783740               0.012626   \n",
       "10           0.002781                0.779476               0.008873   \n",
       "4            0.014024                0.777507               0.021422   \n",
       "13           0.002119                0.775324               0.005025   \n",
       "29           0.005538                0.770551               0.012998   \n",
       "1            0.012414                0.772224               0.020918   \n",
       "19           0.004639                0.772900               0.011392   \n",
       "6            0.003665                0.772145               0.006272   \n",
       "28           0.004850                0.763478               0.012154   \n",
       "31           0.002201                0.759629               0.006250   \n",
       "26           0.003600                0.760024               0.008092   \n",
       "3            0.011882                0.758765               0.019218   \n",
       "22           0.003041                0.759417               0.009522   \n",
       "27           0.002538                0.758083               0.005166   \n",
       "32           0.006418                0.755589               0.016551   \n",
       "25           0.002652                0.758078               0.006652   \n",
       "33           0.003018                0.752499               0.007298   \n",
       "\n",
       "    test_matthews_corrcoef_mean  test_matthews_corrcoef_std  \\\n",
       "9                      0.806987                    0.007162   \n",
       "14                     0.802346                    0.013113   \n",
       "17                     0.799669                    0.005712   \n",
       "15                     0.797744                    0.009264   \n",
       "18                     0.794652                    0.007949   \n",
       "12                     0.793533                    0.012696   \n",
       "21                     0.791291                    0.007713   \n",
       "8                      0.791247                    0.002145   \n",
       "23                     0.788375                    0.009524   \n",
       "52                     0.788096                    0.011700   \n",
       "11                     0.785802                    0.003190   \n",
       "2                      0.785418                    0.006687   \n",
       "24                     0.785061                    0.012452   \n",
       "10                     0.780991                    0.007160   \n",
       "4                      0.779410                    0.018161   \n",
       "13                     0.775374                    0.005025   \n",
       "29                     0.774644                    0.013018   \n",
       "1                      0.773824                    0.019025   \n",
       "19                     0.773273                    0.011237   \n",
       "6                      0.772465                    0.006050   \n",
       "28                     0.765854                    0.011744   \n",
       "31                     0.763347                    0.005598   \n",
       "26                     0.761709                    0.008177   \n",
       "3                      0.760822                    0.017069   \n",
       "22                     0.759939                    0.009311   \n",
       "27                     0.759842                    0.005377   \n",
       "32                     0.759027                    0.015712   \n",
       "25                     0.758940                    0.006486   \n",
       "33                     0.756931                    0.007161   \n",
       "\n",
       "    test_roc_auc_mean  test_roc_auc_std  \n",
       "9            0.902204          0.003758  \n",
       "14           0.899227          0.006905  \n",
       "17           0.896712          0.003317  \n",
       "15           0.896572          0.004780  \n",
       "18           0.894601          0.004291  \n",
       "12           0.895592          0.005998  \n",
       "21           0.892888          0.004368  \n",
       "8            0.895316          0.001221  \n",
       "23           0.891180          0.004716  \n",
       "52           0.892605          0.008458  \n",
       "11           0.892302          0.002114  \n",
       "2            0.893518          0.002842  \n",
       "24           0.889652          0.006470  \n",
       "10           0.889635          0.006359  \n",
       "4            0.889850          0.008470  \n",
       "13           0.887593          0.002703  \n",
       "29           0.881392          0.006483  \n",
       "1            0.887896          0.008848  \n",
       "19           0.885304          0.005978  \n",
       "6            0.886932          0.002699  \n",
       "28           0.878795          0.006334  \n",
       "31           0.876146          0.003473  \n",
       "26           0.877517          0.003974  \n",
       "3            0.881595          0.008048  \n",
       "22           0.878960          0.005728  \n",
       "27           0.876534          0.002464  \n",
       "32           0.874289          0.008676  \n",
       "25           0.877287          0.003529  \n",
       "33           0.872258          0.003736  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results[[ \"Model\",\"test_acc_mean\",\"test_acc_std\", \n",
    "                        \n",
    "                       \"test_prec_mean\", \"test_prec_std\", \n",
    "                        \"test_recall_mean\",\"test_recall_std\", \n",
    "                       \"test_f1-score_mean\", \"test_f1-score_std\", \n",
    "                       \"test_cohens_kappa_mean\", \"test_cohens_kappa_std\", \"test_matthews_corrcoef_mean\",\"test_matthews_corrcoef_std\", \n",
    "                       \"test_roc_auc_mean\", \"test_roc_auc_std\"]][df_results[\"test_matthews_corrcoef_mean\"]>0.5].sort_values(by=[\"test_matthews_corrcoef_mean\", \"test_recall_mean\"], ascending=False)[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_results:\n",
    "    df_results.sort_values(by=[\"test_prec_mean\", \"test_recall_mean\"], ascending=False).to_csv(\"model_selection_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><a id=\"part_9\"><h2>Visualization</h2></a></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results=df_results[df_results[\"test_matthews_corrcoef_mean\"]>0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1800x1800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(25,25))\n",
    "#plt.axis([0.85,1,0.85,1])\n",
    "ax.scatter(df_results[\"test_matthews_corrcoef_mean\"], df_results[\"test_acc_mean\"])\n",
    "\n",
    "for i, txt in enumerate(df_results[\"Model\"]):\n",
    "    ax.annotate(txt, (df_results[\"test_matthews_corrcoef_mean\"].iloc[i], df_results[\"test_acc_mean\"].iloc[i]))\n",
    "\n",
    "plt.xlabel(\"Matthews Corrcoef\")\n",
    "plt.ylabel(\"Recall\")\n",
    "\n",
    "plt.grid(True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
