{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Text Classification</center></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import time\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os\n",
    "import random\n",
    "import stanza\n",
    "\n",
    "#from preprocess import * \n",
    "#from custom_preprocessing import CustomPreProcessing\n",
    "#from custom_preprocessing import PreProcessing\n",
    "#from class_metric import Metrics\n",
    "from googletrans import Translator\n",
    "import sklearn\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn import decomposition, ensemble\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import balanced_accuracy_score, recall_score, f1_score\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "\n",
    "\n",
    "import itertools\n",
    "from textblob import TextBlob \n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "sns.set(style=\"darkgrid\")\n",
    "\n",
    "\n",
    "import string\n",
    "import fasttext\n",
    "import fasttext.util\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ---- Call tqdm to see progress bar with pandas\n",
    "tqdm().pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23.1\n",
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "print(sklearn.__version__)\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tn(y_true, y_pred): return confusion_matrix(y_true, y_pred)[0, 0]\n",
    "def fp(y_true, y_pred): return confusion_matrix(y_true, y_pred)[0, 1]\n",
    "def fn(y_true, y_pred): return confusion_matrix(y_true, y_pred)[1, 0]\n",
    "def tp(y_true, y_pred): return confusion_matrix(y_true, y_pred)[1, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Parameters</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part allows you to determine the text column to classify as well as the label column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = \"mails\"\n",
    "LABEL = \"label\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>List of Models</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results           = True\n",
    "lang                   = False\n",
    "sample                 = False\n",
    "multinomial_naive_bayes= True\n",
    "logistic_regression    = True\n",
    "svm_model              = False\n",
    "k_nn_model             = True\n",
    "sgd                    = True\n",
    "random_forest          = True\n",
    "gradient_boosting      = True\n",
    "xgboost_classifier     = True\n",
    "shallow_network        = True\n",
    "deep_nn                = True\n",
    "rnn                    = True\n",
    "lstm                   = True\n",
    "cnn                    = True\n",
    "gru                    = True\n",
    "cnn_lstm               = True\n",
    "cnn_gru                = True\n",
    "bidirectional_rnn      = True\n",
    "bidirectional_lstm     = True\n",
    "bidirectional_gru      = True\n",
    "rcnn                   = True\n",
    "transformers           = True\n",
    "pre_trained            = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>List of Metrics for the Model Selection</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_metrics = {'acc': accuracy_score,\n",
    "               'balanced_accuracy': balanced_accuracy_score,\n",
    "               'prec': precision_score,\n",
    "               'recall': recall_score,\n",
    "               'f1-score': f1_score,\n",
    "               'tp': tp, 'tn': tn,\n",
    "               'fp': fp, 'fn': fn,\n",
    "               'cohens_kappa':cohen_kappa_score,\n",
    "               'matthews_corrcoef':matthews_corrcoef,\n",
    "               \"roc_auc\":roc_auc_score}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i><h1>Sand Box to Load Data</h1></i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sandbox is the working area of your data if it has not been processed before using the pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for preprocessing\n",
    "def remove_upper_case( text):\n",
    "    '''\n",
    "    Function to transform upper string in title words\n",
    "    @param text: (str) text \n",
    "    @return: (str) text without upper words \n",
    "    '''\n",
    "    sentences = text.split(\"\\n\")\n",
    "    new_sentences = []\n",
    "    for i in sentences:\n",
    "        words = text.split()\n",
    "        stripped = [w.title() if w.isupper() else w for w in words]\n",
    "        new_sentences.append(\" \".join(stripped))\n",
    "    return \"\\n\".join(new_sentences)\n",
    "  \n",
    "def remove_URL( text):\n",
    "    '''\n",
    "    Function to remove url from text.\n",
    "    @param text: (str) sentence\n",
    "    @return: (str) clean text\n",
    "\n",
    "    '''\n",
    "    url = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return url.sub(r'',text)\n",
    "    \n",
    "    \n",
    "def remove_html( text):\n",
    "    '''\n",
    "    Function regex to clean text from html balises.\n",
    "    @param text: (str) sentence \n",
    "    @return: (str) clean text \n",
    "    '''\n",
    "    html=re.compile(r'<.*?>')\n",
    "    return html.sub(r'',text)\n",
    "    \n",
    "    \n",
    "\n",
    "def remove_emoji( text):\n",
    "    '''\n",
    "    Function to remove emojis, symbols and pictograms etc from text\n",
    "    @param text: (str) sentences \n",
    "    @return: (str) clean text \n",
    "    '''\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "other         11585\n",
      "annulation     9483\n",
      "Name: label, dtype: int64\n",
      "441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chris/.local/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/chris/.local/lib/python3.6/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#%%script false --no-raise-error\n",
    "df = pd.read_csv(\"mails_clean_new.csv\", sep=\";\")\n",
    "df[LABEL][df[LABEL]!=\"annulation\"] = \"other\"\n",
    "print(df[LABEL].value_counts())\n",
    "print(df[TEXT].isnull().sum())\n",
    "df[TEXT][df[TEXT].isnull()] = \"empty\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
    "#!tar -xzf aclImdb_v1.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_imdb_sentiment_analysis_dataset(data_path, seed=123):\n",
    "    \"\"\"Loads the IMDb movie reviews sentiment analysis dataset.\n",
    "\n",
    "    # Arguments\n",
    "        data_path: string, path to the data directory.\n",
    "        seed: int, seed for randomizer.\n",
    "\n",
    "    # Returns\n",
    "        A tuple of training and validation data.\n",
    "        Number of training samples: 25000\n",
    "        Number of test samples: 25000\n",
    "        Number of categories: 2 (0 - negative, 1 - positive)\n",
    "\n",
    "    # References\n",
    "        Mass et al., http://www.aclweb.org/anthology/P11-1015\n",
    "\n",
    "        Download and uncompress archive from:\n",
    "        http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
    "    \"\"\"\n",
    "    imdb_data_path = os.path.join(data_path, 'aclImdb')\n",
    "\n",
    "    # Load the training data\n",
    "    train_texts = []\n",
    "    train_labels = []\n",
    "    for category in ['pos', 'neg']:\n",
    "        train_path = os.path.join(imdb_data_path, 'train', category)\n",
    "        for fname in tqdm(sorted(os.listdir(train_path))):\n",
    "            if fname.endswith('.txt'):\n",
    "                with open(os.path.join(train_path, fname)) as f:\n",
    "                    train_texts.append(f.read())\n",
    "                train_labels.append(0 if category == 'neg' else 1)\n",
    "    print(\"\\nTrain done\\n\")\n",
    "    # Load the validation data.\n",
    "    test_texts = []\n",
    "    test_labels = []\n",
    "    for category in ['pos', 'neg']:\n",
    "        test_path = os.path.join(imdb_data_path, 'test', category)\n",
    "        for fname in tqdm(sorted(os.listdir(test_path))):\n",
    "            if fname.endswith('.txt'):\n",
    "                with open(os.path.join(test_path, fname)) as f:\n",
    "                    test_texts.append(f.read())\n",
    "                test_labels.append(0 if category == 'neg' else 1)\n",
    "    print(\"\\nTest done\\n\")\n",
    "    # Shuffle the training data and labels.\n",
    "    random.seed(seed)\n",
    "    random.shuffle(train_texts)\n",
    "    random.seed(seed)\n",
    "    random.shuffle(train_labels)\n",
    "\n",
    "    return ((train_texts, np.array(train_labels)),\n",
    "            (test_texts, np.array(test_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12500/12500 [01:46<00:00, 117.23it/s]\n",
      "100%|██████████| 12500/12500 [01:37<00:00, 128.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train done\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12500/12500 [01:41<00:00, 123.59it/s]\n",
      "100%|██████████| 12500/12500 [01:34<00:00, 132.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test done\n",
      "\n",
      "                                                text label\n",
      "0  Possible SPOILERSThe Spy Who Shagged Me is a m...     0\n",
      "1  The long list of \"big\" names in this flick (in...     0\n",
      "2  Bette Midler showcases her talents and beauty ...     1\n",
      "3  Great movie when I saw it. Have to say one of ...     1\n",
      "4  Although it's most certainly politically incor...     1\n",
      "CPU times: user 23.1 s, sys: 31.8 s, total: 54.8 s\n",
      "Wall time: 7min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%script false --no-raise-error\n",
    "(x_train, y_train), (x_test, y_test) = load_imdb_sentiment_analysis_dataset(\".\")\n",
    "\n",
    "df = pd.DataFrame(data=[x_train, y_train], index=[\"text\", \"label\"]).T\n",
    "df = df.append(pd.DataFrame(data=[x_test, y_test], index=[\"text\", \"label\"]).T)\n",
    "\n",
    "df[TEXT] = df[TEXT].apply(remove_upper_case)\n",
    "df[TEXT] = df[TEXT].apply(remove_URL)\n",
    "df[TEXT] = df[TEXT].apply(remove_html)\n",
    "df[TEXT] = df[TEXT].apply(remove_emoji)\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><i><h1>Sart Pipeline</h1></i></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_lang_google( x):\n",
    "        '''\n",
    "        Function to detect the language of the string\n",
    "        @param x: (str) sentences of text to detect language\n",
    "        @return: (str or nan) language of the sentence\n",
    "        '''\n",
    "        translate = Translator()\n",
    "        try:\n",
    "            return translate.detect(x).lang\n",
    "        except:\n",
    "            return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if lang:\n",
    "    # ---- Language detection of the text\n",
    "    df.loc[:,\"language\"] = df[TEXT].progress_apply(detect_lang_google)\n",
    "    # ---- Extract most frequent language \n",
    "    language = df.language.value_counts().index.tolist()[0]\n",
    "    print(f\"The language most present in the dataset is {language}\")\n",
    "else:\n",
    "    language=\"fr\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Prepare data for ML Classic</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if sample:\n",
    "    df_save = df.copy()\n",
    "    df = df.sample(5000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21068, 11)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Load stopwords \n",
    "if language==\"fr\":\n",
    "    stop_word = np.loadtxt(\"stopwords-fr.txt\", dtype=str)\n",
    "if language==\"en\":\n",
    "    stop_word = np.loadtxt(\"stopwords_en.txt\", dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome in this custom preprocessing class\n",
      "        \n",
      "Welcome in the preprocessing\n"
     ]
    }
   ],
   "source": [
    "def remove_stop_words( x, stop_word):\n",
    "        '''\n",
    "        Function to remove a list of words\n",
    "        @param x : (str) text \n",
    "        @param stop_word: (list) list of stopwords to delete \n",
    "        @return: (str) new string without stopwords \n",
    "        '''\n",
    "        x_new = text_to_word_sequence(x)    # tokenize text \n",
    "        x_ = []\n",
    "        for i in x_new:\n",
    "            if i not in stop_word:\n",
    "                x_.append(i)\n",
    "        return \" \".join(x_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21068/21068 [01:06<00:00, 318.60it/s]\n"
     ]
    }
   ],
   "source": [
    "df.loc[:,TEXT+\"_sw\"] = df.loc[:,TEXT].progress_apply(lambda x : remove_stop_words(x, stop_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if df[TEXT+\"_sw\"].isnull().sum()>0:\n",
    "    print(\"Empty text\")\n",
    "    df[TEXT+\"_sw\"][df[TEXT+\"_sw\"].isnull()] = \"empty_text\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Machine Learning</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset into training and validation datasets \n",
    "# ML classic \n",
    "train_x_sw, valid_x_sw, y_train_sw, y_valid_sw = model_selection.train_test_split(df[TEXT+\"_sw\"], df[LABEL], random_state=42, stratify=df[LABEL], test_size=0.2)\n",
    "\n",
    "# For Embeddings\n",
    "train_x, valid_x, y_train, y_valid = model_selection.train_test_split(df[TEXT], df[LABEL], random_state=42, stratify=df[LABEL], test_size=0.2)\n",
    "\n",
    "# label encode the target variable \n",
    "encoder = preprocessing.LabelEncoder()\n",
    "train_y_sw = encoder.fit_transform(y_train_sw)\n",
    "valid_y_sw = encoder.fit_transform(y_valid_sw)\n",
    "train_y = encoder.fit_transform(y_train)\n",
    "valid_y = encoder.fit_transform(y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Class Weights</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the class weight with sklearn \n",
    "class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                 np.unique(y_train),\n",
    "                                                 y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weight: 1.0083\tclass: 0\n",
      "Class weight: 0.9918\tclass: 1\n"
     ]
    }
   ],
   "source": [
    "print(*[f'Class weight: {round(i[0],4)}\\tclass: {i[1]}' for i in zip(class_weights, np.unique(y_train))], sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The dataset is balanced (ratio=0.984)\n"
     ]
    }
   ],
   "source": [
    "# Determined if the dataset is balanced or imbalanced \n",
    "ratio = np.min(df.label.value_counts()) / np.max(df.label.value_counts())\n",
    "if ratio > 0.1:      # Ratio 1:10 -> limite blanced / imbalanced \n",
    "    balanced = True\n",
    "    print(f\"\\nThe dataset is balanced (ratio={round(ratio, 3)})\")\n",
    "else:\n",
    "    balanced = False\n",
    "    print(f\"\\nThe dataset is imbalanced (ratio={round(ratio, 3)})\")\n",
    "    #from imblearn.over_sampling import ADASYN\n",
    "    # put class for debalanced data \n",
    "    # in progress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Save Unique Labels</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep the unique label corresponding to their encoding correspondance\n",
    "labels = df[LABEL].unique()\n",
    "test=pd.DataFrame(data=np.transpose([labels,encoder.fit_transform(labels)]), columns=[\"labels\", \"encoding\"]).sort_values(by=[\"encoding\"])\n",
    "labels=test.labels.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>DataFrame for the results</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>One-Hot encoding (CountVectorizing)</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.77 s, sys: 156 ms, total: 3.92 s\n",
      "Wall time: 4.01 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# create a count vectorizer object \n",
    "count_vect = CountVectorizer(analyzer='word', token_pattern=r'\\w{1,}')\n",
    "count_vect.fit(df[TEXT]+\"_sw\")\n",
    "\n",
    "# transform the training and validation data using count vectorizer object\n",
    "xtrain_count =  count_vect.transform(train_x_sw)\n",
    "xvalid_count =  count_vect.transform(valid_x_sw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xtrain_tfidf.toarray()[0][xtrain_tfidf.toarray()[0]  >0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>TF-IDF</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word level tf-idf done\n",
      "ngram level tf-idf done\n",
      "characters level tf-idf done\n",
      "CPU times: user 47 s, sys: 3.12 s, total: 50.2 s\n",
      "Wall time: 50.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# word level tf-idf\n",
    "tfidf_vect = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', max_features=10000)\n",
    "tfidf_vect.fit(df[TEXT])\n",
    "xtrain_tfidf =  tfidf_vect.transform(train_x_sw)\n",
    "xvalid_tfidf =  tfidf_vect.transform(valid_x_sw)\n",
    "print(\"word level tf-idf done\")\n",
    "# ngram level tf-idf \n",
    "tfidf_vect_ngram = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', ngram_range=(2,3), max_features=10000)\n",
    "tfidf_vect_ngram.fit(df[TEXT])\n",
    "xtrain_tfidf_ngram =  tfidf_vect_ngram.transform(train_x_sw)\n",
    "xvalid_tfidf_ngram =  tfidf_vect_ngram.transform(valid_x_sw)\n",
    "print(\"ngram level tf-idf done\")\n",
    "# characters level tf-idf\n",
    "tfidf_vect_ngram_chars = TfidfVectorizer(analyzer='char',  ngram_range=(2,3), max_features=10000) #token_pattern=r'\\w{1,}',\n",
    "tfidf_vect_ngram_chars.fit(df[TEXT])\n",
    "xtrain_tfidf_ngram_chars =  tfidf_vect_ngram_chars.transform(train_x_sw) \n",
    "xvalid_tfidf_ngram_chars =  tfidf_vect_ngram_chars.transform(valid_x_sw) \n",
    "print(\"characters level tf-idf done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Load Pre-Trained model fastText</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.14 s, sys: 10.3 s, total: 16.4 s\n",
      "Wall time: 16.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if language==\"fr\":\n",
    "    #!wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.fr.300.bin.gz\n",
    "    #!gunzip cc.fr.300.bin.gz\n",
    "    pretrained = fasttext.FastText.load_model('fastText/cc.fr.300.bin')\n",
    "if language==\"en\":\n",
    "    !wget https://dl.fbaipublicfiles.com/fasttext/vectors-english/crawl-300d-2M-subword.zip\n",
    "    !unzip crawl-300d-2M-subword.zip\n",
    "    pretrained = fasttext.FastText.load_model('crawl-300d-2M-subword.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Word Embeddings</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 158153/158153 [00:02<00:00, 63276.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.3 s, sys: 750 ms, total: 14 s\n",
      "Wall time: 14.2 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "# create a tokenizer \n",
    "token = Tokenizer()\n",
    "token.fit_on_texts(df[TEXT])\n",
    "word_index = token.word_index\n",
    "\n",
    "# convert text to sequence of tokens and pad them to ensure equal length vectors \n",
    "train_seq_x = sequence.pad_sequences(token.texts_to_sequences(train_x), maxlen=300)\n",
    "valid_seq_x = sequence.pad_sequences(token.texts_to_sequences(valid_x), maxlen=300)\n",
    "\n",
    "# create token-embedding mapping\n",
    "embedding_matrix = np.zeros((len(word_index) + 1, 300))\n",
    "words = []\n",
    "for word, i in tqdm(word_index.items()):\n",
    "    embedding_vector = pretrained.get_word_vector(word) #embeddings_index.get(word)\n",
    "    words.append(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#words[1], embedding_matrix[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report(clf, x, y, name='classifier', cv=5, dict_scoring=None, fit_params=None):\n",
    "    '''\n",
    "    Function create a metric report automatically with cross_validate function.\n",
    "    @param clf: (model) classifier\n",
    "    @param x: (list or matrix or tensor) training x data\n",
    "    @param y: (list) label data \n",
    "    @param name: (string) name of the model (default classifier)\n",
    "    @param cv: (int) number of fold for cross-validation (default 5)\n",
    "    @param dict_scoring: (dict) dictionary of metrics and names\n",
    "    @param fit_aparams: (dict) add parameters for model fitting \n",
    "    @return: (pandas.dataframe) dataframe containing all the results of the metrics \n",
    "    for each fold and the mean and std for each of them\n",
    "    '''\n",
    "    if dict_scoring!=None:\n",
    "        score = dict_scoring.copy() # save the original dictionary\n",
    "        for i in score.keys():\n",
    "            score[i] = make_scorer(score[i]) # make each function scorer\n",
    "    \n",
    "    scores = cross_validate(clf, x, y, scoring=score,\n",
    "                         cv=cv, return_train_score=False, n_jobs=-1,  fit_params=fit_params)\n",
    "    # initialisation \n",
    "    index = []\n",
    "    value = []\n",
    "    index.append(\"Model\")\n",
    "    value.append(name)\n",
    "    for i in scores:  # loop on each metric generate text and values\n",
    "        if i == \"estimator\":\n",
    "            continue\n",
    "        for j in enumerate(scores[i]):\n",
    "            index.append(i+\"_cv\"+str(j[0]+1))\n",
    "            value.append(j[1])\n",
    "        \n",
    "        \n",
    "        index.append(i+\"_mean\")\n",
    "        value.append(np.mean(scores[i]))\n",
    "        index.append(i+\"_std\")\n",
    "        value.append(np.std(scores[i]))\n",
    "        \n",
    "    return pd.DataFrame(data=value, index=index).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h2>Multinomial Naive Bayes</h2></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 297 ms, sys: 4.55 s, total: 4.84 s\n",
      "Wall time: 10.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if multinomial_naive_bayes:\n",
    "    df_results = df_results.append(report(naive_bayes.MultinomialNB(), xtrain_count,train_y_sw, name='NB_Count_Vectors', cv=5, dict_scoring=score_metrics))\n",
    "    df_results = df_results.append(report(naive_bayes.MultinomialNB(), xtrain_tfidf,train_y, name='NB_WordLevel_TF-IDF', cv=5, dict_scoring=score_metrics))\n",
    "    df_results = df_results.append(report(naive_bayes.MultinomialNB(), xtrain_tfidf_ngram,train_y, name='NB_N-Gram_TF-IDF', cv=5, dict_scoring=score_metrics))\n",
    "    df_results = df_results.append(report(naive_bayes.MultinomialNB(), xtrain_tfidf_ngram_chars,train_y, name='NB_CharLevel_TF-IDF', cv=5, dict_scoring=score_metrics))\n",
    "    df_results = df_results.append(report(naive_bayes.MultinomialNB(), train_seq_x,train_y, name='NB_Words', cv=5, dict_scoring=score_metrics))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h2>Logistic Regression</h2></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 250 ms, sys: 125 ms, total: 375 ms\n",
      "Wall time: 10.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if logistic_regression:\n",
    "    df_results = df_results.append(report(linear_model.LogisticRegression(max_iter=1000), xtrain_count,train_y_sw, name='LR_Count_Vectors', cv=5, dict_scoring=score_metrics))\n",
    "    df_results = df_results.append(report(linear_model.LogisticRegression(max_iter=1000), xtrain_tfidf,train_y, name='LR_WordLevel_TF-IDF', cv=5, dict_scoring=score_metrics))\n",
    "    df_results = df_results.append(report(linear_model.LogisticRegression(max_iter=1000), xtrain_tfidf_ngram,train_y, name='LR_N-Gram_TF-IDF', cv=5, dict_scoring=score_metrics))\n",
    "    df_results = df_results.append(report(linear_model.LogisticRegression(max_iter=1000), xtrain_tfidf_ngram_chars,train_y, name='LR_CharLevel_TF-IDF', cv=5, dict_scoring=score_metrics))\n",
    "    df_results = df_results.append(report(linear_model.LogisticRegression(max_iter=1000), train_seq_x,train_y, name='LR_Words', cv=5, dict_scoring=score_metrics))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h2>SVM</h2></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 21.5 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if svm_model:\n",
    "    df_results = df_results.append(report(svm.SVC(), xtrain_count,train_y_sw, name='SVM_Count_Vectors', cv=5, dict_scoring=score_metrics))\n",
    "    df_results = df_results.append(report(svm.SVC(), xtrain_tfidf,train_y, name='SVM_WordLevel_TF-IDF', cv=5, dict_scoring=score_metrics))\n",
    "    df_results = df_results.append(report(svm.SVC(), xtrain_tfidf_ngram,train_y, name='SVM_N-Gram_TF-IDF', cv=5, dict_scoring=score_metrics))\n",
    "    df_results = df_results.append(report(svm.SVC(), xtrain_tfidf_ngram_chars,train_y, name='SVM_CharLevel_TF-IDF', cv=5, dict_scoring=score_metrics))\n",
    "    df_results = df_results.append(report(svm.SVC(), train_seq_x,train_y, name='SVM_Words', cv=5, dict_scoring=score_metrics))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h2>k-NN</h2></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chris/.local/lib/python3.6/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "/home/chris/.local/lib/python3.6/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 375 ms, sys: 11.5 s, total: 11.8 s\n",
      "Wall time: 1min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if k_nn_model:\n",
    "    df_results = df_results.append(report(KNeighborsClassifier(n_neighbors=20, weights='distance', n_jobs=-1), xtrain_count,train_y_sw, name='kNN_Count_Vectors', cv=5, dict_scoring=score_metrics))\n",
    "    df_results = df_results.append(report(KNeighborsClassifier(n_neighbors=20, weights='distance', n_jobs=-1), xtrain_tfidf,train_y, name='kNN_WordLevel_TF-IDF', cv=5, dict_scoring=score_metrics))\n",
    "    df_results = df_results.append(report(KNeighborsClassifier(n_neighbors=20, weights='distance', n_jobs=-1), xtrain_tfidf_ngram,train_y, name='kNN_N-Gram_TF-IDF', cv=5, dict_scoring=score_metrics))\n",
    "    df_results = df_results.append(report(KNeighborsClassifier(n_neighbors=20, weights='distance', n_jobs=-1), xtrain_tfidf_ngram_chars,train_y, name='kNN_CharLevel_TF-IDF', cv=5, dict_scoring=score_metrics))\n",
    "    df_results = df_results.append(report(KNeighborsClassifier(n_neighbors=20, weights='distance', n_jobs=-1), train_seq_x,train_y, name='kNN_Words', cv=5, dict_scoring=score_metrics))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h2>RandomForest</h2></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 328 ms, sys: 188 ms, total: 516 ms\n",
      "Wall time: 2min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if random_forest:\n",
    "    df_results = df_results.append(report(ensemble.RandomForestClassifier(bootstrap=True,min_impurity_decrease=1e-7,n_jobs=-1, random_state=42), xtrain_count,train_y_sw, name='RF_Count_Vectors', cv=5, dict_scoring=score_metrics))\n",
    "    df_results = df_results.append(report(ensemble.RandomForestClassifier(bootstrap=True,min_impurity_decrease=1e-7,n_jobs=-1, random_state=42), xtrain_tfidf,train_y, name='RF_WordLevel_TF-IDF', cv=5, dict_scoring=score_metrics))\n",
    "    df_results = df_results.append(report(ensemble.RandomForestClassifier(bootstrap=True,min_impurity_decrease=1e-7,n_jobs=-1, random_state=42), xtrain_tfidf_ngram,train_y, name='RF_N-Gram_TF-IDF', cv=5, dict_scoring=score_metrics))\n",
    "    df_results = df_results.append(report(ensemble.RandomForestClassifier(bootstrap=True,min_impurity_decrease=1e-7,n_jobs=-1, random_state=42), xtrain_tfidf_ngram_chars,train_y, name='RF_CharLevel_TF-IDF', cv=5, dict_scoring=score_metrics))\n",
    "    df_results = df_results.append(report(ensemble.RandomForestClassifier(bootstrap=True,min_impurity_decrease=1e-7,n_jobs=-1, random_state=42), train_seq_x,train_y, name='RF_Words', cv=5, dict_scoring=score_metrics))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h2>Stochastic Descent</h2></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 344 ms, sys: 172 ms, total: 516 ms\n",
      "Wall time: 3.05 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if sgd:\n",
    "    df_results = df_results.append(report(SGDClassifier(loss='modified_huber', max_iter=1000, tol=1e-3,   n_iter_no_change=10, early_stopping=True, n_jobs=-1 ), xtrain_count,train_y_sw, name='SGD_Count_Vectors', cv=5, dict_scoring=score_metrics))\n",
    "    df_results = df_results.append(report(SGDClassifier(loss='modified_huber', max_iter=1000, tol=1e-3,   n_iter_no_change=10, early_stopping=True, n_jobs=-1 ), xtrain_tfidf,train_y, name='SGD_WordLevel_TF-IDF', cv=5, dict_scoring=score_metrics))\n",
    "    df_results = df_results.append(report(SGDClassifier(loss='modified_huber', max_iter=1000, tol=1e-3,   n_iter_no_change=10, early_stopping=True, n_jobs=-1 ), xtrain_tfidf_ngram,train_y, name='SGD_N-Gram_Vectors', cv=5, dict_scoring=score_metrics))\n",
    "    df_results = df_results.append(report(SGDClassifier(loss='modified_huber', max_iter=1000, tol=1e-3,   n_iter_no_change=10, early_stopping=True, n_jobs=-1 ), xtrain_tfidf_ngram_chars,train_y, name='SGD_CharLevel_Vectors', cv=5, dict_scoring=score_metrics))\n",
    "    df_results = df_results.append(report(SGDClassifier(loss='modified_huber', max_iter=1000, tol=1e-3,   n_iter_no_change=10, early_stopping=True, n_jobs=-1 ), train_seq_x,train_y, name='SGD_Words', cv=5, dict_scoring=score_metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>test_acc_mean</th>\n",
       "      <th>test_prec_mean</th>\n",
       "      <th>test_recall_mean</th>\n",
       "      <th>test_f1-score_mean</th>\n",
       "      <th>test_cohens_kappa_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR_Count_Vectors</td>\n",
       "      <td>0.864875</td>\n",
       "      <td>0.860838</td>\n",
       "      <td>0.873539</td>\n",
       "      <td>0.86693</td>\n",
       "      <td>0.729696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR_WordLevel_TF-IDF</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.860478</td>\n",
       "      <td>0.897839</td>\n",
       "      <td>0.878624</td>\n",
       "      <td>0.749891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NB_Count_Vectors</td>\n",
       "      <td>0.83775</td>\n",
       "      <td>0.858464</td>\n",
       "      <td>0.812297</td>\n",
       "      <td>0.834669</td>\n",
       "      <td>0.675619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NB_WordLevel_TF-IDF</td>\n",
       "      <td>0.848625</td>\n",
       "      <td>0.858343</td>\n",
       "      <td>0.838333</td>\n",
       "      <td>0.848133</td>\n",
       "      <td>0.697284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SGD_WordLevel_TF-IDF</td>\n",
       "      <td>0.8595</td>\n",
       "      <td>0.850558</td>\n",
       "      <td>0.875518</td>\n",
       "      <td>0.862576</td>\n",
       "      <td>0.718909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SGD_Count_Vectors</td>\n",
       "      <td>0.841875</td>\n",
       "      <td>0.849118</td>\n",
       "      <td>0.835841</td>\n",
       "      <td>0.841836</td>\n",
       "      <td>0.683762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RF_WordLevel_TF-IDF</td>\n",
       "      <td>0.837875</td>\n",
       "      <td>0.846943</td>\n",
       "      <td>0.828168</td>\n",
       "      <td>0.837404</td>\n",
       "      <td>0.675786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RF_Count_Vectors</td>\n",
       "      <td>0.839</td>\n",
       "      <td>0.83936</td>\n",
       "      <td>0.842048</td>\n",
       "      <td>0.840587</td>\n",
       "      <td>0.677964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR_CharLevel_TF-IDF</td>\n",
       "      <td>0.836625</td>\n",
       "      <td>0.82634</td>\n",
       "      <td>0.855938</td>\n",
       "      <td>0.84083</td>\n",
       "      <td>0.673128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SGD_CharLevel_Vectors</td>\n",
       "      <td>0.826</td>\n",
       "      <td>0.822643</td>\n",
       "      <td>0.841297</td>\n",
       "      <td>0.829343</td>\n",
       "      <td>0.651886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NB_CharLevel_TF-IDF</td>\n",
       "      <td>0.806125</td>\n",
       "      <td>0.799832</td>\n",
       "      <td>0.820975</td>\n",
       "      <td>0.81021</td>\n",
       "      <td>0.612136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RF_CharLevel_TF-IDF</td>\n",
       "      <td>0.788875</td>\n",
       "      <td>0.787647</td>\n",
       "      <td>0.795936</td>\n",
       "      <td>0.791684</td>\n",
       "      <td>0.577684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kNN_WordLevel_TF-IDF</td>\n",
       "      <td>0.762875</td>\n",
       "      <td>0.769554</td>\n",
       "      <td>0.756004</td>\n",
       "      <td>0.762578</td>\n",
       "      <td>0.525786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NB_N-Gram_TF-IDF</td>\n",
       "      <td>0.740375</td>\n",
       "      <td>0.757976</td>\n",
       "      <td>0.712617</td>\n",
       "      <td>0.734538</td>\n",
       "      <td>0.480969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR_N-Gram_TF-IDF</td>\n",
       "      <td>0.737625</td>\n",
       "      <td>0.732122</td>\n",
       "      <td>0.756261</td>\n",
       "      <td>0.743915</td>\n",
       "      <td>0.475072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kNN_CharLevel_TF-IDF</td>\n",
       "      <td>0.690625</td>\n",
       "      <td>0.728211</td>\n",
       "      <td>0.617397</td>\n",
       "      <td>0.667859</td>\n",
       "      <td>0.381979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RF_N-Gram_TF-IDF</td>\n",
       "      <td>0.7165</td>\n",
       "      <td>0.726316</td>\n",
       "      <td>0.702456</td>\n",
       "      <td>0.714115</td>\n",
       "      <td>0.433119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SGD_N-Gram_Vectors</td>\n",
       "      <td>0.717</td>\n",
       "      <td>0.715117</td>\n",
       "      <td>0.729238</td>\n",
       "      <td>0.721952</td>\n",
       "      <td>0.433871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kNN_Count_Vectors</td>\n",
       "      <td>0.6485</td>\n",
       "      <td>0.608261</td>\n",
       "      <td>0.862147</td>\n",
       "      <td>0.712317</td>\n",
       "      <td>0.294476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RF_Words</td>\n",
       "      <td>0.531125</td>\n",
       "      <td>0.536064</td>\n",
       "      <td>0.518212</td>\n",
       "      <td>0.526871</td>\n",
       "      <td>0.0624352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kNN_N-Gram_TF-IDF</td>\n",
       "      <td>0.519625</td>\n",
       "      <td>0.513571</td>\n",
       "      <td>0.902312</td>\n",
       "      <td>0.654385</td>\n",
       "      <td>0.0330878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR_Words</td>\n",
       "      <td>0.506</td>\n",
       "      <td>0.509306</td>\n",
       "      <td>0.549217</td>\n",
       "      <td>0.528472</td>\n",
       "      <td>0.011288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NB_Words</td>\n",
       "      <td>0.50375</td>\n",
       "      <td>0.508797</td>\n",
       "      <td>0.45425</td>\n",
       "      <td>0.479936</td>\n",
       "      <td>0.00831406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SGD_Words</td>\n",
       "      <td>0.50375</td>\n",
       "      <td>0.508646</td>\n",
       "      <td>0.466641</td>\n",
       "      <td>0.482942</td>\n",
       "      <td>0.00809928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kNN_Words</td>\n",
       "      <td>0.4995</td>\n",
       "      <td>0.503621</td>\n",
       "      <td>0.513021</td>\n",
       "      <td>0.508018</td>\n",
       "      <td>-0.00121244</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Model test_acc_mean test_prec_mean test_recall_mean  \\\n",
       "0       LR_Count_Vectors      0.864875       0.860838         0.873539   \n",
       "0    LR_WordLevel_TF-IDF         0.875       0.860478         0.897839   \n",
       "0       NB_Count_Vectors       0.83775       0.858464         0.812297   \n",
       "0    NB_WordLevel_TF-IDF      0.848625       0.858343         0.838333   \n",
       "0   SGD_WordLevel_TF-IDF        0.8595       0.850558         0.875518   \n",
       "0      SGD_Count_Vectors      0.841875       0.849118         0.835841   \n",
       "0    RF_WordLevel_TF-IDF      0.837875       0.846943         0.828168   \n",
       "0       RF_Count_Vectors         0.839        0.83936         0.842048   \n",
       "0    LR_CharLevel_TF-IDF      0.836625        0.82634         0.855938   \n",
       "0  SGD_CharLevel_Vectors         0.826       0.822643         0.841297   \n",
       "0    NB_CharLevel_TF-IDF      0.806125       0.799832         0.820975   \n",
       "0    RF_CharLevel_TF-IDF      0.788875       0.787647         0.795936   \n",
       "0   kNN_WordLevel_TF-IDF      0.762875       0.769554         0.756004   \n",
       "0       NB_N-Gram_TF-IDF      0.740375       0.757976         0.712617   \n",
       "0       LR_N-Gram_TF-IDF      0.737625       0.732122         0.756261   \n",
       "0   kNN_CharLevel_TF-IDF      0.690625       0.728211         0.617397   \n",
       "0       RF_N-Gram_TF-IDF        0.7165       0.726316         0.702456   \n",
       "0     SGD_N-Gram_Vectors         0.717       0.715117         0.729238   \n",
       "0      kNN_Count_Vectors        0.6485       0.608261         0.862147   \n",
       "0               RF_Words      0.531125       0.536064         0.518212   \n",
       "0      kNN_N-Gram_TF-IDF      0.519625       0.513571         0.902312   \n",
       "0               LR_Words         0.506       0.509306         0.549217   \n",
       "0               NB_Words       0.50375       0.508797          0.45425   \n",
       "0              SGD_Words       0.50375       0.508646         0.466641   \n",
       "0              kNN_Words        0.4995       0.503621         0.513021   \n",
       "\n",
       "  test_f1-score_mean test_cohens_kappa_mean  \n",
       "0            0.86693               0.729696  \n",
       "0           0.878624               0.749891  \n",
       "0           0.834669               0.675619  \n",
       "0           0.848133               0.697284  \n",
       "0           0.862576               0.718909  \n",
       "0           0.841836               0.683762  \n",
       "0           0.837404               0.675786  \n",
       "0           0.840587               0.677964  \n",
       "0            0.84083               0.673128  \n",
       "0           0.829343               0.651886  \n",
       "0            0.81021               0.612136  \n",
       "0           0.791684               0.577684  \n",
       "0           0.762578               0.525786  \n",
       "0           0.734538               0.480969  \n",
       "0           0.743915               0.475072  \n",
       "0           0.667859               0.381979  \n",
       "0           0.714115               0.433119  \n",
       "0           0.721952               0.433871  \n",
       "0           0.712317               0.294476  \n",
       "0           0.526871              0.0624352  \n",
       "0           0.654385              0.0330878  \n",
       "0           0.528472               0.011288  \n",
       "0           0.479936             0.00831406  \n",
       "0           0.482942             0.00809928  \n",
       "0           0.508018            -0.00121244  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results[[\"Model\",\"test_acc_mean\", \"test_prec_mean\", \"test_recall_mean\", \"test_f1-score_mean\", \"test_cohens_kappa_mean\"]].sort_values(by=[\"test_prec_mean\"], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h2>Gradient Boosting</h2></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 46.9 ms, sys: 15.6 ms, total: 62.5 ms\n",
      "Wall time: 1min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if gradient_boosting:\n",
    "    df_results = df_results.append(report(ensemble.GradientBoostingClassifier(n_estimators=1000,\n",
    "                                               validation_fraction=0.2,\n",
    "                                               n_iter_no_change=10, tol=0.01,\n",
    "                                               random_state=0, verbose=0 ), xtrain_count,train_y_sw, name='GB_Count_Vectors', cv=5, dict_scoring=score_metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 46.9 ms, sys: 62.5 ms, total: 109 ms\n",
      "Wall time: 45 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if gradient_boosting:\n",
    "    df_results = df_results.append(report(ensemble.GradientBoostingClassifier(n_estimators=1000,\n",
    "                                               validation_fraction=0.2,\n",
    "                                               n_iter_no_change=10, tol=0.01,\n",
    "                                               random_state=0, verbose=0 ), xtrain_tfidf,train_y, name='GB_WordLevel_TF-IDF', cv=5, dict_scoring=score_metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 78.1 ms, sys: 0 ns, total: 78.1 ms\n",
      "Wall time: 3.91 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if gradient_boosting:\n",
    "    df_results = df_results.append(report(ensemble.GradientBoostingClassifier(n_estimators=1000,\n",
    "                                               validation_fraction=0.2,\n",
    "                                               n_iter_no_change=10, tol=0.01,\n",
    "                                               random_state=0, verbose=0 ), xtrain_tfidf_ngram,train_y, name='GB_N-Gram_TF-IDF', cv=5, dict_scoring=score_metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 78.1 ms, sys: 93.8 ms, total: 172 ms\n",
      "Wall time: 6min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if gradient_boosting:\n",
    "    df_results = df_results.append(report(ensemble.GradientBoostingClassifier(n_estimators=1000,\n",
    "                                               validation_fraction=0.2,\n",
    "                                               n_iter_no_change=10, tol=0.01,\n",
    "                                               random_state=0, verbose=0 ), xtrain_tfidf_ngram_chars,train_y, name='GB_CharLevel_TF-IDF', cv=5, dict_scoring=score_metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 46.9 ms, sys: 31.2 ms, total: 78.1 ms\n",
      "Wall time: 7.03 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if gradient_boosting:\n",
    "    df_results = df_results.append(report(ensemble.GradientBoostingClassifier(n_estimators=1000,\n",
    "                                               validation_fraction=0.2,\n",
    "                                               n_iter_no_change=10, tol=0.01,\n",
    "                                               random_state=0, verbose=0 ), train_seq_x,train_y, name='GB_Words', cv=5, dict_scoring=score_metrics))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>XGBoost Classifier</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the XGBoost have early stopping implemented with 10 rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 62.5 ms, sys: 78.1 ms, total: 141 ms\n",
      "Wall time: 31.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if xgboost_classifier:\n",
    "    fit_params={'early_stopping_rounds':10,\\\n",
    "                         'eval_set':[(xvalid_count, valid_y_sw)]}\n",
    "    df_results = df_results.append(report(XGBClassifier(n_estimators=1000, subsample=0.8), xtrain_count,train_y_sw, name='XGB_Count_Vectors', cv=5, fit_params=fit_params, dict_scoring=score_metrics))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 31.2 ms, sys: 62.5 ms, total: 93.8 ms\n",
      "Wall time: 24.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if xgboost_classifier:\n",
    "    fit_params={'early_stopping_rounds':10,\\\n",
    "                         'eval_set':[(xvalid_tfidf, valid_y_sw)]}\n",
    "    df_results = df_results.append(report(XGBClassifier(n_estimators=1000, subsample=0.8), xtrain_tfidf,train_y, name='XGB_WordLevel_TF-IDF', cv=5, fit_params=fit_params, dict_scoring=score_metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 62.5 ms, sys: 46.9 ms, total: 109 ms\n",
      "Wall time: 5.46 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if xgboost_classifier:\n",
    "    fit_params={'early_stopping_rounds':10,\\\n",
    "                         'eval_set':[(xvalid_tfidf_ngram, valid_y_sw)]}\n",
    "    df_results = df_results.append(report(XGBClassifier(n_estimators=1000, subsample=0.8), xtrain_tfidf_ngram,train_y, name='XGB_N-Gram_TF-IDF', cv=5, fit_params=fit_params, dict_scoring=score_metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 46.9 ms, sys: 125 ms, total: 172 ms\n",
      "Wall time: 3min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if xgboost_classifier:\n",
    "    fit_params={'early_stopping_rounds':10,\\\n",
    "                         'eval_set':[(xvalid_tfidf_ngram_chars, valid_y_sw)]}\n",
    "    df_results = df_results.append(report(XGBClassifier(n_estimators=1000, subsample=0.8), xtrain_tfidf_ngram_chars,train_y, name='XGB_CharLevel_TF-IDF', cv=5, fit_params=fit_params, dict_scoring=score_metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 78.1 ms, sys: 31.2 ms, total: 109 ms\n",
      "Wall time: 9.99 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if xgboost_classifier:\n",
    "    fit_params={'early_stopping_rounds':10,\\\n",
    "                         'eval_set':[(valid_seq_x,valid_y)]}\n",
    "    df_results = df_results.append(report(XGBClassifier(n_estimators=1000, subsample=0.8), train_seq_x,train_y, name='XGB_Words', cv=5, fit_params=fit_params, dict_scoring=score_metrics))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>Deep Learning</h1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Cohen’s kappa</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function [cohen_kappa_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.cohen_kappa_score.html#sklearn.metrics.cohen_kappa_score) computes [Cohen’s kappa](https://en.wikipedia.org/wiki/Cohen%27s_kappa) statistic. This measure is intended to compare labelings by different human annotators, not a classifier versus a ground truth.\n",
    "\n",
    "The kappa score (see docstring) is a number between -1 and 1. Scores above .8 are generally considered good agreement; zero or lower means no agreement (practically random labels).\n",
    "\n",
    "Kappa scores can be computed for binary or multiclass problems, but not for multilabel problems (except by manually computing a per-label score) and not for more than two annotators."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Balanced Accuracy</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the balanced accuracy\n",
    "\n",
    "The balanced accuracy in binary and multiclass classification problems to deal with imbalanced datasets. It is defined as the average of recall obtained on each class.\n",
    "\n",
    "The best value is 1 and the worst value is 0 when adjusted=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Early Stopping, Model saving, Class weight configuration</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = tf.keras.callbacks.EarlyStopping(monitor='loss', mode='auto', patience=3)\n",
    "check_p = tf.keras.callbacks.ModelCheckpoint(\"save_models/model.h5\", save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_w = {}\n",
    "for i in zip(range(len(class_weights)), class_weights):\n",
    "    class_w[i[0]] = i[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate_NN(model, X, y, X_test, y_test, callbacks,name=\"NN\", fit_params=None, scoring=None, n_splits=5):\n",
    "    '''\n",
    "    Function create a metric report automatically with cross_validate function.\n",
    "    @param model: (model) neural network model\n",
    "    @param X: (list or matrix or tensor) training X data\n",
    "    @param y: (list) label data \n",
    "    @param X_test: (list or matrix or tensor) testing X data\n",
    "    @param y_test: (list) label test data \n",
    "    @param callbacks: (function) callback function\n",
    "    @param name: (string) name of the model (default classifier)\n",
    "    @param fit_aparams: (dict) add parameters for model fitting \n",
    "    @param scoring: (dict) dictionary of metrics and names\n",
    "    @param n_splits: (int) number of fold for cross-validation (default 5)\n",
    "    @return: (pandas.dataframe) dataframe containing all the results of the metrics \n",
    "    for each fold and the mean and std for each of them\n",
    "    '''\n",
    "    # ---- Parameters initialisation\n",
    "    seed = 42\n",
    "    k = 1\n",
    "    np.random.seed(seed)\n",
    "    kfold = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
    "    \n",
    "    # Creation of list for each metric\n",
    "    if scoring==None:        # create a dictionary if none is passed\n",
    "        dic_scoring = {}\n",
    "    if scoring!=None:        # save the dict \n",
    "        dic_score = scoring.copy()\n",
    "        \n",
    "    dic_score[\"fit_time\"] = None   # initialisation for time fitting and scoring\n",
    "    dic_score[\"score_time\"] = None\n",
    "    scorer = {}\n",
    "    for i in dic_score.keys(): \n",
    "        scorer[i] = []\n",
    "        \n",
    "    \n",
    "    index = [\"Model\"]\n",
    "    results = [name]\n",
    "    # ---- Loop on k-fold for cross-valisation\n",
    "    for train, test in kfold.split(X, y):   # training NN on each fold \n",
    "        # create model\n",
    "        print(f\"k-fold : {k}\")\n",
    "        fit_start = time.time()\n",
    "        _model = model\n",
    "        _model.fit(X[train], y[train],\n",
    "                        epochs=1000, callbacks=[callbacks],\n",
    "                        validation_split=0.2, verbose=False)\n",
    "        \n",
    "        fit_end = time.time() - fit_start\n",
    "\n",
    "        _acc = _model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "        score_start = time.time()\n",
    "        y_pred = (model.predict(X_test)>0.5).astype(int)\n",
    "        score_end = time.time() - score_start\n",
    "\n",
    "        # ---- save each metric\n",
    "        for i in dic_score.keys():    # compute metrics \n",
    "            if i == \"fit_time\":\n",
    "                scorer[i].append(fit_end)\n",
    "                index.append(i+'_cv'+str(k))\n",
    "                results.append(fit_end)\n",
    "                continue\n",
    "            if i == \"score_time\":\n",
    "                scorer[i].append(score_end)\n",
    "                index.append(i+'_cv'+str(k))\n",
    "                results.append(score_end)\n",
    "                continue\n",
    "                \n",
    "            scorer[i].append(dic_score[i](y_test, y_pred))\n",
    "            index.append(\"test_\"+i+'_cv'+str(k))\n",
    "            results.append(scorer[i][-1])\n",
    "                \n",
    "        \n",
    "        k+=1\n",
    "        \n",
    "    # Compute mean and std for each metric\n",
    "    for i in scorer: \n",
    "        \n",
    "        results.append(np.mean(scorer[i]))\n",
    "        results.append(np.std(scorer[i]))\n",
    "        if i == \"fit_time\":\n",
    "            index.append(i+\"_mean\")\n",
    "            index.append(i+\"_std\")\n",
    "            continue\n",
    "        if i == \"score_time\":\n",
    "            index.append(i+\"_mean\")\n",
    "            index.append(i+\"_std\")\n",
    "            continue\n",
    "        \n",
    "        index.append(\"test_\"+i+\"_mean\")\n",
    "        index.append(\"test_\"+i+\"_std\")\n",
    "    \n",
    "    return pd.DataFrame(results, index=index).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Shallow Neural Networks</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shallow_neural_networks(word_index, label=labels, embedding_matrix=embedding_matrix, pre_trained=False):\n",
    "    '''\n",
    "    Function to generate a shallow neural network for binary or multiclass classification.\n",
    "    @param word_index: (matrix) unique token in corpus\n",
    "    @param label: (list) list of labels to determine if it,s a binary or multiclass\n",
    "    @param embedding_matrix: (matrix) matrix of integer for each word in the \n",
    "    @param pre_trained: (bool) determine if the model will use pretrained model\n",
    "    @return: (model) shallow neural network \n",
    "    '''\n",
    "    if pre_trained==False:\n",
    "        embedded = keras.layers.Embedding(len(word_index) + 1, 16)\n",
    "    else:\n",
    "        embedded = keras.layers.Embedding(len(word_index) + 1, 300, weights=[embedding_matrix], trainable=False)\n",
    "    \n",
    "    model = keras.Sequential([\n",
    "      embedded,\n",
    "      keras.layers.GlobalAveragePooling1D(),\n",
    "      \n",
    "      keras.layers.Dense(1 if len(label)<=2 else len(label), activation='sigmoid' if len(label)<=2 else \"softmax\")])\n",
    "\n",
    "    if len(label)==2: # binary\n",
    "        model.compile(optimizer='adam',\n",
    "              loss=tf.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "    else:  # multiclass \n",
    "        model.compile(optimizer='adam',\n",
    "              loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k-fold : 1\n",
      "k-fold : 2\n",
      "k-fold : 3\n",
      "k-fold : 4\n",
      "k-fold : 5\n",
      "CPU times: user 34min 11s, sys: 1min 52s, total: 36min 4s\n",
      "Wall time: 13min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if shallow_network:\n",
    "    df_results = df_results.append(cross_validate_NN(shallow_neural_networks(word_index, pre_trained=pre_trained), train_seq_x, train_y, valid_seq_x, valid_y, es, name=\"Shallow_NN_WE\", scoring=score_metrics, n_splits=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#c = cross_validate_NN(shallow_neural_networks(word_index, pre_trained=pre_trained), train_seq_x[:100], train_y[:100], valid_seq_x[:100], valid_y[:100], es, name=\"Shallow_NN_WE\", scoring=score_metrics, n_splits=2)\n",
    "#c[[\"test_acc_cv1\", \"test_recall_cv1\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Deep Neural Networks</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deep_neural_networks(word_index, label=labels, embedding_matrix=embedding_matrix, pre_trained=False):\n",
    "    '''\n",
    "    Function to generate a deep neural network for binary or multiclass classification.\n",
    "    @param word_index: (matrix) unique token in corpus\n",
    "    @param label: (list) list of labels to determine if it,s a binary or multiclass\n",
    "    @param embedding_matrix: (matrix) matrix of integer for each word in the \n",
    "    @param pre_trained: (bool) determine if the model will use pretrained model\n",
    "    @return: (model) deep neural network \n",
    "    '''\n",
    "    if pre_trained==False:\n",
    "        embedded = keras.layers.Embedding(len(word_index) + 1, 50)\n",
    "    else:\n",
    "        embedded = keras.layers.Embedding(len(word_index) + 1, 300, weights=[embedding_matrix], trainable=False)\n",
    "    \n",
    "    model = keras.Sequential([\n",
    "      embedded,\n",
    "      keras.layers.GlobalAveragePooling1D(),\n",
    "      keras.layers.Dense(16, activation='relu'),\n",
    "      keras.layers.Dense(1 if len(label)<=2 else len(label), activation='sigmoid' if len(label)<=2 else \"softmax\")])\n",
    "\n",
    "    if len(label)==2:\n",
    "        model.compile(optimizer='adam',\n",
    "              loss=tf.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "    else: \n",
    "        model.compile(optimizer='adam',\n",
    "              loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "    #print(model.summary())\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k-fold : 1\n",
      "k-fold : 2\n",
      "k-fold : 3\n",
      "k-fold : 4\n",
      "k-fold : 5\n",
      "CPU times: user 1h 19min 31s, sys: 1h 12min 51s, total: 2h 32min 22s\n",
      "Wall time: 59min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if deep_nn:\n",
    "    df_results = df_results.append(cross_validate_NN(deep_neural_networks(word_index, pre_trained=pre_trained), train_seq_x, train_y, valid_seq_x, valid_y, es, name=\"Deep_NN_WE\",scoring=score_metrics, n_splits=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Deep Neural Networks variation 1</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deep_neural_networks_var1(word_index, label=labels, embedding_matrix=embedding_matrix, pre_trained=False):\n",
    "    '''\n",
    "    Function to generate a deep neural network for binary or multiclass classification.\n",
    "    @param word_index: (matrix) unique token in corpus\n",
    "    @param label: (list) list of labels to determine if it,s a binary or multiclass\n",
    "    @param embedding_matrix: (matrix) matrix of integer for each word in the \n",
    "    @param pre_trained: (bool) determine if the model will use pretrained model\n",
    "    @return: (model) deep neural network \n",
    "    '''\n",
    "    if pre_trained==False:\n",
    "        embedded = keras.layers.Embedding(len(word_index) + 1, 100)\n",
    "    else:\n",
    "        embedded = keras.layers.Embedding(len(word_index) + 1, 300, weights=[embedding_matrix], trainable=False)\n",
    "    \n",
    "    model = keras.Sequential([\n",
    "      embedded,\n",
    "      keras.layers.GlobalAveragePooling1D(),\n",
    "      keras.layers.Dense(16, activation='relu'),\n",
    "      keras.layers.Dense(16, activation='relu'),\n",
    "      keras.layers.Dense(1  if len(label)<=2 else len(label), activation='sigmoid' if len(label)<=2 else \"softmax\")])\n",
    "\n",
    "    if len(label)==2:\n",
    "        model.compile(optimizer='adam',\n",
    "              loss=tf.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "    else: \n",
    "        model.compile(optimizer='adam',\n",
    "              loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "    #print(model.summary())\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k-fold : 1\n",
      "k-fold : 2\n",
      "k-fold : 3\n",
      "k-fold : 4\n",
      "k-fold : 5\n",
      "CPU times: user 1h 35min 32s, sys: 1h 18min 44s, total: 2h 54min 17s\n",
      "Wall time: 1h 4min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if deep_nn:\n",
    "    df_results = df_results.append(cross_validate_NN(deep_neural_networks_var1(word_index, pre_trained=pre_trained), train_seq_x, train_y, valid_seq_x, valid_y, es, name=\"Deep_NN_var1_WE\",scoring=score_metrics, n_splits=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Deep Neural Networks variation 2</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deep_neural_networks_var2(word_index, label=labels, embedding_matrix=embedding_matrix, pre_trained=False):\n",
    "    '''\n",
    "    Function to generate a deep neural network for binary or multiclass classification.\n",
    "    @param word_index: (matrix) unique token in corpus\n",
    "    @param label: (list) list of labels to determine if it,s a binary or multiclass\n",
    "    @param embedding_matrix: (matrix) matrix of integer for each word in the \n",
    "    @param pre_trained: (bool) determine if the model will use pretrained model\n",
    "    @return: (model) deep neural network \n",
    "    '''\n",
    "    if pre_trained==False:\n",
    "        embedded = keras.layers.Embedding(len(word_index) + 1, 100)\n",
    "    else:\n",
    "        embedded = keras.layers.Embedding(len(word_index) + 1, 300, weights=[embedding_matrix], trainable=False)\n",
    "    \n",
    "    model = keras.Sequential([\n",
    "      embedded,\n",
    "      keras.layers.GlobalAveragePooling1D(),\n",
    "      keras.layers.Dense(32, activation='relu'),\n",
    "      keras.layers.Dense(16, activation='relu'),\n",
    "      keras.layers.Dense(1  if len(label)<=2 else len(label), activation='sigmoid' if len(label)<=2 else \"softmax\")])\n",
    "\n",
    "    if len(label)==2:\n",
    "        model.compile(optimizer='adam',\n",
    "              loss=tf.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "    else: \n",
    "        model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=1e-4),\n",
    "              loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "    #print(model.summary())\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k-fold : 1\n",
      "k-fold : 2\n",
      "k-fold : 3\n",
      "k-fold : 4\n",
      "k-fold : 5\n",
      "CPU times: user 1h 20min 45s, sys: 1h 30min 18s, total: 2h 51min 4s\n",
      "Wall time: 1h 6min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if deep_nn:\n",
    "    df_results = df_results.append(cross_validate_NN(deep_neural_networks_var2(word_index, pre_trained=pre_trained), train_seq_x, train_y, valid_seq_x, valid_y, es, name=\"Deep_NN_var2_WE\",scoring=score_metrics, n_splits=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Recurent Neural Network - RNN</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_rnn_model(word_index, label=labels, embedding_matrix=embedding_matrix, pre_trained=False):\n",
    "    '''\n",
    "    Function to generate a recurrent neural network for binary or multiclass classification.\n",
    "    @param word_index: (matrix) unique token in corpus\n",
    "    @param label: (list) list of labels to determine if it,s a binary or multiclass\n",
    "    @param embedding_matrix: (matrix) matrix of integer for each word in the \n",
    "    @param pre_trained: (bool) determine if the model will use pretrained model\n",
    "    @return: (model) recurrent neural network \n",
    "    '''\n",
    "    if pre_trained==False:\n",
    "        embedded = keras.layers.Embedding(len(word_index) + 1, 100)\n",
    "    else:\n",
    "        embedded = keras.layers.Embedding(len(word_index) + 1, 300, weights=[embedding_matrix], trainable=False)\n",
    "    \n",
    "    model = keras.Sequential([\n",
    "    embedded,\n",
    "    keras.layers.SimpleRNN(40, return_sequences=True),\n",
    "    keras.layers.SimpleRNN(40, return_sequences=True),\n",
    "    keras.layers.SimpleRNN(40, return_sequences=True),\n",
    "    keras.layers.SimpleRNN(40),\n",
    "    keras.layers.Dense(1 if len(label)<=2 else len(label), activation='sigmoid' if len(label)<=2 else \"softmax\")])\n",
    "\n",
    "    if len(label)==2:\n",
    "        model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=1e-4),\n",
    "              loss=tf.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "    else: \n",
    "        model.compile(optimizer='adam',\n",
    "              loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "    #print(model.summary())\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k-fold : 1\n",
      "k-fold : 2\n",
      "k-fold : 3\n",
      "k-fold : 4\n",
      "k-fold : 5\n",
      "CPU times: user 3h 54min 23s, sys: 40min 29s, total: 4h 34min 52s\n",
      "Wall time: 1h 36min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if rnn:\n",
    "    df_results = df_results.append(cross_validate_NN(create_rnn_model(word_index, pre_trained=pre_trained), train_seq_x, train_y, valid_seq_x, valid_y, es, name=\"RNN_WE\",scoring=score_metrics, n_splits=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Convolutional Neural Network</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_conv_model(word_index, label=labels, embedding_matrix=embedding_matrix, pre_trained=False):\n",
    "    '''\n",
    "    Function to generate a convulational neural network for binary or multiclass classification.\n",
    "    @param word_index: (matrix) unique token in corpus\n",
    "    @param label: (list) list of labels to determine if it,s a binary or multiclass\n",
    "    @param embedding_matrix: (matrix) matrix of integer for each word in the \n",
    "    @param pre_trained: (bool) determine if the model will use pretrained model\n",
    "    @return: (model) convulational neural network \n",
    "    '''\n",
    "    if pre_trained==False:\n",
    "        embedded = keras.layers.Embedding(len(word_index) +1, 100)\n",
    "    else:\n",
    "        embedded = keras.layers.Embedding(len(word_index) + 1, 300, weights=[embedding_matrix], trainable=False)\n",
    "    \n",
    "    model = keras.Sequential([\n",
    "    embedded,\n",
    "    keras.layers.Conv1D(100, 5, activation='relu'), # padding='same'\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.MaxPooling1D(pool_size=4),\n",
    "    keras.layers.Conv1D(64, 5, activation='relu'),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.MaxPooling1D(pool_size=4),\n",
    "    keras.layers.Conv1D(32, 5, activation='relu'),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.GlobalMaxPooling1D(),\n",
    "\n",
    "    keras.layers.Dense(1 if len(label)<=2 else len(label), activation='sigmoid' if len(label)<=2 else \"softmax\")])\n",
    "\n",
    "    if len(label)==2:\n",
    "        model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=1e-4),\n",
    "              loss=tf.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "    else: \n",
    "        model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=1e-4),\n",
    "              loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "    #print(model.summary())\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k-fold : 1\n",
      "k-fold : 2\n",
      "k-fold : 3\n",
      "k-fold : 4\n",
      "k-fold : 5\n",
      "CPU times: user 3h 38min 51s, sys: 40min 40s, total: 4h 19min 32s\n",
      "Wall time: 1h 30min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if cnn:\n",
    "    df_results = df_results.append(cross_validate_NN(create_rnn_model(word_index, pre_trained=pre_trained), train_seq_x, train_y, valid_seq_x, valid_y, es, name=\"CNN_WE\",scoring=score_metrics, n_splits=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Recurrent Neural Network – LSTM</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lstm_model(word_index, label=labels, embedding_matrix=embedding_matrix, pre_trained=False):\n",
    "    '''\n",
    "    Function to generate a lstm for binary or multiclass classification.\n",
    "    @param word_index: (matrix) unique token in corpus\n",
    "    @param label: (list) list of labels to determine if it,s a binary or multiclass\n",
    "    @param embedding_matrix: (matrix) matrix of integer for each word in the \n",
    "    @param pre_trained: (bool) determine if the model will use pretrained model\n",
    "    @return: (model)lstm \n",
    "    '''\n",
    "    if pre_trained==False:\n",
    "        embedded = keras.layers.Embedding(len(word_index) +1, 100)\n",
    "    else:\n",
    "        embedded = keras.layers.Embedding(len(word_index)+1, 300, weights=[embedding_matrix], trainable=False)\n",
    "    \n",
    "    model = keras.Sequential([\n",
    "    embedded,\n",
    "    keras.layers.LSTM(32),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(1 if len(label)<=2 else len(label), activation='sigmoid' if len(label)<=2 else \"softmax\")])\n",
    "\n",
    "    if len(label)==2:\n",
    "        model.compile(optimizer='adam',\n",
    "              loss=tf.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "    else: \n",
    "        model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=1e-4),\n",
    "              loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "    #print(model.summary())\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k-fold : 1\n",
      "k-fold : 2\n",
      "k-fold : 3\n",
      "k-fold : 4\n",
      "k-fold : 5\n",
      "CPU times: user 1h 38min 51s, sys: 27min 32s, total: 2h 6min 24s\n",
      "Wall time: 40min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if lstm:\n",
    "    df_results = df_results.append(cross_validate_NN(create_lstm_model(word_index, pre_trained=pre_trained), train_seq_x, train_y, valid_seq_x, valid_y, es, name=\"LSTM_WE\",scoring=score_metrics, n_splits=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>CNN – LSTM</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn_lstm_model(word_index, label=labels, embedding_matrix=embedding_matrix, pre_trained=False):\n",
    "    '''\n",
    "    Function to generate a convulational neural network lstm for binary or multiclass classification.\n",
    "    @param word_index: (matrix) unique token in corpus\n",
    "    @param label: (list) list of labels to determine if it,s a binary or multiclass\n",
    "    @param embedding_matrix: (matrix) matrix of integer for each word in the \n",
    "    @param pre_trained: (bool) determine if the model will use pretrained model\n",
    "    @return: (model) convulational neural network lstm\n",
    "    '''\n",
    "    if pre_trained==False:\n",
    "        embedded = keras.layers.Embedding(len(word_index) + 1, 100)\n",
    "    else:\n",
    "        embedded = keras.layers.Embedding(len(word_index) + 1, 300, weights=[embedding_matrix], trainable=False)\n",
    "    \n",
    "    model = keras.Sequential([\n",
    "    embedded,\n",
    "    keras.layers.Conv1D(128, 5, activation='relu'),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.MaxPooling1D(pool_size=4),\n",
    "    keras.layers.LSTM(32),\n",
    "    keras.layers.Dense(1 if len(label)<=2 else len(label), activation='sigmoid' if len(label)<=2 else \"softmax\")])\n",
    "\n",
    "    if len(label)==2:\n",
    "        model.compile(optimizer='adam',\n",
    "              loss=tf.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "    else: \n",
    "        model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=1e-4),\n",
    "              loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "    #print(model.summary())\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k-fold : 1\n",
      "k-fold : 2\n",
      "k-fold : 3\n",
      "k-fold : 4\n",
      "k-fold : 5\n",
      "CPU times: user 4h 14min 33s, sys: 1h 12min 50s, total: 5h 27min 23s\n",
      "Wall time: 1h 38min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if cnn_lstm:\n",
    "    df_results = df_results.append(cross_validate_NN(create_cnn_lstm_model(word_index, pre_trained=pre_trained), train_seq_x, train_y, valid_seq_x, valid_y, es,name=\"CNN_LSTM_WE\", scoring=score_metrics, n_splits=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>CNN – GRU</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn_gru_model(word_index, label=labels, embedding_matrix=embedding_matrix, pre_trained=False):\n",
    "    '''\n",
    "    Function to generate a convulational neural network GRU for binary or multiclass classification.\n",
    "    @param word_index: (matrix) unique token in corpus\n",
    "    @param label: (list) list of labels to determine if it,s a binary or multiclass\n",
    "    @param embedding_matrix: (matrix) matrix of integer for each word in the \n",
    "    @param pre_trained: (bool) determine if the model will use pretrained model\n",
    "    @return: (model) convulational neural network GRU\n",
    "    '''\n",
    "    if pre_trained==False:\n",
    "        embedded = keras.layers.Embedding(len(word_index) + 1, 100)\n",
    "    else:\n",
    "        embedded = keras.layers.Embedding(len(word_index) + 1, 300, weights=[embedding_matrix], trainable=False)\n",
    "    \n",
    "    model = keras.Sequential([\n",
    "    embedded,\n",
    "    keras.layers.Conv1D(128, 5, activation='relu'),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.MaxPooling1D(pool_size=4),\n",
    "    keras.layers.GRU(32),\n",
    "    keras.layers.Dense(1 if len(label)<=2 else len(label), activation='sigmoid' if len(label)<=2 else \"softmax\")])\n",
    "\n",
    "    if len(label)==2:\n",
    "        model.compile(optimizer='adam',\n",
    "              loss=tf.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "    else: \n",
    "        model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=1e-4),\n",
    "              loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "    #print(model.summary())\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k-fold : 1\n",
      "k-fold : 2\n",
      "k-fold : 3\n",
      "k-fold : 4\n",
      "k-fold : 5\n",
      "CPU times: user 3h 5min 18s, sys: 32min 17s, total: 3h 37min 36s\n",
      "Wall time: 1h 5min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if cnn_gru:\n",
    "    df_results = df_results.append(cross_validate_NN(create_cnn_gru_model(word_index, pre_trained=pre_trained), train_seq_x, train_y, valid_seq_x, valid_y, es, name=\"CNN_GRU_WE\", scoring=score_metrics, n_splits=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Recurrent Neural Network – GRU</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.keras.layers.GRU(\n",
    "    units, activation='tanh', recurrent_activation='sigmoid', use_bias=True,\n",
    "    kernel_initializer='glorot_uniform', recurrent_initializer='orthogonal',\n",
    "    bias_initializer='zeros', kernel_regularizer=None, recurrent_regularizer=None,\n",
    "    bias_regularizer=None, activity_regularizer=None, kernel_constraint=None,\n",
    "    recurrent_constraint=None, bias_constraint=None, dropout=0.0,\n",
    "    recurrent_dropout=0.0, implementation=2, return_sequences=False,\n",
    "    return_state=False, go_backwards=False, stateful=False, unroll=False,\n",
    "    time_major=False, reset_after=True, **kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gru_model(word_index, label=labels, embedding_matrix=embedding_matrix, pre_trained=False):\n",
    "    '''\n",
    "    Function to generate a GRU for binary or multiclass classification.\n",
    "    @param word_index: (matrix) unique token in corpus\n",
    "    @param label: (list) list of labels to determine if it,s a binary or multiclass\n",
    "    @param embedding_matrix: (matrix) matrix of integer for each word in the \n",
    "    @param pre_trained: (bool) determine if the model will use pretrained model\n",
    "    @return: (model) GRU\n",
    "    '''\n",
    "    if pre_trained==False:\n",
    "        embedded = keras.layers.Embedding(len(word_index) + 1, 100)\n",
    "    else:\n",
    "        embedded = keras.layers.Embedding(len(word_index) + 1, 300, weights=[embedding_matrix], trainable=False)\n",
    "    \n",
    "    model = keras.Sequential([\n",
    "    embedded,\n",
    "    keras.layers.GRU(32),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(1 if len(label)<=2 else len(label), activation='sigmoid' if len(label)<=2 else \"softmax\")])\n",
    "\n",
    "    if len(label)==2:\n",
    "        model.compile(optimizer='adam',\n",
    "              loss=tf.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "    else: \n",
    "        model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=1e-4),\n",
    "              loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "    #print(model.summary())\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k-fold : 1\n",
      "k-fold : 2\n",
      "k-fold : 3\n",
      "k-fold : 4\n",
      "k-fold : 5\n",
      "CPU times: user 2h 34min 50s, sys: 40min 43s, total: 3h 15min 34s\n",
      "Wall time: 1h 3min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if gru:\n",
    "    df_results = df_results.append(cross_validate_NN(create_gru_model(word_index, pre_trained=pre_trained), train_seq_x, train_y, valid_seq_x, valid_y, es, name=\"GRU_WE\", scoring=score_metrics, n_splits=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Bidirectional RNN</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bidirec_rnn_model(word_index, label=labels, embedding_matrix=embedding_matrix, pre_trained=False):\n",
    "    '''\n",
    "    Function to generate a bidirectionnal rnn for binary or multiclass classification.\n",
    "    @param word_index: (matrix) unique token in corpus\n",
    "    @param label: (list) list of labels to determine if it,s a binary or multiclass\n",
    "    @param embedding_matrix: (matrix) matrix of integer for each word in the \n",
    "    @param pre_trained: (bool) determine if the model will use pretrained model\n",
    "    @return: (model) bidirectionnal rnn\n",
    "    '''\n",
    "    if pre_trained==False:\n",
    "        embedded = keras.layers.Embedding(len(word_index) + 1, 100)\n",
    "    else:\n",
    "        embedded = keras.layers.Embedding(len(word_index) + 1, 300, weights=[embedding_matrix], trainable=False)\n",
    "    \n",
    "    model = keras.Sequential([\n",
    "    embedded,\n",
    "    keras.layers.Bidirectional(keras.layers.SimpleRNN(32, return_sequences=True)),\n",
    "    keras.layers.Bidirectional(keras.layers.SimpleRNN(32, return_sequences=True)),\n",
    "    keras.layers.Bidirectional(keras.layers.SimpleRNN(32, return_sequences=True)),\n",
    "    keras.layers.Bidirectional(keras.layers.SimpleRNN(32)),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(1 if len(label)<=2 else len(label), activation='sigmoid' if len(label)<=2 else \"softmax\")])\n",
    "\n",
    "    if len(label)==2:\n",
    "        model.compile(optimizer='adam',\n",
    "              loss=tf.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "    else: \n",
    "        model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=1e-4),\n",
    "              loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "    #print(model.summary())\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k-fold : 1\n",
      "k-fold : 2\n",
      "k-fold : 3\n",
      "k-fold : 4\n",
      "k-fold : 5\n",
      "CPU times: user 4h 36min 49s, sys: 39min 4s, total: 5h 15min 53s\n",
      "Wall time: 1h 43min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if bidirectional_rnn:\n",
    "    df_results = df_results.append(cross_validate_NN(create_bidirec_rnn_model(word_index, pre_trained=pre_trained), train_seq_x, train_y, valid_seq_x, valid_y, es, name=\"BiRNN_WE\",scoring=score_metrics, n_splits=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Bidirectional LSTM</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bidirec_lstm_model(word_index, label=labels, embedding_matrix=embedding_matrix, pre_trained=False):\n",
    "    '''\n",
    "    Function to generate a bidirectionnal lstm for binary or multiclass classification.\n",
    "    @param word_index: (matrix) unique token in corpus\n",
    "    @param label: (list) list of labels to determine if it,s a binary or multiclass\n",
    "    @param embedding_matrix: (matrix) matrix of integer for each word in the \n",
    "    @param pre_trained: (bool) determine if the model will use pretrained model\n",
    "    @return: (model) bidirectionnal lstm\n",
    "    '''\n",
    "    if pre_trained==False:\n",
    "        embedded = keras.layers.Embedding(len(word_index) + 1, 100)\n",
    "    else:\n",
    "        embedded = keras.layers.Embedding(len(word_index) + 1, 300, weights=[embedding_matrix], trainable=False)\n",
    "    \n",
    "    model = keras.Sequential([\n",
    "    embedded,\n",
    "    keras.layers.Bidirectional(keras.layers.LSTM(32)),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(1 if len(label)<=2 else len(label), activation='sigmoid' if len(label)<=2 else \"softmax\")])\n",
    "\n",
    "    if len(label)==2:\n",
    "        model.compile(optimizer='adam',\n",
    "              loss=tf.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "    else: \n",
    "        model.compile(optimizer=tf.keras.optimizers.RMSprop(1e-4),\n",
    "              loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "    #print(model.summary())\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k-fold : 1\n",
      "k-fold : 2\n",
      "k-fold : 3\n",
      "k-fold : 4\n",
      "k-fold : 5\n",
      "CPU times: user 3h 15min 50s, sys: 20min 33s, total: 3h 36min 24s\n",
      "Wall time: 1h 8min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if bidirectional_lstm:\n",
    "    df_results = df_results.append(cross_validate_NN(create_bidirec_lstm_model(word_index, pre_trained=pre_trained), train_seq_x, train_y, valid_seq_x, valid_y, es, name=\"BiLSTM_WE\",scoring=score_metrics, n_splits=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Bidirectional GRU</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bidirec_gru_model(word_index, label=labels, embedding_matrix=embedding_matrix, pre_trained=False):\n",
    "    '''\n",
    "    Function to generate a bidirectionnal gru for binary or multiclass classification.\n",
    "    @param word_index: (matrix) unique token in corpus\n",
    "    @param label: (list) list of labels to determine if it,s a binary or multiclass\n",
    "    @param embedding_matrix: (matrix) matrix of integer for each word in the \n",
    "    @param pre_trained: (bool) determine if the model will use pretrained model\n",
    "    @return: (model) bidirectionnal gru\n",
    "    '''\n",
    "    if pre_trained==False:\n",
    "        embedded = keras.layers.Embedding(len(word_index) + 1, 100)\n",
    "    else:\n",
    "        embedded = keras.layers.Embedding(len(word_index) + 1, 300, weights=[embedding_matrix], trainable=False)\n",
    "    \n",
    "    model = keras.Sequential([\n",
    "    embedded,\n",
    "    keras.layers.Bidirectional(keras.layers.GRU(32)),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(1 if len(label)<=2 else len(label), activation='sigmoid' if len(label)<=2 else \"softmax\")])\n",
    "\n",
    "    if len(label)==2:\n",
    "        model.compile(optimizer='adam',\n",
    "              loss=tf.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "    else: \n",
    "        model.compile(optimizer=tf.keras.optimizers.RMSprop(1e-4),\n",
    "              loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "    #print(model.summary())\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k-fold : 1\n",
      "k-fold : 2\n",
      "k-fold : 3\n",
      "k-fold : 4\n",
      "k-fold : 5\n",
      "CPU times: user 1h 37min 47s, sys: 23min 45s, total: 2h 1min 32s\n",
      "Wall time: 40min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if bidirectional_gru:\n",
    "    df_results = df_results.append(cross_validate_NN(create_bidirec_gru_model(word_index, pre_trained=pre_trained), train_seq_x, train_y, valid_seq_x, valid_y, es, name=\"BiGRU_WE\",scoring=score_metrics, n_splits=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Recurrent Convolutional Neural Network</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_rcnn(X, word_index, label=labels, embedding_matrix=embedding_matrix, pre_trained=False):\n",
    "    '''\n",
    "    Function to generate a rcnn for binary or multiclass classification.\n",
    "    @param word_index: (matrix) unique token in corpus\n",
    "    @param label: (list) list of labels to determine if it,s a binary or multiclass\n",
    "    @param embedding_matrix: (matrix) matrix of integer for each word in the \n",
    "    @param pre_trained: (bool) determine if the model will use pretrained model\n",
    "    @return: (model)  rcnn\n",
    "    '''\n",
    "    if pre_trained==False:\n",
    "        embedded = keras.layers.Embedding(len(word_index) + 1, 100)\n",
    "    else:\n",
    "        embedded = keras.layers.Embedding(len(word_index) + 1, 300,input_length=X.shape[1], weights=[embedding_matrix], trainable=False)\n",
    "    \n",
    "    model = keras.Sequential([\n",
    "    embedded,\n",
    "    keras.layers.SpatialDropout1D(0.3),\n",
    "    keras.layers.Bidirectional(keras.layers.GRU(32,return_sequences=True)),\n",
    "    keras.layers.Convolution1D(32, 3, activation=\"relu\"),\n",
    "    keras.layers.GlobalMaxPool1D(),\n",
    "    keras.layers.Dense(25, activation=\"relu\"),\n",
    "    keras.layers.Dropout(0.25),\n",
    "    keras.layers.Dense(1 if len(label)<=2 else len(label), activation='sigmoid' if len(label)<=2 else \"softmax\")])\n",
    "\n",
    "    if len(label)==2:\n",
    "        model.compile(optimizer='adam',\n",
    "              loss=tf.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "    else: \n",
    "        model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=1e-4),\n",
    "              loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "    #print(model.summary())\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k-fold : 1\n",
      "k-fold : 2\n",
      "k-fold : 3\n",
      "k-fold : 4\n",
      "k-fold : 5\n",
      "CPU times: user 1h 50min 17s, sys: 33min 45s, total: 2h 24min 2s\n",
      "Wall time: 46min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if rcnn:\n",
    "    df_results = df_results.append(cross_validate_NN(create_rcnn(train_seq_x, word_index, pre_trained=pre_trained), train_seq_x, train_y, valid_seq_x, valid_y, es, name=\"RCNN_WE\",scoring=score_metrics, n_splits=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Recurrent Convolutional Neural Network variation 1</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_rcnn_var1(word_index, label=labels, embedding_matrix=embedding_matrix, pre_trained=False):\n",
    "    '''\n",
    "    Function to generate a rcnn for binary or multiclass classification.\n",
    "    @param word_index: (matrix) unique token in corpus\n",
    "    @param label: (list) list of labels to determine if it,s a binary or multiclass\n",
    "    @param embedding_matrix: (matrix) matrix of integer for each word in the \n",
    "    @param pre_trained: (bool) determine if the model will use pretrained model\n",
    "    @return: (model)  rcnn\n",
    "    '''\n",
    "    if pre_trained==False:\n",
    "        embedded = keras.layers.Embedding(len(word_index) + 1, 100)\n",
    "    else:\n",
    "        embedded = keras.layers.Embedding(len(word_index) + 1, 300, weights=[embedding_matrix], trainable=False)\n",
    "    \n",
    "    model = keras.Sequential([\n",
    "    embedded,\n",
    "    keras.layers.SpatialDropout1D(0.3),\n",
    "    keras.layers.Bidirectional(keras.layers.LSTM(32,return_sequences=True)),\n",
    "    keras.layers.Convolution1D(32, 3, activation=\"relu\"),\n",
    "    keras.layers.GlobalMaxPool1D(),\n",
    "    keras.layers.Dense(25, activation=\"relu\"),\n",
    "    keras.layers.Dropout(0.25),\n",
    "    keras.layers.Dense(1 if len(label)<=2 else len(label), activation='sigmoid' if len(label)<=2 else \"softmax\")])\n",
    "\n",
    "    if len(label)==2:\n",
    "        model.compile(optimizer='adam',\n",
    "              loss=tf.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "    else: \n",
    "        model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=1e-4),\n",
    "              loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "    #print(model.summary())\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k-fold : 1\n",
      "k-fold : 2\n",
      "k-fold : 3\n",
      "k-fold : 4\n",
      "k-fold : 5\n",
      "CPU times: user 2h 34min 25s, sys: 39min 14s, total: 3h 13min 39s\n",
      "Wall time: 57min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if rcnn:\n",
    "    df_results = df_results.append(cross_validate_NN(create_rcnn_var1(word_index, pre_trained=pre_trained), train_seq_x, train_y, valid_seq_x, valid_y, es, name=\"RCNN_var1_WE\",scoring=score_metrics, n_splits=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Recurrent Convulational Neural Network variation 2</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_rcnn_var2(word_index, label=labels, embedding_matrix=embedding_matrix, pre_trained=False):\n",
    "    '''\n",
    "    Function to generate a rcnn for binary or multiclass classification.\n",
    "    @param word_index: (matrix) unique token in corpus\n",
    "    @param label: (list) list of labels to determine if it,s a binary or multiclass\n",
    "    @param embedding_matrix: (matrix) matrix of integer for each word in the \n",
    "    @param pre_trained: (bool) determine if the model will use pretrained model\n",
    "    @return: (model)  rcnn\n",
    "    '''\n",
    "    if pre_trained==False:\n",
    "        embedded = keras.layers.Embedding(len(word_index) + 1, 100)\n",
    "    else:\n",
    "        embedded = keras.layers.Embedding(len(word_index) + 1, 300, weights=[embedding_matrix], trainable=False)\n",
    "    \n",
    "    model = keras.Sequential([\n",
    "    embedded,\n",
    "    keras.layers.SpatialDropout1D(0.3),\n",
    "    keras.layers.Bidirectional(keras.layers.GRU(32,return_sequences=True)),\n",
    "    keras.layers.Bidirectional(keras.layers.GRU(32,return_sequences=True)),\n",
    "    keras.layers.Convolution1D(32, 3, activation=\"relu\"),\n",
    "    keras.layers.GlobalMaxPool1D(),\n",
    "    keras.layers.Dense(25, activation=\"relu\"),\n",
    "    keras.layers.Dropout(0.25),\n",
    "    keras.layers.Dense(1 if len(label)<=2 else len(label), activation='sigmoid' if len(label)<=2 else \"softmax\")])\n",
    "\n",
    "    if len(label)==2:\n",
    "        model.compile(optimizer='adam',\n",
    "              loss=tf.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "    else: \n",
    "        model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=1e-4),\n",
    "              loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "    #print(model.summary())\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k-fold : 1\n",
      "k-fold : 2\n",
      "k-fold : 3\n",
      "k-fold : 4\n",
      "k-fold : 5\n",
      "CPU times: user 3h 44min 4s, sys: 32min 52s, total: 4h 16min 56s\n",
      "Wall time: 1h 16min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if rcnn:\n",
    "    df_results = df_results.append(cross_validate_NN(create_rcnn_var2(word_index, pre_trained=pre_trained), train_seq_x, train_y, valid_seq_x, valid_y, es, name=\"RCNN_var2_WE\",scoring=score_metrics, n_splits=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Recurrent Convulational Neural Network variation 3</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_rcnn_var3(word_index, label=labels, embedding_matrix=embedding_matrix, pre_trained=False):\n",
    "    if pre_trained==False:\n",
    "        embedded = keras.layers.Embedding(len(word_index) + 1, 100)\n",
    "    else:\n",
    "        embedded = keras.layers.Embedding(len(word_index) + 1, 300, weights=[embedding_matrix], trainable=False)\n",
    "    \n",
    "    model = keras.Sequential([\n",
    "    embedded,\n",
    "    keras.layers.SpatialDropout1D(0.3),\n",
    "    keras.layers.Bidirectional(keras.layers.GRU(32,return_sequences=True)),\n",
    "    keras.layers.Bidirectional(keras.layers.LSTM(32,return_sequences=True)),\n",
    "    keras.layers.Convolution1D(32, 3, activation=\"relu\"),\n",
    "    keras.layers.GlobalMaxPool1D(),\n",
    "    keras.layers.Dense(25, activation=\"relu\"),\n",
    "    keras.layers.Dropout(0.25),\n",
    "    keras.layers.Dense(1 if len(label)<=2 else len(label), activation='sigmoid' if len(label)<=2 else \"softmax\")])\n",
    "\n",
    "    if len(label)==2:\n",
    "        model.compile(optimizer='adam',\n",
    "              loss=tf.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "    else: \n",
    "        model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=1e-4),\n",
    "              loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "    #print(model.summary())\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k-fold : 1\n",
      "k-fold : 2\n",
      "k-fold : 3\n",
      "k-fold : 4\n",
      "k-fold : 5\n",
      "CPU times: user 4h 43min 32s, sys: 30min, total: 5h 13min 32s\n",
      "Wall time: 1h 30min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if rcnn:\n",
    "    df_results = df_results.append(cross_validate_NN(create_rcnn_var3(word_index, pre_trained=pre_trained), train_seq_x, train_y, valid_seq_x, valid_y, es, name=\"RCNN_var3_WE\",scoring=score_metrics, n_splits=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Transformers</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tutorial available on Keras documentation, code example written by Apoorv Nandan (<a href=\"https://keras.io/examples/nlp/text_classification_with_transformer/\">source: kears.io</a>)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadSelfAttention(layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads=8):\n",
    "        super(MultiHeadSelfAttention, self).__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        if embed_dim % num_heads != 0:\n",
    "            raise ValueError(\n",
    "                f\"embedding dimension = {embed_dim} should be divisible by number of heads = {num_heads}\"\n",
    "            )\n",
    "        self.projection_dim = embed_dim // num_heads\n",
    "        self.query_dense = layers.Dense(embed_dim)\n",
    "        self.key_dense = layers.Dense(embed_dim)\n",
    "        self.value_dense = layers.Dense(embed_dim)\n",
    "        self.combine_heads = layers.Dense(embed_dim)\n",
    "\n",
    "    def attention(self, query, key, value):\n",
    "        score = tf.matmul(query, key, transpose_b=True)\n",
    "        dim_key = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "        scaled_score = score / tf.math.sqrt(dim_key)\n",
    "        weights = tf.nn.softmax(scaled_score, axis=-1)\n",
    "        output = tf.matmul(weights, value)\n",
    "        return output, weights\n",
    "\n",
    "    def separate_heads(self, x, batch_size):\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.projection_dim))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # x.shape = [batch_size, seq_len, embedding_dim]\n",
    "        batch_size = tf.shape(inputs)[0]\n",
    "        query = self.query_dense(inputs)  # (batch_size, seq_len, embed_dim)\n",
    "        key = self.key_dense(inputs)  # (batch_size, seq_len, embed_dim)\n",
    "        value = self.value_dense(inputs)  # (batch_size, seq_len, embed_dim)\n",
    "        query = self.separate_heads(\n",
    "            query, batch_size\n",
    "        )  # (batch_size, num_heads, seq_len, projection_dim)\n",
    "        key = self.separate_heads(\n",
    "            key, batch_size\n",
    "        )  # (batch_size, num_heads, seq_len, projection_dim)\n",
    "        value = self.separate_heads(\n",
    "            value, batch_size\n",
    "        )  # (batch_size, num_heads, seq_len, projection_dim)\n",
    "        attention, weights = self.attention(query, key, value)\n",
    "        attention = tf.transpose(\n",
    "            attention, perm=[0, 2, 1, 3]\n",
    "        )  # (batch_size, seq_len, num_heads, projection_dim)\n",
    "        concat_attention = tf.reshape(\n",
    "            attention, (batch_size, -1, self.embed_dim)\n",
    "        )  # (batch_size, seq_len, embed_dim)\n",
    "        output = self.combine_heads(\n",
    "            concat_attention\n",
    "        )  # (batch_size, seq_len, embed_dim)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.att = MultiHeadSelfAttention(embed_dim, num_heads)\n",
    "        self.ffn = keras.Sequential(\n",
    "            [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
    "        )\n",
    "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = layers.Dropout(rate)\n",
    "        self.dropout2 = layers.Dropout(rate)\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        attn_output = self.att(inputs)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenAndPositionEmbedding(layers.Layer):\n",
    "    def __init__(self, maxlen, vocab_size, emded_dim):\n",
    "        super(TokenAndPositionEmbedding, self).__init__()\n",
    "        self.token_emb = layers.Embedding(input_dim=vocab_size, output_dim=emded_dim)\n",
    "        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=emded_dim)\n",
    "\n",
    "    def call(self, x):\n",
    "        maxlen = tf.shape(x)[-1]\n",
    "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
    "        positions = self.pos_emb(positions)\n",
    "        x = self.token_emb(x)\n",
    "        return x + positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformers_classifier(word_index, label=labels):\n",
    "    '''\n",
    "    Function to generate a rcnn for binary or multiclass classification.\n",
    "    @param word_index: (matrix) unique token in corpus\n",
    "    @param label: (list) list of labels to determine if it,s a binary or multiclass\n",
    "    @param embedding_matrix: (matrix) matrix of integer for each word in the \n",
    "    @param pre_trained: (bool) determine if the model will use pretrained model\n",
    "    @return: (model)  rcnn\n",
    "    '''\n",
    "    embed_dim = 32  # Embedding size for each token\n",
    "    num_heads = 2  # Number of attention heads\n",
    "    ff_dim = 32  # Hidden layer size in feed forward network inside transformer\n",
    "    vocab_size = len(word_index)+1\n",
    "    maxlen = 300\n",
    "    inputs = layers.Input(shape=(maxlen,))\n",
    "    embedding_layer = TokenAndPositionEmbedding(maxlen, vocab_size, embed_dim)\n",
    "    x = embedding_layer(inputs)\n",
    "    transformer_block = TransformerBlock(embed_dim, num_heads, ff_dim)\n",
    "    x = transformer_block(x)\n",
    "    x = layers.GlobalAveragePooling1D()(x)\n",
    "    x = layers.Dropout(0.1)(x)\n",
    "    x = layers.Dense(20, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(0.1)(x)\n",
    "    #outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "    \n",
    "    outputs = keras.layers.Dense(1 if len(label)<=2 else len(label), activation='sigmoid' if len(label)<=2 else \"softmax\")(x)\n",
    "\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    if len(label)==2:\n",
    "        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "              loss=tf.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "    else: \n",
    "        model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=1e-4),\n",
    "              loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "    print(model.summary())\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 300)]             0         \n",
      "_________________________________________________________________\n",
      "token_and_position_embedding (None, 300, 32)           5070528   \n",
      "_________________________________________________________________\n",
      "transformer_block (Transform (None, 300, 32)           6464      \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d (Gl (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 20)                660       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 5,077,673\n",
      "Trainable params: 5,077,673\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "k-fold : 1\n",
      "k-fold : 2\n"
     ]
    }
   ],
   "source": [
    "if transformers:\n",
    "    \n",
    "    df_results = df_results.append(cross_validate_NN(transformers_classifier(word_index, label=labels), train_seq_x, train_y, valid_seq_x, valid_y, es, name=\"transformers\",scoring=score_metrics, n_splits=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>Results</h1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = df_results.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results[[ \"Model\",\"test_acc_mean\",\"test_acc_std\", \n",
    "                        \"test_balanced_accuracy_mean\",\"test_balanced_accuracy_std\", \n",
    "                       \"test_prec_mean\", \"test_prec_std\", \n",
    "                        \"test_recall_mean\",\"test_recall_std\", \n",
    "                       \"test_f1-score_mean\", \"test_f1-score_std\", \n",
    "                       \"test_cohens_kappa_mean\", \"test_cohens_kappa_std\", \"test_matthews_corrcoef_mean\",\"test_matthews_corrcoef_std\", \n",
    "                       \"test_roc_auc_mean\", \"test_roc_auc_std\"]][df_results[\"test_prec_mean\"]<1].sort_values(by=[\"test_acc_mean\", \"test_recall_mean\"], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_results:\n",
    "    df_results.sort_values(by=[\"test_prec_mean\", \"test_recall_mean\"], ascending=False).to_csv(\"model_selection_results_IMDB.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h2>Visualisation</h2></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results=df_results[df_results[\"test_matthews_corrcoef_mean\"]>0.6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1800x1800 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(25,25))\n",
    "#plt.axis([0.85,1,0.85,1])\n",
    "ax.scatter(df_results[\"test_matthews_corrcoef_mean\"], df_results[\"test_acc_mean\"])\n",
    "\n",
    "for i, txt in enumerate(df_results[\"Model\"]):\n",
    "    ax.annotate(txt, (df_results[\"test_matthews_corrcoef_mean\"].iloc[i], df_results[\"test_acc_mean\"].iloc[i]))\n",
    "\n",
    "plt.xlabel(\"Matthews Corrcoef\")\n",
    "plt.ylabel(\"Recall\")\n",
    "\n",
    "plt.grid(True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
